{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to kal_utils","text":"<p>Kaleidoo utils package</p> <ul> <li>Free software: MIT License</li> <li>Documentation: https://BarLanderK.github.io/kal_utils</li> </ul>"},{"location":"#features","title":"Features","text":"<ul> <li>TODO</li> </ul>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v20828-date","title":"v2.0.8.28 - Date","text":"<p>Improvement:</p> <ul> <li>TBD</li> </ul> <p>New Features:</p> <ul> <li>Fully Featured, Tool Agnostic Event Messaging, Currently Includes the following tool support:</li> <li>RabbitMQ (Synchronous &amp; Asynchronous Implementation)</li> <li>Kafka (Synchronous &amp; Asynchronous Implementation)</li> <li>PubSub (Synchronous &amp; Asynchronous Implementation)</li> <li>All Implementations are OOP based (Abstract Polymorphic Implementation)</li> </ul>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"contributing/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"contributing/#report-bugs","title":"Report Bugs","text":"<p>Report bugs at https://github.com/BarLanderK/kal-utils/issues.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"contributing/#fix-bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with <code>bug</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#implement-features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with <code>enhancement</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#write-documentation","title":"Write Documentation","text":"<p>kal-utils could always use more documentation, whether as part of the official kal-utils docs, in docstrings, or even on the web in blog posts, articles, and such.</p>"},{"location":"contributing/#submit-feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to file an issue at https://github.com/BarLanderK/kal-utils/issues.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> <li>Remember that this is a volunteer-driven project, and that contributions are welcome :)</li> </ul>"},{"location":"contributing/#get-started","title":"Get Started!","text":"<p>Ready to contribute? Here's how to set up kal-utils for local development.</p> <ol> <li> <p>Fork the kal-utils repo on GitHub.</p> </li> <li> <p>Clone your fork locally:</p> <pre><code>$ git clone git@github.com:your_name_here/kal-utils.git\n</code></pre> </li> <li> <p>Install your local copy into a virtualenv. Assuming you have     virtualenvwrapper installed, this is how you set up your fork for     local development:</p> <pre><code>$ mkvirtualenv kal-utils\n$ cd kal-utils/\n$ python setup.py develop\n</code></pre> </li> <li> <p>Create a branch for local development:</p> <pre><code>$ git checkout -b name-of-your-bugfix-or-feature\n</code></pre> <p>Now you can make your changes locally.</p> </li> <li> <p>When you're done making changes, check that your changes pass flake8     and the tests, including testing other Python versions with tox:</p> <pre><code>$ flake8 kal-utils tests\n$ python setup.py test or pytest\n$ tox\n</code></pre> <p>To get flake8 and tox, just pip install them into your virtualenv.</p> </li> <li> <p>Commit your changes and push your branch to GitHub:</p> <pre><code>$ git add .\n$ git commit -m \"Your detailed description of your changes.\"\n$ git push origin name-of-your-bugfix-or-feature\n</code></pre> </li> <li> <p>Submit a pull request through the GitHub website.</p> </li> </ol>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li>The pull request should include tests.</li> <li>If the pull request adds functionality, the docs should be updated.     Put your new functionality into a function with a docstring, and add     the feature to the list in README.rst.</li> <li>The pull request should work for Python 3.8 and later, and     for PyPy. Check https://github.com/BarLanderK/kal-utils/pull_requests and make sure that the tests pass for all     supported Python versions.</li> </ol>"},{"location":"faq/","title":"FAQ","text":""},{"location":"handle_response/","title":"handle_response module","text":""},{"location":"helper/","title":"helper module","text":""},{"location":"helper/#kal_utils.helper.validate_dict_structure","title":"<code>validate_dict_structure(data, expected_data, check_extra_keys=False)</code>","text":"<p>Validate that all expected data is present and not empty, and optionally check for extra keys.</p> <ul> <li>data (dict): A dictionary containing the actual data to validate.</li> <li>expected_data (dict): A dictionary containing the expected data structure.</li> <li>check_extra_keys (bool): A boolean flag indicating whether to check for extra keys in the data.                            Default is False.</li> </ul> <ul> <li>bool: True if validation passes, False otherwise.</li> </ul> Source code in <code>kal_utils/helper.py</code> <pre><code>def validate_dict_structure(data: dict, expected_data: dict, check_extra_keys: bool = False) -&gt; bool:\n    \"\"\"\n    Validate that all expected data is present and not empty, and optionally check for extra keys.\n\n    Parameters:\n    - data (dict): A dictionary containing the actual data to validate.\n    - expected_data (dict): A dictionary containing the expected data structure.\n    - check_extra_keys (bool): A boolean flag indicating whether to check for extra keys in the data.\n                               Default is False.\n\n    Returns:\n    - bool: True if validation passes, False otherwise.\n    \"\"\"\n    # Check for missing or empty values\n    for key in expected_data.keys():\n        if not data.get(key):\n            return False\n\n    if check_extra_keys:\n        # Check for extra keys\n        for key in data.keys():\n            if key not in expected_data:\n                return False\n\n    return True\n</code></pre>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#stable-release","title":"Stable release","text":"<p>To install kal-utils, run this command in your terminal:</p> <pre><code>pip install kal-utils\n</code></pre> <p>This is the preferred method to install kal-utils, as it will always install the most recent stable release.</p> <p>If you don't have pip installed, this Python installation guide can guide you through the process.</p>"},{"location":"installation/#from-sources","title":"From sources","text":"<p>To install kal-utils from sources, run this command in your terminal:</p> <pre><code>pip install git+https://github.com/BarLanderK/kal-utils\n</code></pre>"},{"location":"kal_utils/","title":"kal_utils module","text":"<p>Main module.</p>"},{"location":"logging/","title":"logging module","text":"<p>This module provides an abstraction layer for working with different logger systems.</p>"},{"location":"logging/#functions","title":"functions","text":""},{"location":"logging/#logger","title":"logger","text":"<p>Initializes the logger with the specified name, sets its log level, and sets up trace logging. This should be called during application startup to configure logging.</p> Source code in <code>kal_utils/logging/logger.py</code> <pre><code>def init_logger(name):\n    \"\"\"\n    Initializes the logger with the specified name, sets its log level, and sets up trace logging.\n    This should be called during application startup to configure logging.\n    \"\"\"\n    # Create a logger with the provided name\n    logger = logging.getLogger(name)\n    # Set the log level to INFO, so it captures logs of level INFO or higher\n    logger.setLevel(logging.INFO)\n\n    # Set up trace logging (filters, formatter, and noisy loggers)\n    setup_trace_logging(logger)\n\n    # Enable OpenTelemetry logging instrumentation to track trace data\n    LoggingInstrumentor().instrument()\n\n    # Return the configured logger for use in the application\n    return logger\n</code></pre>"},{"location":"mongodb/","title":"mongodb module","text":""},{"location":"monitoring/","title":"Monitoring Module","text":"<p>This module provides interfaces and prebuilt monitoring configuration and integration tools.</p>"},{"location":"monitoring/#classes","title":"Classes","text":""},{"location":"monitoring/#configmanager","title":"ConfigManager","text":"<p>Abstract base class for configuration management.</p> <p>This class defines the methods that must be implemented by any concrete configuration manager to provide configuration details required by the application.</p> Source code in <code>kal_utils/monitoring/core/config_managers.py</code> <pre><code>class ConfigManager(ABC):\n    \"\"\"\n    Abstract base class for configuration management.\n\n    This class defines the methods that must be implemented by any concrete configuration manager\n    to provide configuration details required by the application.\n    \"\"\"\n\n    @abstractmethod\n    def get_service_name(self) -&gt; str:\n        \"\"\"\n        Abstract method to retrieve the service name.\n\n        Returns:\n            str: The service name.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_endpoint(self) -&gt; str:\n        \"\"\"\n        Abstract method to retrieve the endpoint URL.\n\n        Returns:\n            str: The endpoint URL.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_exporter_type(self) -&gt; str:\n        \"\"\"\n        Abstract method to retrieve the exporter type.\n\n        Returns:\n            str: The exporter type.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_insecure(self) -&gt; bool:\n        \"\"\"\n        Abstract method to determine if the connection is insecure.\n\n        Returns:\n            bool: True if the connection is insecure, False otherwise.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.core.config_managers.ConfigManager.get_endpoint","title":"<code>get_endpoint(self)</code>","text":"<p>Abstract method to retrieve the endpoint URL.</p> <p>Returns:</p> Type Description <code>str</code> <p>The endpoint URL.</p> Source code in <code>kal_utils/monitoring/core/config_managers.py</code> <pre><code>@abstractmethod\ndef get_endpoint(self) -&gt; str:\n    \"\"\"\n    Abstract method to retrieve the endpoint URL.\n\n    Returns:\n        str: The endpoint URL.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.core.config_managers.ConfigManager.get_exporter_type","title":"<code>get_exporter_type(self)</code>","text":"<p>Abstract method to retrieve the exporter type.</p> <p>Returns:</p> Type Description <code>str</code> <p>The exporter type.</p> Source code in <code>kal_utils/monitoring/core/config_managers.py</code> <pre><code>@abstractmethod\ndef get_exporter_type(self) -&gt; str:\n    \"\"\"\n    Abstract method to retrieve the exporter type.\n\n    Returns:\n        str: The exporter type.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.core.config_managers.ConfigManager.get_insecure","title":"<code>get_insecure(self)</code>","text":"<p>Abstract method to determine if the connection is insecure.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the connection is insecure, False otherwise.</p> Source code in <code>kal_utils/monitoring/core/config_managers.py</code> <pre><code>@abstractmethod\ndef get_insecure(self) -&gt; bool:\n    \"\"\"\n    Abstract method to determine if the connection is insecure.\n\n    Returns:\n        bool: True if the connection is insecure, False otherwise.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.core.config_managers.ConfigManager.get_service_name","title":"<code>get_service_name(self)</code>","text":"<p>Abstract method to retrieve the service name.</p> <p>Returns:</p> Type Description <code>str</code> <p>The service name.</p> Source code in <code>kal_utils/monitoring/core/config_managers.py</code> <pre><code>@abstractmethod\ndef get_service_name(self) -&gt; str:\n    \"\"\"\n    Abstract method to retrieve the service name.\n\n    Returns:\n        str: The service name.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"monitoring/#envconfigmanager","title":"EnvConfigManager","text":"<p>Configuration manager that reads configuration from environment variables.</p> <p>This implementation retrieves configuration values from environment variables.</p> Source code in <code>kal_utils/monitoring/core/config_managers.py</code> <pre><code>class EnvConfigManager(ConfigManager):\n    \"\"\"\n    Configuration manager that reads configuration from environment variables.\n\n    This implementation retrieves configuration values from environment variables.\n    \"\"\"\n\n    def get_service_name(self) -&gt; str:\n        \"\"\"\n        Retrieves the service name from the environment variables.\n\n        Returns:\n            str: The service name, defaulting to \"my-fastapi-service\" if not set.\n        \"\"\"\n        return os.getenv(\"OTEL_SERVICE_NAME\", \"my-fastapi-service\")\n\n    def get_endpoint(self) -&gt; str:\n        \"\"\"\n        Retrieves the endpoint URL from the environment variables.\n\n        Returns:\n            str: The endpoint URL, defaulting to \"http://localhost:4317\" if not set.\n        \"\"\"\n        return os.getenv(\"OTEL_ENDPOINT\", \"http://localhost:4317\")\n\n    def get_exporter_type(self) -&gt; str:\n        \"\"\"\n        Retrieves the exporter type from the environment variables.\n\n        Returns:\n            str: The exporter type, defaulting to \"otlp\" if not set.\n        \"\"\"\n        return os.getenv(\"OTEL_EXPORTER_TYPE\", \"otlp\")\n\n    def get_insecure(self) -&gt; bool:\n        \"\"\"\n        Determines if the connection is insecure based on environment variables.\n\n        Returns:\n            bool: True if the connection is insecure (when \"OTEL_INSECURE\" is \"true\", \"1\", or \"yes\"), False otherwise.\n        \"\"\"\n        return os.getenv(\"OTEL_INSECURE\", \"true\").lower() in [\"true\", \"1\", \"yes\"]\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.core.config_managers.EnvConfigManager.get_endpoint","title":"<code>get_endpoint(self)</code>","text":"<p>Retrieves the endpoint URL from the environment variables.</p> <p>Returns:</p> Type Description <code>str</code> <p>The endpoint URL, defaulting to \"http://localhost:4317\" if not set.</p> Source code in <code>kal_utils/monitoring/core/config_managers.py</code> <pre><code>def get_endpoint(self) -&gt; str:\n    \"\"\"\n    Retrieves the endpoint URL from the environment variables.\n\n    Returns:\n        str: The endpoint URL, defaulting to \"http://localhost:4317\" if not set.\n    \"\"\"\n    return os.getenv(\"OTEL_ENDPOINT\", \"http://localhost:4317\")\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.core.config_managers.EnvConfigManager.get_exporter_type","title":"<code>get_exporter_type(self)</code>","text":"<p>Retrieves the exporter type from the environment variables.</p> <p>Returns:</p> Type Description <code>str</code> <p>The exporter type, defaulting to \"otlp\" if not set.</p> Source code in <code>kal_utils/monitoring/core/config_managers.py</code> <pre><code>def get_exporter_type(self) -&gt; str:\n    \"\"\"\n    Retrieves the exporter type from the environment variables.\n\n    Returns:\n        str: The exporter type, defaulting to \"otlp\" if not set.\n    \"\"\"\n    return os.getenv(\"OTEL_EXPORTER_TYPE\", \"otlp\")\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.core.config_managers.EnvConfigManager.get_insecure","title":"<code>get_insecure(self)</code>","text":"<p>Determines if the connection is insecure based on environment variables.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the connection is insecure (when \"OTEL_INSECURE\" is \"true\", \"1\", or \"yes\"), False otherwise.</p> Source code in <code>kal_utils/monitoring/core/config_managers.py</code> <pre><code>def get_insecure(self) -&gt; bool:\n    \"\"\"\n    Determines if the connection is insecure based on environment variables.\n\n    Returns:\n        bool: True if the connection is insecure (when \"OTEL_INSECURE\" is \"true\", \"1\", or \"yes\"), False otherwise.\n    \"\"\"\n    return os.getenv(\"OTEL_INSECURE\", \"true\").lower() in [\"true\", \"1\", \"yes\"]\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.core.config_managers.EnvConfigManager.get_service_name","title":"<code>get_service_name(self)</code>","text":"<p>Retrieves the service name from the environment variables.</p> <p>Returns:</p> Type Description <code>str</code> <p>The service name, defaulting to \"my-fastapi-service\" if not set.</p> Source code in <code>kal_utils/monitoring/core/config_managers.py</code> <pre><code>def get_service_name(self) -&gt; str:\n    \"\"\"\n    Retrieves the service name from the environment variables.\n\n    Returns:\n        str: The service name, defaulting to \"my-fastapi-service\" if not set.\n    \"\"\"\n    return os.getenv(\"OTEL_SERVICE_NAME\", \"my-fastapi-service\")\n</code></pre>"},{"location":"monitoring/#awsconfigmanager","title":"AWSConfigManager","text":"<p>Configuration manager that retrieves configuration from AWS Secrets Manager.</p> <p>This implementation retrieves configuration values stored in AWS Secrets Manager.</p> Source code in <code>kal_utils/monitoring/core/config_managers.py</code> <pre><code>class AWSConfigManager(ConfigManager):\n    \"\"\"\n    Configuration manager that retrieves configuration from AWS Secrets Manager.\n\n    This implementation retrieves configuration values stored in AWS Secrets Manager.\n    \"\"\"\n\n    def __init__(self, secret_name: str, region_name: str):\n        \"\"\"\n        Initializes the AWSConfigManager with the secret name and AWS region.\n\n        Args:\n            secret_name (str): The name of the secret in AWS Secrets Manager.\n            region_name (str): The AWS region where the secret is stored.\n        \"\"\"\n        self.secret_name = secret_name\n        self.region_name = region_name\n        self.client = boto3.client(\"secretsmanager\", region_name=self.region_name)\n\n    def _get_secret(self) -&gt; str:\n        \"\"\"\n        Retrieves the secret value from AWS Secrets Manager.\n\n        Returns:\n            str: The secret value as a JSON string.\n\n        Raises:\n            Exception: If there is an error retrieving the secret from AWS Secrets Manager.\n        \"\"\"\n        try:\n            response = self.client.get_secret_value(SecretId=self.secret_name)\n            return response['SecretString']\n        except ClientError as e:\n            raise Exception(f\"Error retrieving secret from AWS Secrets Manager: {e}\")\n\n    def get_service_name(self) -&gt; str:\n        \"\"\"\n        Retrieves the service name from the AWS secret.\n\n        Returns:\n            str: The service name, defaulting to \"my-fastapi-service\" if not found in the secret.\n        \"\"\"\n        secret = self._get_secret()\n        return json.loads(secret).get(\"OTEL_SERVICE_NAME\", \"my-fastapi-service\")\n\n    def get_endpoint(self) -&gt; str:\n        \"\"\"\n        Retrieves the endpoint URL from the AWS secret.\n\n        Returns:\n            str: The endpoint URL, defaulting to \"http://localhost:4317\" if not found in the secret.\n        \"\"\"\n        secret = self._get_secret()\n        return json.loads(secret).get(\"OTEL_ENDPOINT\", \"http://localhost:4317\")\n\n    def get_exporter_type(self) -&gt; str:\n        \"\"\"\n        Retrieves the exporter type from the AWS secret.\n\n        Returns:\n            str: The exporter type, defaulting to \"otlp\" if not found in the secret.\n        \"\"\"\n        secret = self._get_secret()\n        return json.loads(secret).get(\"OTEL_EXPORTER_TYPE\", \"otlp\")\n\n    def get_insecure(self) -&gt; bool:\n        \"\"\"\n        Determines if the connection is insecure based on the AWS secret.\n\n        Returns:\n            bool: True if the connection is insecure (when \"OTEL_INSECURE\" is \"true\", \"1\", or \"yes\" in the secret), False otherwise.\n        \"\"\"\n        secret = self._get_secret()\n        return json.loads(secret).get(\"OTEL_INSECURE\", \"true\").lower() in [\"true\", \"1\", \"yes\"]\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.core.config_managers.AWSConfigManager.__init__","title":"<code>__init__(self, secret_name, region_name)</code>  <code>special</code>","text":"<p>Initializes the AWSConfigManager with the secret name and AWS region.</p> <p>Parameters:</p> Name Type Description Default <code>secret_name</code> <code>str</code> <p>The name of the secret in AWS Secrets Manager.</p> required <code>region_name</code> <code>str</code> <p>The AWS region where the secret is stored.</p> required Source code in <code>kal_utils/monitoring/core/config_managers.py</code> <pre><code>def __init__(self, secret_name: str, region_name: str):\n    \"\"\"\n    Initializes the AWSConfigManager with the secret name and AWS region.\n\n    Args:\n        secret_name (str): The name of the secret in AWS Secrets Manager.\n        region_name (str): The AWS region where the secret is stored.\n    \"\"\"\n    self.secret_name = secret_name\n    self.region_name = region_name\n    self.client = boto3.client(\"secretsmanager\", region_name=self.region_name)\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.core.config_managers.AWSConfigManager.get_endpoint","title":"<code>get_endpoint(self)</code>","text":"<p>Retrieves the endpoint URL from the AWS secret.</p> <p>Returns:</p> Type Description <code>str</code> <p>The endpoint URL, defaulting to \"http://localhost:4317\" if not found in the secret.</p> Source code in <code>kal_utils/monitoring/core/config_managers.py</code> <pre><code>def get_endpoint(self) -&gt; str:\n    \"\"\"\n    Retrieves the endpoint URL from the AWS secret.\n\n    Returns:\n        str: The endpoint URL, defaulting to \"http://localhost:4317\" if not found in the secret.\n    \"\"\"\n    secret = self._get_secret()\n    return json.loads(secret).get(\"OTEL_ENDPOINT\", \"http://localhost:4317\")\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.core.config_managers.AWSConfigManager.get_exporter_type","title":"<code>get_exporter_type(self)</code>","text":"<p>Retrieves the exporter type from the AWS secret.</p> <p>Returns:</p> Type Description <code>str</code> <p>The exporter type, defaulting to \"otlp\" if not found in the secret.</p> Source code in <code>kal_utils/monitoring/core/config_managers.py</code> <pre><code>def get_exporter_type(self) -&gt; str:\n    \"\"\"\n    Retrieves the exporter type from the AWS secret.\n\n    Returns:\n        str: The exporter type, defaulting to \"otlp\" if not found in the secret.\n    \"\"\"\n    secret = self._get_secret()\n    return json.loads(secret).get(\"OTEL_EXPORTER_TYPE\", \"otlp\")\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.core.config_managers.AWSConfigManager.get_insecure","title":"<code>get_insecure(self)</code>","text":"<p>Determines if the connection is insecure based on the AWS secret.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the connection is insecure (when \"OTEL_INSECURE\" is \"true\", \"1\", or \"yes\" in the secret), False otherwise.</p> Source code in <code>kal_utils/monitoring/core/config_managers.py</code> <pre><code>def get_insecure(self) -&gt; bool:\n    \"\"\"\n    Determines if the connection is insecure based on the AWS secret.\n\n    Returns:\n        bool: True if the connection is insecure (when \"OTEL_INSECURE\" is \"true\", \"1\", or \"yes\" in the secret), False otherwise.\n    \"\"\"\n    secret = self._get_secret()\n    return json.loads(secret).get(\"OTEL_INSECURE\", \"true\").lower() in [\"true\", \"1\", \"yes\"]\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.core.config_managers.AWSConfigManager.get_service_name","title":"<code>get_service_name(self)</code>","text":"<p>Retrieves the service name from the AWS secret.</p> <p>Returns:</p> Type Description <code>str</code> <p>The service name, defaulting to \"my-fastapi-service\" if not found in the secret.</p> Source code in <code>kal_utils/monitoring/core/config_managers.py</code> <pre><code>def get_service_name(self) -&gt; str:\n    \"\"\"\n    Retrieves the service name from the AWS secret.\n\n    Returns:\n        str: The service name, defaulting to \"my-fastapi-service\" if not found in the secret.\n    \"\"\"\n    secret = self._get_secret()\n    return json.loads(secret).get(\"OTEL_SERVICE_NAME\", \"my-fastapi-service\")\n</code></pre>"},{"location":"monitoring/#prometheusmetricsdecorator","title":"PrometheusMetricsDecorator","text":"<p>An abstract base class for creating Prometheus metrics decorators.</p> <p>This class provides a framework for implementing Prometheus metrics in a FastAPI application. To use this class, create a subclass and implement the abstract methods.</p> <p>Exceptions:</p> Type Description <code>NotImplementedError</code> <p>If any of the abstract methods are not implemented in the subclass.</p> Source code in <code>kal_utils/monitoring/prometheus/prometheus_base.py</code> <pre><code>class PrometheusMetricsDecorator(ABC):\n    \"\"\"\n    An abstract base class for creating Prometheus metrics decorators.\n\n    This class provides a framework for implementing Prometheus metrics\n    in a FastAPI application. To use this class, create a subclass and\n    implement the abstract methods.\n\n    Raises:\n        NotImplementedError: If any of the abstract methods are not implemented in the subclass.\n    \"\"\"\n\n    def __init__(self, app: FastAPI):\n        \"\"\"\n        Initialize the metrics decorator.\n        Calls setup_metrics() which should be implemented in the subclass.\n        \"\"\"\n        self.metrics = {}\n        # Define the metrics if they don't already exist in the registry\n        if 'db_time_seconds' not in REGISTRY._names_to_collectors:\n            self.metrics['db_time'] = Summary(\n                'db_time_seconds',\n                'Time taken for database operations'\n            )\n        else:\n            self.metrics['db_time'] = REGISTRY._names_to_collectors['db_time_seconds']\n\n        if 'print_time_seconds' not in REGISTRY._names_to_collectors:\n            self.metrics['print_time'] = Summary(\n                'print_time_seconds',\n                'Time taken for print operations'\n            )\n        else:\n            self.metrics['print_time'] = REGISTRY._names_to_collectors['print_time_seconds']\n\n        if 'produce_time_seconds' not in REGISTRY._names_to_collectors:\n            self.metrics['produce_time'] = Histogram(\n                'produce_time_seconds',\n                'Time taken to produce messages in seconds'\n            )\n        else:\n            self.metrics['produce_time'] = REGISTRY._names_to_collectors['produce_time_seconds']\n\n        if 'consume_time_seconds' not in REGISTRY._names_to_collectors:\n            self.metrics['consume_time'] = Histogram(\n                'consume_time_seconds',\n                'Time taken to consume messages in seconds'\n            )\n        else:\n            self.metrics['consume_time'] = REGISTRY._names_to_collectors['consume_time_seconds']\n        self.setup_metrics()\n        self.add_metrics_endpoint(app)\n\n    @abstractmethod\n    def setup_metrics(self):\n        \"\"\"\n        Abstract method to set up Prometheus metrics.\n\n        Implement this method in your subclass to initialize all the\n        Prometheus metrics you want to track (e.g., Counters, Gauges, Histograms).\n\n        Raises:\n            NotImplementedError: If not implemented in the subclass.\n        \"\"\"\n        raise NotImplementedError(\"setup_metrics() must be implemented in the subclass\")\n\n    def add_metrics_endpoint(self, app: FastAPI):\n        \"\"\"\n        Add a /metrics endpoint to the FastAPI app for Prometheus to scrape.\n\n        Args:\n            app (FastAPI): The FastAPI application instance.\n        \"\"\"\n        @app.get(\"/metrics\")\n        async def metrics(credentials: HTTPBasicCredentials = Depends(authenticate)):\n            return Response(generate_latest(), media_type=CONTENT_TYPE_LATEST)\n\n\n    def instrument(self) -&gt; Callable:\n        \"\"\"\n        Decorator to instrument FastAPI route handlers.\n\n        This method returns a decorator that wraps route handlers to execute\n        before_request() and after_request() methods around each request.\n\n        Returns:\n            Callable: A decorator function.\n        \"\"\"\n        def decorator(func: Callable) -&gt; Callable:\n            @wraps(func)\n            async def wrapper(request: Request, *args: Any, **kwargs: Any) -&gt; Any:\n                self.before_request(request)\n                response = await func(request, *args, **kwargs)\n                self.after_request(request, response)\n                return response\n            return wrapper\n        return decorator\n\n    @abstractmethod\n    def before_request(self, request: Request):\n        \"\"\"\n        Abstract method to be called before each request is processed.\n\n        Implement this method in your subclass to perform any pre-request\n        actions, such as incrementing request counters or starting timers.\n\n        Args:\n            request (Request): The FastAPI Request object.\n\n        Raises:\n            NotImplementedError: If not implemented in the subclass.\n        \"\"\"\n        raise NotImplementedError(\"before_request() must be implemented in the subclass\")\n\n    @abstractmethod\n    def after_request(self, request: Request, response: Any):\n        \"\"\"\n        Abstract method to be called after each request is processed.\n\n        Implement this method in your subclass to perform any post-request\n        actions, such as recording response times or updating response status metrics.\n\n        Args:\n            request (Request): The FastAPI Request object.\n            response (Any): The response returned by the route handler.\n\n        Raises:\n            NotImplementedError: If not implemented in the subclass.\n        \"\"\"\n        raise NotImplementedError(\"after_request() must be implemented in the subclass\")\n\n    @abstractmethod\n    def update_metrics(self, request: Request, response: Any):\n        \"\"\"\n        Abstract method to be called after each request is processed.\n\n        Implement this method in your subclass to perform any post-request\n        actions, such as recording response times or updating response status metrics.\n\n        Args:\n            request (Request): The FastAPI Request object.\n            response (Any): The response returned by the route handler.\n\n        Raises:\n            NotImplementedError: If not implemented in the subclass.\n        \"\"\"\n        raise NotImplementedError(\"after_request() must be implemented in the subclass\")\n\n    @contextmanager\n    def db_time(self):\n        \"\"\"\n        Context manager for tracking DB operation time.\n\n        This context manager measures the time taken for database operations\n        and records this duration as a Prometheus metric.\n\n        Example:\n            with self.db_time():\n                # Perform database operations here\n                result = perform_database_query()\n        \"\"\"\n        start_time = time.time()\n        try:\n            yield\n        finally:\n            duration = time.time() - start_time\n            self.record_metric('db_time', duration)\n\n    @contextmanager\n    def print_time(self):\n        \"\"\"\n        Context manager for tracking print operation time.\n\n        This context manager measures the time taken for print operations\n        or similar tasks and records this duration as a Prometheus metric.\n\n        Example:\n            with self.print_time():\n                # Perform print operations here\n                print(\"Logging some information...\")\n        \"\"\"\n        start_time = time.time()\n        try:\n            yield\n        finally:\n            duration = time.time() - start_time\n            self.record_metric('print_time', duration)\n\n    @contextmanager\n    def produce_time(self):\n        \"\"\"\n        Context manager for tracking the time taken to produce a message.\n\n        This context manager measures the time taken for produce operations\n        and records this duration as a Prometheus metric.\n\n        Example:\n            with self.produce_time():\n                # Perform produce operations here\n                produce_message()\n        \"\"\"\n        start_time = time.time()\n        try:\n            yield\n        finally:\n            duration = time.time() - start_time\n            self.record_metric('produce_time', duration)\n\n    @contextmanager\n    def consume_time(self):\n        \"\"\"\n        Context manager for tracking the time taken to produce a message.\n\n        This context manager measures the time taken for produce operations\n        and records this duration as a Prometheus metric.\n\n        Example:\n            with self.produce_time():\n                # Perform produce operations here\n                produce_message()\n        \"\"\"\n        start_time = time.time()\n        try:\n            yield\n        finally:\n            duration = time.time() - start_time\n            self.record_metric('consume_time', duration)\n\n    def record_metric(self, name: str, duration: float):\n        \"\"\"\n        Record the metric with the given name and duration.\n\n        Args:\n            name (str): The name of the metric.\n            duration (float): The duration of the operation.\n        \"\"\"\n        if name in self.metrics:\n            self.metrics[name].observe(duration)\n\n    def handle_exception(self, name: str, exc_type: type, exc_val: Exception):\n        \"\"\"\n        Handle exceptions in context managers if needed.\n\n        Args:\n            name (str): The name of the metric.\n            exc_type (type): The type of exception.\n            exc_val (Exception): The exception value.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.prometheus_base.PrometheusMetricsDecorator.__init__","title":"<code>__init__(self, app)</code>  <code>special</code>","text":"<p>Initialize the metrics decorator. Calls setup_metrics() which should be implemented in the subclass.</p> Source code in <code>kal_utils/monitoring/prometheus/prometheus_base.py</code> <pre><code>def __init__(self, app: FastAPI):\n    \"\"\"\n    Initialize the metrics decorator.\n    Calls setup_metrics() which should be implemented in the subclass.\n    \"\"\"\n    self.metrics = {}\n    # Define the metrics if they don't already exist in the registry\n    if 'db_time_seconds' not in REGISTRY._names_to_collectors:\n        self.metrics['db_time'] = Summary(\n            'db_time_seconds',\n            'Time taken for database operations'\n        )\n    else:\n        self.metrics['db_time'] = REGISTRY._names_to_collectors['db_time_seconds']\n\n    if 'print_time_seconds' not in REGISTRY._names_to_collectors:\n        self.metrics['print_time'] = Summary(\n            'print_time_seconds',\n            'Time taken for print operations'\n        )\n    else:\n        self.metrics['print_time'] = REGISTRY._names_to_collectors['print_time_seconds']\n\n    if 'produce_time_seconds' not in REGISTRY._names_to_collectors:\n        self.metrics['produce_time'] = Histogram(\n            'produce_time_seconds',\n            'Time taken to produce messages in seconds'\n        )\n    else:\n        self.metrics['produce_time'] = REGISTRY._names_to_collectors['produce_time_seconds']\n\n    if 'consume_time_seconds' not in REGISTRY._names_to_collectors:\n        self.metrics['consume_time'] = Histogram(\n            'consume_time_seconds',\n            'Time taken to consume messages in seconds'\n        )\n    else:\n        self.metrics['consume_time'] = REGISTRY._names_to_collectors['consume_time_seconds']\n    self.setup_metrics()\n    self.add_metrics_endpoint(app)\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.prometheus_base.PrometheusMetricsDecorator.add_metrics_endpoint","title":"<code>add_metrics_endpoint(self, app)</code>","text":"<p>Add a /metrics endpoint to the FastAPI app for Prometheus to scrape.</p> <p>Parameters:</p> Name Type Description Default <code>app</code> <code>FastAPI</code> <p>The FastAPI application instance.</p> required Source code in <code>kal_utils/monitoring/prometheus/prometheus_base.py</code> <pre><code>def add_metrics_endpoint(self, app: FastAPI):\n    \"\"\"\n    Add a /metrics endpoint to the FastAPI app for Prometheus to scrape.\n\n    Args:\n        app (FastAPI): The FastAPI application instance.\n    \"\"\"\n    @app.get(\"/metrics\")\n    async def metrics(credentials: HTTPBasicCredentials = Depends(authenticate)):\n        return Response(generate_latest(), media_type=CONTENT_TYPE_LATEST)\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.prometheus_base.PrometheusMetricsDecorator.after_request","title":"<code>after_request(self, request, response)</code>","text":"<p>Abstract method to be called after each request is processed.</p> <p>Implement this method in your subclass to perform any post-request actions, such as recording response times or updating response status metrics.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>The FastAPI Request object.</p> required <code>response</code> <code>Any</code> <p>The response returned by the route handler.</p> required <p>Exceptions:</p> Type Description <code>NotImplementedError</code> <p>If not implemented in the subclass.</p> Source code in <code>kal_utils/monitoring/prometheus/prometheus_base.py</code> <pre><code>@abstractmethod\ndef after_request(self, request: Request, response: Any):\n    \"\"\"\n    Abstract method to be called after each request is processed.\n\n    Implement this method in your subclass to perform any post-request\n    actions, such as recording response times or updating response status metrics.\n\n    Args:\n        request (Request): The FastAPI Request object.\n        response (Any): The response returned by the route handler.\n\n    Raises:\n        NotImplementedError: If not implemented in the subclass.\n    \"\"\"\n    raise NotImplementedError(\"after_request() must be implemented in the subclass\")\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.prometheus_base.PrometheusMetricsDecorator.before_request","title":"<code>before_request(self, request)</code>","text":"<p>Abstract method to be called before each request is processed.</p> <p>Implement this method in your subclass to perform any pre-request actions, such as incrementing request counters or starting timers.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>The FastAPI Request object.</p> required <p>Exceptions:</p> Type Description <code>NotImplementedError</code> <p>If not implemented in the subclass.</p> Source code in <code>kal_utils/monitoring/prometheus/prometheus_base.py</code> <pre><code>@abstractmethod\ndef before_request(self, request: Request):\n    \"\"\"\n    Abstract method to be called before each request is processed.\n\n    Implement this method in your subclass to perform any pre-request\n    actions, such as incrementing request counters or starting timers.\n\n    Args:\n        request (Request): The FastAPI Request object.\n\n    Raises:\n        NotImplementedError: If not implemented in the subclass.\n    \"\"\"\n    raise NotImplementedError(\"before_request() must be implemented in the subclass\")\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.prometheus_base.PrometheusMetricsDecorator.consume_time","title":"<code>consume_time(self)</code>","text":"<p>Context manager for tracking the time taken to produce a message.</p> <p>This context manager measures the time taken for produce operations and records this duration as a Prometheus metric.</p> <p>Examples:</p> <p>with self.produce_time():     # Perform produce operations here     produce_message()</p> Source code in <code>kal_utils/monitoring/prometheus/prometheus_base.py</code> <pre><code>@contextmanager\ndef consume_time(self):\n    \"\"\"\n    Context manager for tracking the time taken to produce a message.\n\n    This context manager measures the time taken for produce operations\n    and records this duration as a Prometheus metric.\n\n    Example:\n        with self.produce_time():\n            # Perform produce operations here\n            produce_message()\n    \"\"\"\n    start_time = time.time()\n    try:\n        yield\n    finally:\n        duration = time.time() - start_time\n        self.record_metric('consume_time', duration)\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.prometheus_base.PrometheusMetricsDecorator.db_time","title":"<code>db_time(self)</code>","text":"<p>Context manager for tracking DB operation time.</p> <p>This context manager measures the time taken for database operations and records this duration as a Prometheus metric.</p> <p>Examples:</p> <p>with self.db_time():     # Perform database operations here     result = perform_database_query()</p> Source code in <code>kal_utils/monitoring/prometheus/prometheus_base.py</code> <pre><code>@contextmanager\ndef db_time(self):\n    \"\"\"\n    Context manager for tracking DB operation time.\n\n    This context manager measures the time taken for database operations\n    and records this duration as a Prometheus metric.\n\n    Example:\n        with self.db_time():\n            # Perform database operations here\n            result = perform_database_query()\n    \"\"\"\n    start_time = time.time()\n    try:\n        yield\n    finally:\n        duration = time.time() - start_time\n        self.record_metric('db_time', duration)\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.prometheus_base.PrometheusMetricsDecorator.handle_exception","title":"<code>handle_exception(self, name, exc_type, exc_val)</code>","text":"<p>Handle exceptions in context managers if needed.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the metric.</p> required <code>exc_type</code> <code>type</code> <p>The type of exception.</p> required <code>exc_val</code> <code>Exception</code> <p>The exception value.</p> required Source code in <code>kal_utils/monitoring/prometheus/prometheus_base.py</code> <pre><code>def handle_exception(self, name: str, exc_type: type, exc_val: Exception):\n    \"\"\"\n    Handle exceptions in context managers if needed.\n\n    Args:\n        name (str): The name of the metric.\n        exc_type (type): The type of exception.\n        exc_val (Exception): The exception value.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.prometheus_base.PrometheusMetricsDecorator.instrument","title":"<code>instrument(self)</code>","text":"<p>Decorator to instrument FastAPI route handlers.</p> <p>This method returns a decorator that wraps route handlers to execute before_request() and after_request() methods around each request.</p> <p>Returns:</p> Type Description <code>Callable</code> <p>A decorator function.</p> Source code in <code>kal_utils/monitoring/prometheus/prometheus_base.py</code> <pre><code>def instrument(self) -&gt; Callable:\n    \"\"\"\n    Decorator to instrument FastAPI route handlers.\n\n    This method returns a decorator that wraps route handlers to execute\n    before_request() and after_request() methods around each request.\n\n    Returns:\n        Callable: A decorator function.\n    \"\"\"\n    def decorator(func: Callable) -&gt; Callable:\n        @wraps(func)\n        async def wrapper(request: Request, *args: Any, **kwargs: Any) -&gt; Any:\n            self.before_request(request)\n            response = await func(request, *args, **kwargs)\n            self.after_request(request, response)\n            return response\n        return wrapper\n    return decorator\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.prometheus_base.PrometheusMetricsDecorator.print_time","title":"<code>print_time(self)</code>","text":"<p>Context manager for tracking print operation time.</p> <p>This context manager measures the time taken for print operations or similar tasks and records this duration as a Prometheus metric.</p> <p>Examples:</p> <p>with self.print_time():     # Perform print operations here     print(\"Logging some information...\")</p> Source code in <code>kal_utils/monitoring/prometheus/prometheus_base.py</code> <pre><code>@contextmanager\ndef print_time(self):\n    \"\"\"\n    Context manager for tracking print operation time.\n\n    This context manager measures the time taken for print operations\n    or similar tasks and records this duration as a Prometheus metric.\n\n    Example:\n        with self.print_time():\n            # Perform print operations here\n            print(\"Logging some information...\")\n    \"\"\"\n    start_time = time.time()\n    try:\n        yield\n    finally:\n        duration = time.time() - start_time\n        self.record_metric('print_time', duration)\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.prometheus_base.PrometheusMetricsDecorator.produce_time","title":"<code>produce_time(self)</code>","text":"<p>Context manager for tracking the time taken to produce a message.</p> <p>This context manager measures the time taken for produce operations and records this duration as a Prometheus metric.</p> <p>Examples:</p> <p>with self.produce_time():     # Perform produce operations here     produce_message()</p> Source code in <code>kal_utils/monitoring/prometheus/prometheus_base.py</code> <pre><code>@contextmanager\ndef produce_time(self):\n    \"\"\"\n    Context manager for tracking the time taken to produce a message.\n\n    This context manager measures the time taken for produce operations\n    and records this duration as a Prometheus metric.\n\n    Example:\n        with self.produce_time():\n            # Perform produce operations here\n            produce_message()\n    \"\"\"\n    start_time = time.time()\n    try:\n        yield\n    finally:\n        duration = time.time() - start_time\n        self.record_metric('produce_time', duration)\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.prometheus_base.PrometheusMetricsDecorator.record_metric","title":"<code>record_metric(self, name, duration)</code>","text":"<p>Record the metric with the given name and duration.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the metric.</p> required <code>duration</code> <code>float</code> <p>The duration of the operation.</p> required Source code in <code>kal_utils/monitoring/prometheus/prometheus_base.py</code> <pre><code>def record_metric(self, name: str, duration: float):\n    \"\"\"\n    Record the metric with the given name and duration.\n\n    Args:\n        name (str): The name of the metric.\n        duration (float): The duration of the operation.\n    \"\"\"\n    if name in self.metrics:\n        self.metrics[name].observe(duration)\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.prometheus_base.PrometheusMetricsDecorator.setup_metrics","title":"<code>setup_metrics(self)</code>","text":"<p>Abstract method to set up Prometheus metrics.</p> <p>Implement this method in your subclass to initialize all the Prometheus metrics you want to track (e.g., Counters, Gauges, Histograms).</p> <p>Exceptions:</p> Type Description <code>NotImplementedError</code> <p>If not implemented in the subclass.</p> Source code in <code>kal_utils/monitoring/prometheus/prometheus_base.py</code> <pre><code>@abstractmethod\ndef setup_metrics(self):\n    \"\"\"\n    Abstract method to set up Prometheus metrics.\n\n    Implement this method in your subclass to initialize all the\n    Prometheus metrics you want to track (e.g., Counters, Gauges, Histograms).\n\n    Raises:\n        NotImplementedError: If not implemented in the subclass.\n    \"\"\"\n    raise NotImplementedError(\"setup_metrics() must be implemented in the subclass\")\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.prometheus_base.PrometheusMetricsDecorator.update_metrics","title":"<code>update_metrics(self, request, response)</code>","text":"<p>Abstract method to be called after each request is processed.</p> <p>Implement this method in your subclass to perform any post-request actions, such as recording response times or updating response status metrics.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>The FastAPI Request object.</p> required <code>response</code> <code>Any</code> <p>The response returned by the route handler.</p> required <p>Exceptions:</p> Type Description <code>NotImplementedError</code> <p>If not implemented in the subclass.</p> Source code in <code>kal_utils/monitoring/prometheus/prometheus_base.py</code> <pre><code>@abstractmethod\ndef update_metrics(self, request: Request, response: Any):\n    \"\"\"\n    Abstract method to be called after each request is processed.\n\n    Implement this method in your subclass to perform any post-request\n    actions, such as recording response times or updating response status metrics.\n\n    Args:\n        request (Request): The FastAPI Request object.\n        response (Any): The response returned by the route handler.\n\n    Raises:\n        NotImplementedError: If not implemented in the subclass.\n    \"\"\"\n    raise NotImplementedError(\"after_request() must be implemented in the subclass\")\n</code></pre>"},{"location":"monitoring/#locationrequestcounter","title":"LocationRequestCounter","text":"<p>A class to monitor HTTP request metrics based on request locations using Prometheus.</p> <p>Attributes:</p> Name Type Description <code>location_requests</code> <code>Counter</code> <p>A Prometheus counter that tracks the total number of requests received from different locations, labeled by latitude and longitude.</p> Source code in <code>kal_utils/monitoring/prometheus/locationRequestCounter.py</code> <pre><code>class LocationRequestCounter(PrometheusMetricsDecorator):\n    \"\"\"\n    A class to monitor HTTP request metrics based on request locations using Prometheus.\n\n    Attributes:\n        location_requests (Counter): A Prometheus counter that tracks the total number of requests\n            received from different locations, labeled by latitude and longitude.\n    \"\"\"\n\n    def __init__(self, app):\n        \"\"\"\n        Initialize the LocationRequestCounter class.\n\n        Args:\n            app: The FastAPI application instance.\n        \"\"\"\n        self.location_requests = None\n        self.setup_metrics()\n\n    def setup_metrics(self):\n        \"\"\"\n        Initialize Prometheus metrics for tracking request locations.\n        \"\"\"\n        if 'location_requests' not in REGISTRY._names_to_collectors:\n            self.location_requests = Counter(\n                'location_requests',\n                'Total number of requests received by location (latitude, longitude)',\n                ['latitude', 'longitude']\n            )\n        else:\n            self.location_requests = REGISTRY._names_to_collectors['location_requests']\n\n    def before_request(self, request: Request):\n        \"\"\"\n        This method can be used to perform actions before processing the request.\n        Currently, no actions are performed here.\n        \"\"\"\n\n    def after_request(self, request: Request, response: Any):\n        \"\"\"\n        Update metrics after processing each request.\n\n        Args:\n            request (Request): The incoming HTTP request object.\n            response (Any): The HTTP response object.\n        \"\"\"\n        # Extract client IP address\n        client_ip = request.client.host\n\n        # Get location data\n        latitude, longitude = get_location_from_ip(client_ip)\n\n        # Increment the location-based counter\n        self.location_requests.labels(latitude=str(latitude), longitude=str(longitude)).inc()\n\n    def update_metrics(self, request: Request, response: Any):\n        pass\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.locationRequestCounter.LocationRequestCounter.__init__","title":"<code>__init__(self, app)</code>  <code>special</code>","text":"<p>Initialize the LocationRequestCounter class.</p> <p>Parameters:</p> Name Type Description Default <code>app</code> <p>The FastAPI application instance.</p> required Source code in <code>kal_utils/monitoring/prometheus/locationRequestCounter.py</code> <pre><code>def __init__(self, app):\n    \"\"\"\n    Initialize the LocationRequestCounter class.\n\n    Args:\n        app: The FastAPI application instance.\n    \"\"\"\n    self.location_requests = None\n    self.setup_metrics()\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.locationRequestCounter.LocationRequestCounter.after_request","title":"<code>after_request(self, request, response)</code>","text":"<p>Update metrics after processing each request.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>The incoming HTTP request object.</p> required <code>response</code> <code>Any</code> <p>The HTTP response object.</p> required Source code in <code>kal_utils/monitoring/prometheus/locationRequestCounter.py</code> <pre><code>def after_request(self, request: Request, response: Any):\n    \"\"\"\n    Update metrics after processing each request.\n\n    Args:\n        request (Request): The incoming HTTP request object.\n        response (Any): The HTTP response object.\n    \"\"\"\n    # Extract client IP address\n    client_ip = request.client.host\n\n    # Get location data\n    latitude, longitude = get_location_from_ip(client_ip)\n\n    # Increment the location-based counter\n    self.location_requests.labels(latitude=str(latitude), longitude=str(longitude)).inc()\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.locationRequestCounter.LocationRequestCounter.before_request","title":"<code>before_request(self, request)</code>","text":"<p>This method can be used to perform actions before processing the request. Currently, no actions are performed here.</p> Source code in <code>kal_utils/monitoring/prometheus/locationRequestCounter.py</code> <pre><code>def before_request(self, request: Request):\n    \"\"\"\n    This method can be used to perform actions before processing the request.\n    Currently, no actions are performed here.\n    \"\"\"\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.locationRequestCounter.LocationRequestCounter.setup_metrics","title":"<code>setup_metrics(self)</code>","text":"<p>Initialize Prometheus metrics for tracking request locations.</p> Source code in <code>kal_utils/monitoring/prometheus/locationRequestCounter.py</code> <pre><code>def setup_metrics(self):\n    \"\"\"\n    Initialize Prometheus metrics for tracking request locations.\n    \"\"\"\n    if 'location_requests' not in REGISTRY._names_to_collectors:\n        self.location_requests = Counter(\n            'location_requests',\n            'Total number of requests received by location (latitude, longitude)',\n            ['latitude', 'longitude']\n        )\n    else:\n        self.location_requests = REGISTRY._names_to_collectors['location_requests']\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.locationRequestCounter.LocationRequestCounter.update_metrics","title":"<code>update_metrics(self, request, response)</code>","text":"<p>Abstract method to be called after each request is processed.</p> <p>Implement this method in your subclass to perform any post-request actions, such as recording response times or updating response status metrics.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>The FastAPI Request object.</p> required <code>response</code> <code>Any</code> <p>The response returned by the route handler.</p> required <p>Exceptions:</p> Type Description <code>NotImplementedError</code> <p>If not implemented in the subclass.</p> Source code in <code>kal_utils/monitoring/prometheus/locationRequestCounter.py</code> <pre><code>def update_metrics(self, request: Request, response: Any):\n    pass\n</code></pre>"},{"location":"monitoring/#requestcounter","title":"RequestCounter","text":"<p>A class to monitor HTTP request metrics using Prometheus.</p> <p>Attributes:</p> Name Type Description <code>total_requests</code> <code>Counter</code> <p>A Prometheus counter that tracks the total number of requests received, labeled by HTTP status code.</p> Source code in <code>kal_utils/monitoring/prometheus/requestMetrics.py</code> <pre><code>class RequestCounter(PrometheusMetricsDecorator):\n    \"\"\"\n    A class to monitor HTTP request metrics using Prometheus.\n\n    Attributes:\n        total_requests (Counter): A Prometheus counter that tracks the total number of requests\n            received, labeled by HTTP status code.\n    \"\"\"\n\n    def __init__(self, app):\n        \"\"\"\n        Initialize the RequestCounter class.\n\n        Args:\n            app: The FastAPI application instance. This parameter is required for initializing\n                 the Prometheus metrics and integrating them with the FastAPI application.\n        \"\"\"\n        self.total_requests = None\n        self.setup_metrics()\n\n    def setup_metrics(self):\n        \"\"\"\n        Initialize Prometheus metrics for tracking request metrics.\n\n        This method sets up:\n            - `total_requests`: A Prometheus Counter to track the number of requests received,\n              with labels for HTTP status codes. If the counter already exists in the Prometheus\n              registry, it will reuse the existing one.\n        \"\"\"\n        if 'total_requests' not in REGISTRY._names_to_collectors:\n            self.total_requests = Counter(\n                'total_requests',\n                'Total number of requests received by status code',\n                ['status_code', 'method', 'route']\n            )\n        else:\n            self.total_requests = REGISTRY._names_to_collectors['total_requests']\n\n    def before_request(self, request: Request):\n        \"\"\"\n        Args:\n            request (Request): The incoming HTTP request object. This method does not currently\n                               perform any actions.\n        \"\"\"\n\n    def after_request(self, request: Request, response: Any):\n        \"\"\"\n        Update metrics after processing each request.\n\n        Args:\n            request (Request): The incoming HTTP request object.\n            response (Any): The HTTP response object.\n\n        Actions:\n            - Increment the `total_requests` counter, labeled by the status code of the response.\n        \"\"\"\n        # Determine the status code and increment the corresponding counter\n        status_code = response.status_code\n        route_name = request.url.path\n        self.total_requests.labels(status_code=str(status_code), method=request.method, route=route_name).inc()\n\n    def update_metrics(self, request: Request, response: Any):\n        pass\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.requestMetrics.RequestCounter.__init__","title":"<code>__init__(self, app)</code>  <code>special</code>","text":"<p>Initialize the RequestCounter class.</p> <p>Parameters:</p> Name Type Description Default <code>app</code> <p>The FastAPI application instance. This parameter is required for initializing  the Prometheus metrics and integrating them with the FastAPI application.</p> required Source code in <code>kal_utils/monitoring/prometheus/requestMetrics.py</code> <pre><code>def __init__(self, app):\n    \"\"\"\n    Initialize the RequestCounter class.\n\n    Args:\n        app: The FastAPI application instance. This parameter is required for initializing\n             the Prometheus metrics and integrating them with the FastAPI application.\n    \"\"\"\n    self.total_requests = None\n    self.setup_metrics()\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.requestMetrics.RequestCounter.after_request","title":"<code>after_request(self, request, response)</code>","text":"<p>Update metrics after processing each request.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>The incoming HTTP request object.</p> required <code>response</code> <code>Any</code> <p>The HTTP response object.</p> required <p>Actions</p> <ul> <li>Increment the <code>total_requests</code> counter, labeled by the status code of the response.</li> </ul> Source code in <code>kal_utils/monitoring/prometheus/requestMetrics.py</code> <pre><code>def after_request(self, request: Request, response: Any):\n    \"\"\"\n    Update metrics after processing each request.\n\n    Args:\n        request (Request): The incoming HTTP request object.\n        response (Any): The HTTP response object.\n\n    Actions:\n        - Increment the `total_requests` counter, labeled by the status code of the response.\n    \"\"\"\n    # Determine the status code and increment the corresponding counter\n    status_code = response.status_code\n    route_name = request.url.path\n    self.total_requests.labels(status_code=str(status_code), method=request.method, route=route_name).inc()\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.requestMetrics.RequestCounter.before_request","title":"<code>before_request(self, request)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>The incoming HTTP request object. This method does not currently                perform any actions.</p> required Source code in <code>kal_utils/monitoring/prometheus/requestMetrics.py</code> <pre><code>def before_request(self, request: Request):\n    \"\"\"\n    Args:\n        request (Request): The incoming HTTP request object. This method does not currently\n                           perform any actions.\n    \"\"\"\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.requestMetrics.RequestCounter.setup_metrics","title":"<code>setup_metrics(self)</code>","text":"<p>Initialize Prometheus metrics for tracking request metrics.</p> <p>This method sets up:     - <code>total_requests</code>: A Prometheus Counter to track the number of requests received,       with labels for HTTP status codes. If the counter already exists in the Prometheus       registry, it will reuse the existing one.</p> Source code in <code>kal_utils/monitoring/prometheus/requestMetrics.py</code> <pre><code>def setup_metrics(self):\n    \"\"\"\n    Initialize Prometheus metrics for tracking request metrics.\n\n    This method sets up:\n        - `total_requests`: A Prometheus Counter to track the number of requests received,\n          with labels for HTTP status codes. If the counter already exists in the Prometheus\n          registry, it will reuse the existing one.\n    \"\"\"\n    if 'total_requests' not in REGISTRY._names_to_collectors:\n        self.total_requests = Counter(\n            'total_requests',\n            'Total number of requests received by status code',\n            ['status_code', 'method', 'route']\n        )\n    else:\n        self.total_requests = REGISTRY._names_to_collectors['total_requests']\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.requestMetrics.RequestCounter.update_metrics","title":"<code>update_metrics(self, request, response)</code>","text":"<p>Abstract method to be called after each request is processed.</p> <p>Implement this method in your subclass to perform any post-request actions, such as recording response times or updating response status metrics.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>The FastAPI Request object.</p> required <code>response</code> <code>Any</code> <p>The response returned by the route handler.</p> required <p>Exceptions:</p> Type Description <code>NotImplementedError</code> <p>If not implemented in the subclass.</p> Source code in <code>kal_utils/monitoring/prometheus/requestMetrics.py</code> <pre><code>def update_metrics(self, request: Request, response: Any):\n    pass\n</code></pre>"},{"location":"monitoring/#servererrormetrics","title":"ServerErrorMetrics","text":"<p>A class to monitor server errors using Prometheus.</p> <p>Attributes:</p> Name Type Description <code>server_errors</code> <code>Counter</code> <p>A Prometheus counter to track the number of server errors (5xx status codes).</p> Source code in <code>kal_utils/monitoring/prometheus/requestMetrics.py</code> <pre><code>class ServerErrorMetrics(PrometheusMetricsDecorator):\n    \"\"\"\n    A class to monitor server errors using Prometheus.\n\n    Attributes:\n        server_errors (Counter): A Prometheus counter to track the number of server errors (5xx status codes).\n    \"\"\"\n\n    def __init__(self, app):\n        \"\"\"\n        Initialize ServerErrorMetrics class.\n\n        Args:\n            app: The FastAPI application instance.\n        \"\"\"\n        self.server_errors = None\n        self.setup_metrics()\n\n    def setup_metrics(self):\n        \"\"\"\n        Initialize Prometheus metrics for tracking server errors.\n\n        Sets up:\n            - server_errors: A counter to track the number of server errors (5xx status codes).\n        \"\"\"\n        # Check if the server_errors counter is already in the registry\n        if 'server_errors' not in REGISTRY._names_to_collectors:\n            self.server_errors = Counter('server_errors',\n                                         'Total number of server errors (5xx status codes)')\n        else:\n            self.server_errors = REGISTRY._names_to_collectors['server_errors']\n\n    def before_request(self, request: Request):\n        \"\"\"\n        Prepare to track request latency.\n\n        Args:\n            request (Request): The incoming HTTP request object.\n\n        Actions:\n            - Record the start time of the request to measure latency.\n        \"\"\"\n        pass\n\n    def after_request(self, request: Request, response: Any):\n        \"\"\"\n        Update metrics after processing each request.\n\n        Args:\n            request (Request): The incoming HTTP request object.\n            response (Any): The HTTP response object.\n\n        Actions:\n            - Increment the server_errors counter for server errors (5xx status codes).\n        \"\"\"\n        # Increment the server_errors counter for 5xx status codes\n        if 500 &lt;= response.status_code &lt; 600:\n            self.server_errors.inc()\n\n    def update_metrics(self, request: Request, response: Any):\n        pass\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.requestMetrics.ServerErrorMetrics.__init__","title":"<code>__init__(self, app)</code>  <code>special</code>","text":"<p>Initialize ServerErrorMetrics class.</p> <p>Parameters:</p> Name Type Description Default <code>app</code> <p>The FastAPI application instance.</p> required Source code in <code>kal_utils/monitoring/prometheus/requestMetrics.py</code> <pre><code>def __init__(self, app):\n    \"\"\"\n    Initialize ServerErrorMetrics class.\n\n    Args:\n        app: The FastAPI application instance.\n    \"\"\"\n    self.server_errors = None\n    self.setup_metrics()\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.requestMetrics.ServerErrorMetrics.after_request","title":"<code>after_request(self, request, response)</code>","text":"<p>Update metrics after processing each request.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>The incoming HTTP request object.</p> required <code>response</code> <code>Any</code> <p>The HTTP response object.</p> required <p>Actions</p> <ul> <li>Increment the server_errors counter for server errors (5xx status codes).</li> </ul> Source code in <code>kal_utils/monitoring/prometheus/requestMetrics.py</code> <pre><code>def after_request(self, request: Request, response: Any):\n    \"\"\"\n    Update metrics after processing each request.\n\n    Args:\n        request (Request): The incoming HTTP request object.\n        response (Any): The HTTP response object.\n\n    Actions:\n        - Increment the server_errors counter for server errors (5xx status codes).\n    \"\"\"\n    # Increment the server_errors counter for 5xx status codes\n    if 500 &lt;= response.status_code &lt; 600:\n        self.server_errors.inc()\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.requestMetrics.ServerErrorMetrics.before_request","title":"<code>before_request(self, request)</code>","text":"<p>Prepare to track request latency.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>The incoming HTTP request object.</p> required <p>Actions</p> <ul> <li>Record the start time of the request to measure latency.</li> </ul> Source code in <code>kal_utils/monitoring/prometheus/requestMetrics.py</code> <pre><code>def before_request(self, request: Request):\n    \"\"\"\n    Prepare to track request latency.\n\n    Args:\n        request (Request): The incoming HTTP request object.\n\n    Actions:\n        - Record the start time of the request to measure latency.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.requestMetrics.ServerErrorMetrics.setup_metrics","title":"<code>setup_metrics(self)</code>","text":"<p>Initialize Prometheus metrics for tracking server errors.</p> <p>Sets up:     - server_errors: A counter to track the number of server errors (5xx status codes).</p> Source code in <code>kal_utils/monitoring/prometheus/requestMetrics.py</code> <pre><code>def setup_metrics(self):\n    \"\"\"\n    Initialize Prometheus metrics for tracking server errors.\n\n    Sets up:\n        - server_errors: A counter to track the number of server errors (5xx status codes).\n    \"\"\"\n    # Check if the server_errors counter is already in the registry\n    if 'server_errors' not in REGISTRY._names_to_collectors:\n        self.server_errors = Counter('server_errors',\n                                     'Total number of server errors (5xx status codes)')\n    else:\n        self.server_errors = REGISTRY._names_to_collectors['server_errors']\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.requestMetrics.ServerErrorMetrics.update_metrics","title":"<code>update_metrics(self, request, response)</code>","text":"<p>Abstract method to be called after each request is processed.</p> <p>Implement this method in your subclass to perform any post-request actions, such as recording response times or updating response status metrics.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>The FastAPI Request object.</p> required <code>response</code> <code>Any</code> <p>The response returned by the route handler.</p> required <p>Exceptions:</p> Type Description <code>NotImplementedError</code> <p>If not implemented in the subclass.</p> Source code in <code>kal_utils/monitoring/prometheus/requestMetrics.py</code> <pre><code>def update_metrics(self, request: Request, response: Any):\n    pass\n</code></pre>"},{"location":"monitoring/#requesthist","title":"RequestHist","text":"<p>A class to monitor request metrics using Prometheus.</p> <p>Attributes:</p> Name Type Description <code>request_latency</code> <code>Histogram</code> <p>A Prometheus histogram to track the latency of requests in seconds.</p> Source code in <code>kal_utils/monitoring/prometheus/requestMetrics.py</code> <pre><code>class RequestHist(PrometheusMetricsDecorator):\n    \"\"\"\n    A class to monitor request metrics using Prometheus.\n\n    Attributes:\n        request_latency (Histogram): A Prometheus histogram to track the latency of requests in seconds.\n    \"\"\"\n\n    def __init__(self, app):\n        \"\"\"\n        Initialize RequestHist class.\n\n        Args:\n            app: The FastAPI application instance.\n        \"\"\"\n        self.request_latency = None\n        self.request_start_time = None\n        self.setup_metrics()\n\n    def setup_metrics(self):\n        \"\"\"\n        Initialize Prometheus metrics for tracking request metrics.\n\n        Sets up:\n            - request_latency: A histogram to measure the latency of requests in seconds.\n        \"\"\"\n        if 'request_latency_seconds' not in REGISTRY._names_to_collectors:\n            self.request_latency = Histogram('request_latency_seconds',\n                                             'Request latency in seconds',\n                                             ['status_code', 'method', 'route'])\n        else:\n            self.request_latency = REGISTRY._names_to_collectors['request_latency_seconds']\n\n    def before_request(self, request: Request):\n        \"\"\"\n        Prepare to track request latency.\n\n        Args:\n            request (Request): The incoming HTTP request object.\n\n        Actions:\n            - Record the start time of the request to measure latency.\n        \"\"\"\n        self.request_start_time = time.time()  # Store the start time\n\n    def after_request(self, request: Request, response: Any):\n        \"\"\"\n        Update metrics after processing each request.\n\n        Args:\n            request (Request): The incoming HTTP request object.\n            response (Any): The HTTP response object.\n\n        Actions:\n            - Calculate and record the request latency in the request_latency histogram.\n        \"\"\"\n\n        # Measure and record the request latency\n        status_code = response.status_code\n        route_name = request.url.path\n        latency = time.time() - self.request_start_time\n        self.request_latency.labels(status_code=str(status_code), method=request.method, route=route_name).observe(latency)\n\n    def update_metrics(self, request: Request, response: Any):\n        pass\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.requestMetrics.RequestHist.__init__","title":"<code>__init__(self, app)</code>  <code>special</code>","text":"<p>Initialize RequestHist class.</p> <p>Parameters:</p> Name Type Description Default <code>app</code> <p>The FastAPI application instance.</p> required Source code in <code>kal_utils/monitoring/prometheus/requestMetrics.py</code> <pre><code>def __init__(self, app):\n    \"\"\"\n    Initialize RequestHist class.\n\n    Args:\n        app: The FastAPI application instance.\n    \"\"\"\n    self.request_latency = None\n    self.request_start_time = None\n    self.setup_metrics()\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.requestMetrics.RequestHist.after_request","title":"<code>after_request(self, request, response)</code>","text":"<p>Update metrics after processing each request.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>The incoming HTTP request object.</p> required <code>response</code> <code>Any</code> <p>The HTTP response object.</p> required <p>Actions</p> <ul> <li>Calculate and record the request latency in the request_latency histogram.</li> </ul> Source code in <code>kal_utils/monitoring/prometheus/requestMetrics.py</code> <pre><code>def after_request(self, request: Request, response: Any):\n    \"\"\"\n    Update metrics after processing each request.\n\n    Args:\n        request (Request): The incoming HTTP request object.\n        response (Any): The HTTP response object.\n\n    Actions:\n        - Calculate and record the request latency in the request_latency histogram.\n    \"\"\"\n\n    # Measure and record the request latency\n    status_code = response.status_code\n    route_name = request.url.path\n    latency = time.time() - self.request_start_time\n    self.request_latency.labels(status_code=str(status_code), method=request.method, route=route_name).observe(latency)\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.requestMetrics.RequestHist.before_request","title":"<code>before_request(self, request)</code>","text":"<p>Prepare to track request latency.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>The incoming HTTP request object.</p> required <p>Actions</p> <ul> <li>Record the start time of the request to measure latency.</li> </ul> Source code in <code>kal_utils/monitoring/prometheus/requestMetrics.py</code> <pre><code>def before_request(self, request: Request):\n    \"\"\"\n    Prepare to track request latency.\n\n    Args:\n        request (Request): The incoming HTTP request object.\n\n    Actions:\n        - Record the start time of the request to measure latency.\n    \"\"\"\n    self.request_start_time = time.time()  # Store the start time\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.requestMetrics.RequestHist.setup_metrics","title":"<code>setup_metrics(self)</code>","text":"<p>Initialize Prometheus metrics for tracking request metrics.</p> <p>Sets up:     - request_latency: A histogram to measure the latency of requests in seconds.</p> Source code in <code>kal_utils/monitoring/prometheus/requestMetrics.py</code> <pre><code>def setup_metrics(self):\n    \"\"\"\n    Initialize Prometheus metrics for tracking request metrics.\n\n    Sets up:\n        - request_latency: A histogram to measure the latency of requests in seconds.\n    \"\"\"\n    if 'request_latency_seconds' not in REGISTRY._names_to_collectors:\n        self.request_latency = Histogram('request_latency_seconds',\n                                         'Request latency in seconds',\n                                         ['status_code', 'method', 'route'])\n    else:\n        self.request_latency = REGISTRY._names_to_collectors['request_latency_seconds']\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.requestMetrics.RequestHist.update_metrics","title":"<code>update_metrics(self, request, response)</code>","text":"<p>Abstract method to be called after each request is processed.</p> <p>Implement this method in your subclass to perform any post-request actions, such as recording response times or updating response status metrics.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>The FastAPI Request object.</p> required <code>response</code> <code>Any</code> <p>The response returned by the route handler.</p> required <p>Exceptions:</p> Type Description <code>NotImplementedError</code> <p>If not implemented in the subclass.</p> Source code in <code>kal_utils/monitoring/prometheus/requestMetrics.py</code> <pre><code>def update_metrics(self, request: Request, response: Any):\n    pass\n</code></pre>"},{"location":"monitoring/#cpuusagemonitor","title":"CpuUsageMonitor","text":"<p>A class to monitor CPU usage metrics using Prometheus.</p> <p>Attributes:</p> Name Type Description <code>cpu_usage</code> <code>Gauge</code> <p>A Prometheus gauge that tracks the current CPU usage percentage.</p> Source code in <code>kal_utils/monitoring/prometheus/systemMetrics.py</code> <pre><code>class CpuUsageMonitor(PrometheusMetricsDecorator):\n    \"\"\"\n    A class to monitor CPU usage metrics using Prometheus.\n\n    Attributes:\n        cpu_usage (Gauge): A Prometheus gauge that tracks the current CPU usage percentage.\n    \"\"\"\n\n    def __init__(self, app):\n        \"\"\"\n        Initialize the CpuUsageMonitor class.\n\n        Args:\n            app: The FastAPI application instance. This parameter is required for initializing\n                 the Prometheus metrics and integrating them with the FastAPI application.\n        \"\"\"\n        self.cpu_usage = None\n        self.setup_metrics()\n\n    def setup_metrics(self):\n        \"\"\"\n        Initialize Prometheus metrics for tracking CPU usage.\n\n        This method sets up:\n            - cpu_usage: A Prometheus Gauge to track the current CPU usage percentage.\n        \"\"\"\n        if 'cpu_usage_percentage' not in REGISTRY._names_to_collectors:\n            self.cpu_usage = Gauge(\n                'cpu_usage_percentage',\n                'Current CPU usage percentage'\n            )\n        else:\n            self.cpu_usage = REGISTRY._names_to_collectors['cpu_usage_percentage']\n\n    def before_request(self, request: Request):\n        \"\"\"\n        Args:\n            request (Request): The incoming HTTP request object. This method does not currently\n                               perform any actions.\n        \"\"\"\n        pass\n\n    def after_request(self, request: Request, response: Any):\n        \"\"\"\n        Update metrics after processing each request.\n\n        Args:\n            request (Request): The incoming HTTP request object.\n            response (Any): The HTTP response object.\n\n        Actions:\n            - Update the cpu_usage gauge with the current CPU usage percentage.\n        \"\"\"\n        pass\n\n    def update_metrics(self, request: Request, response: Any):\n        \"\"\"\n        Update metrics after processing each request.\n\n        Args:\n            request (Request): The incoming HTTP request object.\n            response (Any): The HTTP response object.\n\n        Actions:\n            - Update the cpu_usage gauge with the current CPU usage percentage.\n        \"\"\"\n        # Update the CPU usage gauge\n        cpu_percent = psutil.cpu_percent()\n        self.cpu_usage.set(cpu_percent)\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.systemMetrics.CpuUsageMonitor.__init__","title":"<code>__init__(self, app)</code>  <code>special</code>","text":"<p>Initialize the CpuUsageMonitor class.</p> <p>Parameters:</p> Name Type Description Default <code>app</code> <p>The FastAPI application instance. This parameter is required for initializing  the Prometheus metrics and integrating them with the FastAPI application.</p> required Source code in <code>kal_utils/monitoring/prometheus/systemMetrics.py</code> <pre><code>def __init__(self, app):\n    \"\"\"\n    Initialize the CpuUsageMonitor class.\n\n    Args:\n        app: The FastAPI application instance. This parameter is required for initializing\n             the Prometheus metrics and integrating them with the FastAPI application.\n    \"\"\"\n    self.cpu_usage = None\n    self.setup_metrics()\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.systemMetrics.CpuUsageMonitor.after_request","title":"<code>after_request(self, request, response)</code>","text":"<p>Update metrics after processing each request.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>The incoming HTTP request object.</p> required <code>response</code> <code>Any</code> <p>The HTTP response object.</p> required <p>Actions</p> <ul> <li>Update the cpu_usage gauge with the current CPU usage percentage.</li> </ul> Source code in <code>kal_utils/monitoring/prometheus/systemMetrics.py</code> <pre><code>def after_request(self, request: Request, response: Any):\n    \"\"\"\n    Update metrics after processing each request.\n\n    Args:\n        request (Request): The incoming HTTP request object.\n        response (Any): The HTTP response object.\n\n    Actions:\n        - Update the cpu_usage gauge with the current CPU usage percentage.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.systemMetrics.CpuUsageMonitor.before_request","title":"<code>before_request(self, request)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>The incoming HTTP request object. This method does not currently                perform any actions.</p> required Source code in <code>kal_utils/monitoring/prometheus/systemMetrics.py</code> <pre><code>def before_request(self, request: Request):\n    \"\"\"\n    Args:\n        request (Request): The incoming HTTP request object. This method does not currently\n                           perform any actions.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.systemMetrics.CpuUsageMonitor.setup_metrics","title":"<code>setup_metrics(self)</code>","text":"<p>Initialize Prometheus metrics for tracking CPU usage.</p> <p>This method sets up:     - cpu_usage: A Prometheus Gauge to track the current CPU usage percentage.</p> Source code in <code>kal_utils/monitoring/prometheus/systemMetrics.py</code> <pre><code>def setup_metrics(self):\n    \"\"\"\n    Initialize Prometheus metrics for tracking CPU usage.\n\n    This method sets up:\n        - cpu_usage: A Prometheus Gauge to track the current CPU usage percentage.\n    \"\"\"\n    if 'cpu_usage_percentage' not in REGISTRY._names_to_collectors:\n        self.cpu_usage = Gauge(\n            'cpu_usage_percentage',\n            'Current CPU usage percentage'\n        )\n    else:\n        self.cpu_usage = REGISTRY._names_to_collectors['cpu_usage_percentage']\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.systemMetrics.CpuUsageMonitor.update_metrics","title":"<code>update_metrics(self, request, response)</code>","text":"<p>Update metrics after processing each request.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>The incoming HTTP request object.</p> required <code>response</code> <code>Any</code> <p>The HTTP response object.</p> required <p>Actions</p> <ul> <li>Update the cpu_usage gauge with the current CPU usage percentage.</li> </ul> Source code in <code>kal_utils/monitoring/prometheus/systemMetrics.py</code> <pre><code>def update_metrics(self, request: Request, response: Any):\n    \"\"\"\n    Update metrics after processing each request.\n\n    Args:\n        request (Request): The incoming HTTP request object.\n        response (Any): The HTTP response object.\n\n    Actions:\n        - Update the cpu_usage gauge with the current CPU usage percentage.\n    \"\"\"\n    # Update the CPU usage gauge\n    cpu_percent = psutil.cpu_percent()\n    self.cpu_usage.set(cpu_percent)\n</code></pre>"},{"location":"monitoring/#memoryusagemonitor","title":"MemoryUsageMonitor","text":"<p>A class to monitor memory usage metrics using Prometheus.</p> <p>Attributes:</p> Name Type Description <code>memory_usage</code> <code>Gauge</code> <p>A Prometheus gauge that tracks the current memory usage percentage.</p> Source code in <code>kal_utils/monitoring/prometheus/systemMetrics.py</code> <pre><code>class MemoryUsageMonitor(PrometheusMetricsDecorator):\n    \"\"\"\n    A class to monitor memory usage metrics using Prometheus.\n\n    Attributes:\n        memory_usage (Gauge): A Prometheus gauge that tracks the current memory usage percentage.\n    \"\"\"\n\n    def __init__(self, app):\n        \"\"\"\n        Initialize the MemoryUsageMonitor class.\n\n        Args:\n            app: The FastAPI application instance.\n        \"\"\"\n        self.memory_usage = None\n        self.setup_metrics()\n\n    def setup_metrics(self):\n        \"\"\"\n        Initialize Prometheus metrics for tracking memory usage.\n\n        This method sets up:\n            - memory_usage: A Prometheus Gauge to track the current memory usage percentage.\n        \"\"\"\n        if 'memory_usage_percentage' not in REGISTRY._names_to_collectors:\n            self.memory_usage = Gauge(\n                'memory_usage_percentage',\n                'Current memory usage percentage'\n            )\n        else:\n            self.memory_usage = REGISTRY._names_to_collectors['memory_usage_percentage']\n\n    def before_request(self, request: Request):\n        \"\"\"This method does not currently perform any actions.\"\"\"\n        pass\n\n    def after_request(self, request: Request, response: Any):\n        \"\"\"\n        Update metrics after processing each request.\n\n        Args:\n            request (Request): The incoming HTTP request object.\n            response (Any): The HTTP response object.\n\n        Actions:\n            - Update the memory_usage gauge with the current memory usage percentage.\n        \"\"\"\n\n    def update_metrics(self, request: Request, response: Any):\n        \"\"\"\n        Update metrics after processing each request.\n\n        Args:\n            request (Request): The incoming HTTP request object.\n            response (Any): The HTTP response object.\n\n        Actions:\n            - Update the memory_usage gauge with the current memory usage percentage.\n        \"\"\"\n        memory_info = psutil.virtual_memory()\n        self.memory_usage.set(memory_info.percent)\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.systemMetrics.MemoryUsageMonitor.__init__","title":"<code>__init__(self, app)</code>  <code>special</code>","text":"<p>Initialize the MemoryUsageMonitor class.</p> <p>Parameters:</p> Name Type Description Default <code>app</code> <p>The FastAPI application instance.</p> required Source code in <code>kal_utils/monitoring/prometheus/systemMetrics.py</code> <pre><code>def __init__(self, app):\n    \"\"\"\n    Initialize the MemoryUsageMonitor class.\n\n    Args:\n        app: The FastAPI application instance.\n    \"\"\"\n    self.memory_usage = None\n    self.setup_metrics()\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.systemMetrics.MemoryUsageMonitor.after_request","title":"<code>after_request(self, request, response)</code>","text":"<p>Update metrics after processing each request.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>The incoming HTTP request object.</p> required <code>response</code> <code>Any</code> <p>The HTTP response object.</p> required <p>Actions</p> <ul> <li>Update the memory_usage gauge with the current memory usage percentage.</li> </ul> Source code in <code>kal_utils/monitoring/prometheus/systemMetrics.py</code> <pre><code>def after_request(self, request: Request, response: Any):\n    \"\"\"\n    Update metrics after processing each request.\n\n    Args:\n        request (Request): The incoming HTTP request object.\n        response (Any): The HTTP response object.\n\n    Actions:\n        - Update the memory_usage gauge with the current memory usage percentage.\n    \"\"\"\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.systemMetrics.MemoryUsageMonitor.before_request","title":"<code>before_request(self, request)</code>","text":"<p>This method does not currently perform any actions.</p> Source code in <code>kal_utils/monitoring/prometheus/systemMetrics.py</code> <pre><code>def before_request(self, request: Request):\n    \"\"\"This method does not currently perform any actions.\"\"\"\n    pass\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.systemMetrics.MemoryUsageMonitor.setup_metrics","title":"<code>setup_metrics(self)</code>","text":"<p>Initialize Prometheus metrics for tracking memory usage.</p> <p>This method sets up:     - memory_usage: A Prometheus Gauge to track the current memory usage percentage.</p> Source code in <code>kal_utils/monitoring/prometheus/systemMetrics.py</code> <pre><code>def setup_metrics(self):\n    \"\"\"\n    Initialize Prometheus metrics for tracking memory usage.\n\n    This method sets up:\n        - memory_usage: A Prometheus Gauge to track the current memory usage percentage.\n    \"\"\"\n    if 'memory_usage_percentage' not in REGISTRY._names_to_collectors:\n        self.memory_usage = Gauge(\n            'memory_usage_percentage',\n            'Current memory usage percentage'\n        )\n    else:\n        self.memory_usage = REGISTRY._names_to_collectors['memory_usage_percentage']\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.systemMetrics.MemoryUsageMonitor.update_metrics","title":"<code>update_metrics(self, request, response)</code>","text":"<p>Update metrics after processing each request.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>The incoming HTTP request object.</p> required <code>response</code> <code>Any</code> <p>The HTTP response object.</p> required <p>Actions</p> <ul> <li>Update the memory_usage gauge with the current memory usage percentage.</li> </ul> Source code in <code>kal_utils/monitoring/prometheus/systemMetrics.py</code> <pre><code>def update_metrics(self, request: Request, response: Any):\n    \"\"\"\n    Update metrics after processing each request.\n\n    Args:\n        request (Request): The incoming HTTP request object.\n        response (Any): The HTTP response object.\n\n    Actions:\n        - Update the memory_usage gauge with the current memory usage percentage.\n    \"\"\"\n    memory_info = psutil.virtual_memory()\n    self.memory_usage.set(memory_info.percent)\n</code></pre>"},{"location":"monitoring/#diskusagemonitor","title":"DiskUsageMonitor","text":"<p>A class to monitor disk usage metrics using Prometheus.</p> <p>Attributes:</p> Name Type Description <code>disk_usage</code> <code>Gauge</code> <p>A Prometheus gauge that tracks the current disk usage percentage.</p> Source code in <code>kal_utils/monitoring/prometheus/systemMetrics.py</code> <pre><code>class DiskUsageMonitor(PrometheusMetricsDecorator):\n    \"\"\"\n    A class to monitor disk usage metrics using Prometheus.\n\n    Attributes:\n        disk_usage (Gauge): A Prometheus gauge that tracks the current disk usage percentage.\n    \"\"\"\n\n    def __init__(self, app):\n        \"\"\"\n        Initialize the DiskUsageMonitor class.\n\n        Args:\n            app: The FastAPI application instance.\n        \"\"\"\n        self.disk_usage = None\n        self.setup_metrics()\n\n    def setup_metrics(self):\n        \"\"\"\n        Initialize Prometheus metrics for tracking disk usage.\n\n        This method sets up:\n            - disk_usage: A Prometheus Gauge to track the current disk usage percentage.\n        \"\"\"\n        if 'disk_usage_percentage' not in REGISTRY._names_to_collectors:\n            self.disk_usage = Gauge(\n                'disk_usage_percentage',\n                'Current disk usage percentage'\n            )\n        else:\n            self.disk_usage = REGISTRY._names_to_collectors['disk_usage_percentage']\n\n    def before_request(self, request: Request):\n        \"\"\"This method does not currently perform any actions.\"\"\"\n        pass\n\n    def after_request(self, request: Request, response: Any):\n        \"\"\"\n        Update metrics after processing each request.\n\n        Args:\n            request (Request): The incoming HTTP request object.\n            response (Any): The HTTP response object.\n\n        Actions:\n            - Update the disk_usage gauge with the current disk usage percentage.\n        \"\"\"\n\n    def update_metrics(self, request: Request, response: Any):\n        \"\"\"\n        Update metrics after processing each request.\n\n        Args:\n            request (Request): The incoming HTTP request object.\n            response (Any): The HTTP response object.\n\n        Actions:\n            - Update the disk_usage gauge with the current disk usage percentage.\n        \"\"\"\n        disk_info = psutil.disk_usage('/')\n        self.disk_usage.set(disk_info.percent)\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.systemMetrics.DiskUsageMonitor.__init__","title":"<code>__init__(self, app)</code>  <code>special</code>","text":"<p>Initialize the DiskUsageMonitor class.</p> <p>Parameters:</p> Name Type Description Default <code>app</code> <p>The FastAPI application instance.</p> required Source code in <code>kal_utils/monitoring/prometheus/systemMetrics.py</code> <pre><code>def __init__(self, app):\n    \"\"\"\n    Initialize the DiskUsageMonitor class.\n\n    Args:\n        app: The FastAPI application instance.\n    \"\"\"\n    self.disk_usage = None\n    self.setup_metrics()\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.systemMetrics.DiskUsageMonitor.after_request","title":"<code>after_request(self, request, response)</code>","text":"<p>Update metrics after processing each request.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>The incoming HTTP request object.</p> required <code>response</code> <code>Any</code> <p>The HTTP response object.</p> required <p>Actions</p> <ul> <li>Update the disk_usage gauge with the current disk usage percentage.</li> </ul> Source code in <code>kal_utils/monitoring/prometheus/systemMetrics.py</code> <pre><code>def after_request(self, request: Request, response: Any):\n    \"\"\"\n    Update metrics after processing each request.\n\n    Args:\n        request (Request): The incoming HTTP request object.\n        response (Any): The HTTP response object.\n\n    Actions:\n        - Update the disk_usage gauge with the current disk usage percentage.\n    \"\"\"\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.systemMetrics.DiskUsageMonitor.before_request","title":"<code>before_request(self, request)</code>","text":"<p>This method does not currently perform any actions.</p> Source code in <code>kal_utils/monitoring/prometheus/systemMetrics.py</code> <pre><code>def before_request(self, request: Request):\n    \"\"\"This method does not currently perform any actions.\"\"\"\n    pass\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.systemMetrics.DiskUsageMonitor.setup_metrics","title":"<code>setup_metrics(self)</code>","text":"<p>Initialize Prometheus metrics for tracking disk usage.</p> <p>This method sets up:     - disk_usage: A Prometheus Gauge to track the current disk usage percentage.</p> Source code in <code>kal_utils/monitoring/prometheus/systemMetrics.py</code> <pre><code>def setup_metrics(self):\n    \"\"\"\n    Initialize Prometheus metrics for tracking disk usage.\n\n    This method sets up:\n        - disk_usage: A Prometheus Gauge to track the current disk usage percentage.\n    \"\"\"\n    if 'disk_usage_percentage' not in REGISTRY._names_to_collectors:\n        self.disk_usage = Gauge(\n            'disk_usage_percentage',\n            'Current disk usage percentage'\n        )\n    else:\n        self.disk_usage = REGISTRY._names_to_collectors['disk_usage_percentage']\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.systemMetrics.DiskUsageMonitor.update_metrics","title":"<code>update_metrics(self, request, response)</code>","text":"<p>Update metrics after processing each request.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>The incoming HTTP request object.</p> required <code>response</code> <code>Any</code> <p>The HTTP response object.</p> required <p>Actions</p> <ul> <li>Update the disk_usage gauge with the current disk usage percentage.</li> </ul> Source code in <code>kal_utils/monitoring/prometheus/systemMetrics.py</code> <pre><code>def update_metrics(self, request: Request, response: Any):\n    \"\"\"\n    Update metrics after processing each request.\n\n    Args:\n        request (Request): The incoming HTTP request object.\n        response (Any): The HTTP response object.\n\n    Actions:\n        - Update the disk_usage gauge with the current disk usage percentage.\n    \"\"\"\n    disk_info = psutil.disk_usage('/')\n    self.disk_usage.set(disk_info.percent)\n</code></pre>"},{"location":"monitoring/#networkusagemonitor","title":"NetworkUsageMonitor","text":"<p>A class to monitor network usage metrics using Prometheus.</p> <p>Attributes:</p> Name Type Description <code>network_bytes_sent</code> <code>Gauge</code> <p>A Prometheus gauge that tracks the number of bytes sent.</p> <code>network_bytes_received</code> <code>Gauge</code> <p>A Prometheus gauge that tracks the number of bytes received.</p> Source code in <code>kal_utils/monitoring/prometheus/systemMetrics.py</code> <pre><code>class NetworkUsageMonitor(PrometheusMetricsDecorator):\n    \"\"\"\n    A class to monitor network usage metrics using Prometheus.\n\n    Attributes:\n        network_bytes_sent (Gauge): A Prometheus gauge that tracks the number of bytes sent.\n        network_bytes_received (Gauge): A Prometheus gauge that tracks the number of bytes received.\n    \"\"\"\n\n    def __init__(self, app):\n        \"\"\"\n        Initialize the NetworkUsageMonitor class.\n\n        Args:\n            app: The FastAPI application instance. This parameter is required for initializing\n                 the Prometheus metrics and integrating them with the FastAPI application.\n        \"\"\"\n        self.network_bytes_sent = None\n        self.network_bytes_received = None\n        self.setup_metrics()\n\n    def setup_metrics(self):\n        \"\"\"\n        Initialize Prometheus metrics for tracking network usage.\n\n        This method sets up:\n            - network_bytes_sent: A Prometheus Gauge to track the number of bytes sent.\n            - network_bytes_received: A Prometheus Gauge to track the number of bytes received.\n        \"\"\"\n        if 'network_bytes_sent' not in REGISTRY._names_to_collectors:\n            self.network_bytes_sent = Gauge(\n                'network_bytes_sent',\n                'Total number of bytes sent'\n            )\n        else:\n            self.network_bytes_sent = REGISTRY._names_to_collectors['network_bytes_sent']\n\n        if 'network_bytes_received' not in REGISTRY._names_to_collectors:\n            self.network_bytes_received = Gauge(\n                'network_bytes_received',\n                'Total number of bytes received'\n            )\n        else:\n            self.network_bytes_received = REGISTRY._names_to_collectors['network_bytes_received']\n\n    def before_request(self, request: Request):\n        \"\"\"This method does not currently perform any actions.\"\"\"\n        pass\n\n    def after_request(self, request: Request, response: Any):\n        \"\"\"\n        Update metrics after processing each request.\n\n        Args:\n            request (Request): The incoming HTTP request object.\n            response (Any): The HTTP response object.\n\n        Actions:\n            - Update the network_bytes_sent and network_bytes_received gauges with the current\n              network usage statistics.\n        \"\"\"\n\n    def update_metrics(self, request: Request, response: Any):\n        \"\"\"\n        Update metrics after processing each request.\n\n        Args:\n            request (Request): The incoming HTTP request object.\n            response (Any): The HTTP response object.\n\n        Actions:\n            - Update the network_bytes_sent and network_bytes_received gauges with the current\n              network usage statistics.\n        \"\"\"\n        net_io = psutil.net_io_counters()\n        self.network_bytes_sent.set(net_io.bytes_sent)\n        self.network_bytes_received.set(net_io.bytes_recv)\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.systemMetrics.NetworkUsageMonitor.__init__","title":"<code>__init__(self, app)</code>  <code>special</code>","text":"<p>Initialize the NetworkUsageMonitor class.</p> <p>Parameters:</p> Name Type Description Default <code>app</code> <p>The FastAPI application instance. This parameter is required for initializing  the Prometheus metrics and integrating them with the FastAPI application.</p> required Source code in <code>kal_utils/monitoring/prometheus/systemMetrics.py</code> <pre><code>def __init__(self, app):\n    \"\"\"\n    Initialize the NetworkUsageMonitor class.\n\n    Args:\n        app: The FastAPI application instance. This parameter is required for initializing\n             the Prometheus metrics and integrating them with the FastAPI application.\n    \"\"\"\n    self.network_bytes_sent = None\n    self.network_bytes_received = None\n    self.setup_metrics()\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.systemMetrics.NetworkUsageMonitor.after_request","title":"<code>after_request(self, request, response)</code>","text":"<p>Update metrics after processing each request.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>The incoming HTTP request object.</p> required <code>response</code> <code>Any</code> <p>The HTTP response object.</p> required <p>Actions</p> <ul> <li>Update the network_bytes_sent and network_bytes_received gauges with the current   network usage statistics.</li> </ul> Source code in <code>kal_utils/monitoring/prometheus/systemMetrics.py</code> <pre><code>def after_request(self, request: Request, response: Any):\n    \"\"\"\n    Update metrics after processing each request.\n\n    Args:\n        request (Request): The incoming HTTP request object.\n        response (Any): The HTTP response object.\n\n    Actions:\n        - Update the network_bytes_sent and network_bytes_received gauges with the current\n          network usage statistics.\n    \"\"\"\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.systemMetrics.NetworkUsageMonitor.before_request","title":"<code>before_request(self, request)</code>","text":"<p>This method does not currently perform any actions.</p> Source code in <code>kal_utils/monitoring/prometheus/systemMetrics.py</code> <pre><code>def before_request(self, request: Request):\n    \"\"\"This method does not currently perform any actions.\"\"\"\n    pass\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.systemMetrics.NetworkUsageMonitor.setup_metrics","title":"<code>setup_metrics(self)</code>","text":"<p>Initialize Prometheus metrics for tracking network usage.</p> <p>This method sets up:     - network_bytes_sent: A Prometheus Gauge to track the number of bytes sent.     - network_bytes_received: A Prometheus Gauge to track the number of bytes received.</p> Source code in <code>kal_utils/monitoring/prometheus/systemMetrics.py</code> <pre><code>def setup_metrics(self):\n    \"\"\"\n    Initialize Prometheus metrics for tracking network usage.\n\n    This method sets up:\n        - network_bytes_sent: A Prometheus Gauge to track the number of bytes sent.\n        - network_bytes_received: A Prometheus Gauge to track the number of bytes received.\n    \"\"\"\n    if 'network_bytes_sent' not in REGISTRY._names_to_collectors:\n        self.network_bytes_sent = Gauge(\n            'network_bytes_sent',\n            'Total number of bytes sent'\n        )\n    else:\n        self.network_bytes_sent = REGISTRY._names_to_collectors['network_bytes_sent']\n\n    if 'network_bytes_received' not in REGISTRY._names_to_collectors:\n        self.network_bytes_received = Gauge(\n            'network_bytes_received',\n            'Total number of bytes received'\n        )\n    else:\n        self.network_bytes_received = REGISTRY._names_to_collectors['network_bytes_received']\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.prometheus.systemMetrics.NetworkUsageMonitor.update_metrics","title":"<code>update_metrics(self, request, response)</code>","text":"<p>Update metrics after processing each request.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>The incoming HTTP request object.</p> required <code>response</code> <code>Any</code> <p>The HTTP response object.</p> required <p>Actions</p> <ul> <li>Update the network_bytes_sent and network_bytes_received gauges with the current   network usage statistics.</li> </ul> Source code in <code>kal_utils/monitoring/prometheus/systemMetrics.py</code> <pre><code>def update_metrics(self, request: Request, response: Any):\n    \"\"\"\n    Update metrics after processing each request.\n\n    Args:\n        request (Request): The incoming HTTP request object.\n        response (Any): The HTTP response object.\n\n    Actions:\n        - Update the network_bytes_sent and network_bytes_received gauges with the current\n          network usage statistics.\n    \"\"\"\n    net_io = psutil.net_io_counters()\n    self.network_bytes_sent.set(net_io.bytes_sent)\n    self.network_bytes_received.set(net_io.bytes_recv)\n</code></pre>"},{"location":"monitoring/#tracingconfig","title":"TracingConfig","text":"<p>Abstract base class for configuring tracing with different exporters.</p> <p>This class defines the interface for configuring tracing. Concrete implementations should provide specific configurations for various tracing exporters.</p> <p>Attributes:</p> Name Type Description <code>service_name</code> <code>str</code> <p>The name of the service for tracing.</p> <code>endpoint</code> <code>str</code> <p>The endpoint URL for the tracing exporter.</p> <code>insecure</code> <code>bool</code> <p>Whether the connection is insecure (default is True).</p> Source code in <code>kal_utils/monitoring/tempo/tracing_manager.py</code> <pre><code>class TracingConfig(ABC):\n    \"\"\"\n    Abstract base class for configuring tracing with different exporters.\n\n    This class defines the interface for configuring tracing. Concrete implementations\n    should provide specific configurations for various tracing exporters.\n\n    Attributes:\n        service_name (str): The name of the service for tracing.\n        endpoint (str): The endpoint URL for the tracing exporter.\n        insecure (bool): Whether the connection is insecure (default is True).\n    \"\"\"\n\n    def __init__(self, service_name: str, endpoint: str, insecure: bool = True):\n        \"\"\"\n        Initializes the TracingConfig with the given parameters.\n\n        Args:\n            service_name (str): The name of the service for tracing.\n            endpoint (str): The endpoint URL for the tracing exporter.\n            insecure (bool, optional): Whether the connection is insecure (default is True).\n        \"\"\"\n        self.service_name = service_name\n        self.endpoint = endpoint\n        self.insecure = insecure\n\n    @abstractmethod\n    def configure_tracing(self):\n        \"\"\"\n        Abstract method to configure tracing based on the exporter.\n\n        Concrete implementations must provide their own configuration logic.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.tempo.tracing_manager.TracingConfig.__init__","title":"<code>__init__(self, service_name, endpoint, insecure=True)</code>  <code>special</code>","text":"<p>Initializes the TracingConfig with the given parameters.</p> <p>Parameters:</p> Name Type Description Default <code>service_name</code> <code>str</code> <p>The name of the service for tracing.</p> required <code>endpoint</code> <code>str</code> <p>The endpoint URL for the tracing exporter.</p> required <code>insecure</code> <code>bool</code> <p>Whether the connection is insecure (default is True).</p> <code>True</code> Source code in <code>kal_utils/monitoring/tempo/tracing_manager.py</code> <pre><code>def __init__(self, service_name: str, endpoint: str, insecure: bool = True):\n    \"\"\"\n    Initializes the TracingConfig with the given parameters.\n\n    Args:\n        service_name (str): The name of the service for tracing.\n        endpoint (str): The endpoint URL for the tracing exporter.\n        insecure (bool, optional): Whether the connection is insecure (default is True).\n    \"\"\"\n    self.service_name = service_name\n    self.endpoint = endpoint\n    self.insecure = insecure\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.tempo.tracing_manager.TracingConfig.configure_tracing","title":"<code>configure_tracing(self)</code>","text":"<p>Abstract method to configure tracing based on the exporter.</p> <p>Concrete implementations must provide their own configuration logic.</p> Source code in <code>kal_utils/monitoring/tempo/tracing_manager.py</code> <pre><code>@abstractmethod\ndef configure_tracing(self):\n    \"\"\"\n    Abstract method to configure tracing based on the exporter.\n\n    Concrete implementations must provide their own configuration logic.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"monitoring/#otlptracingconfig","title":"OTLPTracingConfig","text":"<p>Concrete implementation of TracingConfig for OTLP exporter.</p> <p>This class configures tracing using the OTLP exporter.</p> <p>Methods</p> <p>configure_tracing: Configures OpenTelemetry tracing with OTLP exporter.</p> Source code in <code>kal_utils/monitoring/tempo/tracing_manager.py</code> <pre><code>class OTLPTracingConfig(TracingConfig):\n    \"\"\"\n    Concrete implementation of TracingConfig for OTLP exporter.\n\n    This class configures tracing using the OTLP exporter.\n\n    Methods:\n        configure_tracing: Configures OpenTelemetry tracing with OTLP exporter.\n    \"\"\"\n\n    def configure_tracing(self):\n        \"\"\"\n        Configures tracing using the OTLP exporter.\n\n        This method sets up OpenTelemetry Tracing with the OTLP exporter, including:\n        - Setting the tracer provider with a resource that includes the service name.\n        - Creating an OTLPSpanExporter and a BatchSpanProcessor.\n        - Adding the span processor to the tracer provider.\n        \"\"\"\n        # Set up OpenTelemetry Tracing\n        set_tracer_provider(\n            TracerProvider(\n                resource=Resource.create({SERVICE_NAME: self.service_name})\n            )\n        )\n        tracer_provider = get_tracer_provider()\n\n        # Configure OTLP exporter\n        exporter = OTLPSpanExporter(endpoint=self.endpoint, insecure=self.insecure)\n        span_processor = BatchSpanProcessor(exporter)\n        tracer_provider.add_span_processor(span_processor)\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.tempo.tracing_manager.OTLPTracingConfig.configure_tracing","title":"<code>configure_tracing(self)</code>","text":"<p>Configures tracing using the OTLP exporter.</p> <p>This method sets up OpenTelemetry Tracing with the OTLP exporter, including: - Setting the tracer provider with a resource that includes the service name. - Creating an OTLPSpanExporter and a BatchSpanProcessor. - Adding the span processor to the tracer provider.</p> Source code in <code>kal_utils/monitoring/tempo/tracing_manager.py</code> <pre><code>def configure_tracing(self):\n    \"\"\"\n    Configures tracing using the OTLP exporter.\n\n    This method sets up OpenTelemetry Tracing with the OTLP exporter, including:\n    - Setting the tracer provider with a resource that includes the service name.\n    - Creating an OTLPSpanExporter and a BatchSpanProcessor.\n    - Adding the span processor to the tracer provider.\n    \"\"\"\n    # Set up OpenTelemetry Tracing\n    set_tracer_provider(\n        TracerProvider(\n            resource=Resource.create({SERVICE_NAME: self.service_name})\n        )\n    )\n    tracer_provider = get_tracer_provider()\n\n    # Configure OTLP exporter\n    exporter = OTLPSpanExporter(endpoint=self.endpoint, insecure=self.insecure)\n    span_processor = BatchSpanProcessor(exporter)\n    tracer_provider.add_span_processor(span_processor)\n</code></pre>"},{"location":"monitoring/#jaegertracingconfig","title":"JaegerTracingConfig","text":"<p>Concrete implementation of TracingConfig for Jaeger exporter.</p> <p>This class configures tracing using the Jaeger exporter.</p> <p>Methods</p> <p>configure_tracing: Configures OpenTelemetry tracing with Jaeger exporter.</p> Source code in <code>kal_utils/monitoring/tempo/tracing_manager.py</code> <pre><code>class JaegerTracingConfig(TracingConfig):\n    \"\"\"\n    Concrete implementation of TracingConfig for Jaeger exporter.\n\n    This class configures tracing using the Jaeger exporter.\n\n    Methods:\n        configure_tracing: Configures OpenTelemetry tracing with Jaeger exporter.\n    \"\"\"\n\n    def configure_tracing(self):\n        \"\"\"\n        Configures tracing using the Jaeger exporter.\n\n        This method sets up OpenTelemetry Tracing with the Jaeger exporter, including:\n        - Setting the tracer provider with a resource that includes the service name.\n        - Creating a JaegerExporter and a BatchSpanProcessor.\n        - Adding the span processor to the tracer provider.\n        \"\"\"\n        # Set up OpenTelemetry Tracing\n        set_tracer_provider(\n            TracerProvider(\n                resource=Resource.create({SERVICE_NAME: self.service_name})\n            )\n        )\n        tracer_provider = get_tracer_provider()\n\n        # Configure Jaeger exporter\n        exporter = JaegerExporter(agent_endpoint=self.endpoint)\n        span_processor = BatchSpanProcessor(exporter)\n        tracer_provider.add_span_processor(span_processor)\n</code></pre>"},{"location":"monitoring/#kal_utils.monitoring.tempo.tracing_manager.JaegerTracingConfig.configure_tracing","title":"<code>configure_tracing(self)</code>","text":"<p>Configures tracing using the Jaeger exporter.</p> <p>This method sets up OpenTelemetry Tracing with the Jaeger exporter, including: - Setting the tracer provider with a resource that includes the service name. - Creating a JaegerExporter and a BatchSpanProcessor. - Adding the span processor to the tracer provider.</p> Source code in <code>kal_utils/monitoring/tempo/tracing_manager.py</code> <pre><code>def configure_tracing(self):\n    \"\"\"\n    Configures tracing using the Jaeger exporter.\n\n    This method sets up OpenTelemetry Tracing with the Jaeger exporter, including:\n    - Setting the tracer provider with a resource that includes the service name.\n    - Creating a JaegerExporter and a BatchSpanProcessor.\n    - Adding the span processor to the tracer provider.\n    \"\"\"\n    # Set up OpenTelemetry Tracing\n    set_tracer_provider(\n        TracerProvider(\n            resource=Resource.create({SERVICE_NAME: self.service_name})\n        )\n    )\n    tracer_provider = get_tracer_provider()\n\n    # Configure Jaeger exporter\n    exporter = JaegerExporter(agent_endpoint=self.endpoint)\n    span_processor = BatchSpanProcessor(exporter)\n    tracer_provider.add_span_processor(span_processor)\n</code></pre>"},{"location":"monitoring/#functions","title":"Functions","text":""},{"location":"monitoring/#span_with_attributes","title":"span_with_attributes","text":"<p>Context manager for creating a span with specified attributes.</p> <p>This context manager starts a new OpenTelemetry span with the given span name and sets the provided attributes on that span. It ensures that the span is closed after exiting the context.</p> <p>Parameters:</p> Name Type Description Default <code>attributes</code> <code>dict</code> <p>A dictionary of attributes to set on the span.</p> required <code>span_name</code> <code>str</code> <p>The name of the span. Defaults to \"custom-span\".</p> <code>'custom-span'</code> <p>Yields:</p> Type Description <code>Span</code> <p>The created span with the given attributes set.</p> Source code in <code>kal_utils/monitoring/tempo/context_manager.py</code> <pre><code>@contextmanager\ndef span_with_attributes(attributes, span_name=\"custom-span\"):\n    \"\"\"\n    Context manager for creating a span with specified attributes.\n\n    This context manager starts a new OpenTelemetry span with the given span name\n    and sets the provided attributes on that span. It ensures that the span is closed\n    after exiting the context.\n\n    Args:\n        attributes (dict): A dictionary of attributes to set on the span.\n        span_name (str, optional): The name of the span. Defaults to \"custom-span\".\n\n    Yields:\n        Span: The created span with the given attributes set.\n    \"\"\"\n    tracer = trace.get_tracer(__name__)\n    with tracer.start_as_current_span(span_name) as span:\n        # Set the specified attributes on the span\n        for key, value in attributes.items():\n            span.set_attribute(key, value)\n        # Yield the span to the context\n        yield span\n</code></pre>"},{"location":"monitoring/#span_with_event","title":"span_with_event","text":"<p>Context manager for adding an event with optional attributes to the current active span.</p> <p>This context manager adds an event with the specified name and attributes to the current active OpenTelemetry span. If no active span is available, it does nothing.</p> <p>Parameters:</p> Name Type Description Default <code>event_name</code> <code>str</code> <p>The name of the event to add to the span.</p> required <code>attributes</code> <code>Optional[Dict[str, Any]]</code> <p>A dictionary of attributes to set on the event.</p> <code>None</code> <p>Yields:</p> Type Description <code>Span</code> <p>The current active span with the event and attributes added, or None if no span.</p> Source code in <code>kal_utils/monitoring/tempo/context_manager.py</code> <pre><code>@contextmanager\ndef span_with_event(event_name: str, attributes: Optional[Dict[str, Any]] = None):\n    \"\"\"\n    Context manager for adding an event with optional attributes to the current active span.\n\n    This context manager adds an event with the specified name and attributes to the current\n    active OpenTelemetry span. If no active span is available, it does nothing.\n\n    Args:\n        event_name (str): The name of the event to add to the span.\n        attributes (Optional[Dict[str, Any]]): A dictionary of attributes to set on the event.\n\n    Yields:\n        Span: The current active span with the event and attributes added, or None if no span.\n    \"\"\"\n    # Ensure you are using the correct tracer\n    tracer = trace.get_tracer(__name__)\n\n    # Get the current active span\n    current_span = trace.get_current_span()\n\n    if not current_span or not current_span.is_recording():\n        # If no active span or span is not recording, do nothing\n        yield None\n        return\n\n    # Add the event to the current span with optional attributes\n    current_span.add_event(event_name, attributes=attributes)\n\n    # Yield the current span with the event and attributes added\n    try:\n        yield current_span\n    finally:\n        pass  # If you want to clean up anything after the block ends\n</code></pre>"},{"location":"monitoring/#add_span_attributes","title":"add_span_attributes","text":"<p>Decorator to add attributes to a span for a decorated asynchronous function.</p> <p>This decorator creates a span for the decorated function and sets the specified attributes on it. It also sets the span status to OK if the function executes without errors, and to ERROR if an exception is raised.</p> <p>Parameters:</p> Name Type Description Default <code>**attributes</code> <p>Arbitrary keyword arguments representing the attributes           to be set on the span. For example, <code>key1=\"value1\"</code>.</p> <code>{}</code> Source code in <code>kal_utils/monitoring/tempo/decorator_manager.py</code> <pre><code>def add_span_attributes(**attributes):\n    \"\"\"\n    Decorator to add attributes to a span for a decorated asynchronous function.\n\n    This decorator creates a span for the decorated function and sets the specified\n    attributes on it. It also sets the span status to OK if the function executes\n    without errors, and to ERROR if an exception is raised.\n\n    Args:\n        **attributes: Arbitrary keyword arguments representing the attributes\n                      to be set on the span. For example, `key1=\"value1\"`.\n    \"\"\"\n    def decorator(func):\n        @wraps(func)\n        async def wrapper(*args, **kwargs):\n            tracer = trace.get_tracer(__name__)\n            # Create a new span with the function name\n            with tracer.start_as_current_span(func.__name__) as span:\n                # Set static attributes\n                for key, value in attributes.items():\n                    if isinstance(value, str) and value.startswith(\"{{\") and value.endswith(\"}}\"):\n                        # Extract parameter name from `{{param_name}}`\n                        param_name = value.strip(\"{}\")\n                        # Try to get the parameter value from kwargs or args\n                        if param_name in kwargs:\n                            span.set_attribute(key, kwargs[param_name])\n                        else:\n                            # Use args and match by function signature position\n                            try:\n                                # Get the parameter's position from the function signature\n                                func_signature = func.__code__.co_varnames\n                                param_index = func_signature.index(param_name)\n                                span.set_attribute(key, args[param_index])\n                            except (ValueError, IndexError):\n                                pass  # Parameter not found\n                    else:\n                        # Set static value\n                        span.set_attribute(key, value)\n\n                try:\n                    # Call the decorated function\n                    result = await func(*args, **kwargs)\n                    # Set span status to OK if no error occurs\n                    span.set_status(Status(StatusCode.OK, \"Success\"))\n                    return result\n                except Exception as e:\n                    # Set span status to ERROR if an exception occurs\n                    span.set_status(Status(StatusCode.ERROR, str(e)))\n                    # Re-raise the exception to ensure proper error handling\n                    raise\n\n        return wrapper\n    return decorator\n</code></pre>"},{"location":"monitoring/#add_span_event","title":"add_span_event","text":"<p>Decorator to add an event to a span for a decorated asynchronous function.</p> <p>This decorator creates a span for the decorated function and logs an event with the specified name to that span. It does not modify the span status based on the function execution outcome.</p> <p>Parameters:</p> Name Type Description Default <code>event_name</code> <code>str</code> <p>The name of the event to be added to the span.</p> required <p>Returns:</p> Type Description <code>function</code> <p>The decorated asynchronous function with tracing.</p> Source code in <code>kal_utils/monitoring/tempo/decorator_manager.py</code> <pre><code>def add_span_event(event_name):\n    \"\"\"\n    Decorator to add an event to a span for a decorated asynchronous function.\n\n    This decorator creates a span for the decorated function and logs an event with\n    the specified name to that span. It does not modify the span status based on\n    the function execution outcome.\n\n    Args:\n        event_name (str): The name of the event to be added to the span.\n\n    Returns:\n        function: The decorated asynchronous function with tracing.\n    \"\"\"\n    def decorator(func):\n        @wraps(func)\n        async def wrapper(*args, **kwargs):\n            tracer = trace.get_tracer(__name__)\n            with tracer.start_as_current_span(func.__name__) as span:\n                span.add_event(event_name)\n                return await func(*args, **kwargs)\n        return wrapper\n    return decorator\n</code></pre>"},{"location":"monitoring/#configure_monitor","title":"configure_monitor","text":"Source code in <code>kal_utils/monitoring/core/config_metrics.py</code> <pre><code>def configure_monitor(app: FastAPI):\n    UnifiedMetrics = create_unified_metrics_class(app)\n    metrics = UnifiedMetrics(app)\n    app.add_middleware(BaseHTTPMiddleware, dispatch=metrics.dispatch)\n    FastAPIInstrumentor.instrument_app(app)\n    return metrics\n</code></pre>"},{"location":"monitoring/#get_enabled_metrics","title":"get_enabled_metrics","text":"<p>Retrieves the enabled metrics classes from environment variables.</p> Source code in <code>kal_utils/monitoring/core/metrics.py</code> <pre><code>def get_enabled_metrics() -&gt; Set[str]:\n    \"\"\"\n    Retrieves the enabled metrics classes from environment variables.\n    \"\"\"\n    enabled_metrics = os.getenv('ENABLED_METRICS', 'RequestCounter,RequestHist,ServerErrorMetrics').split(',')\n    return set(enabled_metrics)\n</code></pre>"},{"location":"monitoring/#get_metrics_classes","title":"get_metrics_classes","text":"<p>Dynamically load and return a dictionary of available metrics classes.</p> Source code in <code>kal_utils/monitoring/core/metrics.py</code> <pre><code>def get_metrics_classes() -&gt; Dict[str, Type]:\n    \"\"\"\n    Dynamically load and return a dictionary of available metrics classes.\n    \"\"\"\n    from .. import prometheus\n    metrics_classes = {\n        \"LocationRequestCounter\":prometheus.locationRequestCounter.LocationRequestCounter,\n        \"RequestCounter\":prometheus.requestMetrics.RequestCounter,\n        \"RequestHist\":prometheus.requestMetrics.RequestHist,\n        \"ServerErrorMetrics\":prometheus.requestMetrics.ServerErrorMetrics,\n        \"CpuUsageMonitor\":prometheus.systemMetrics.CpuUsageMonitor,\n        \"MemoryUsageMonitor\":prometheus.systemMetrics.MemoryUsageMonitor,\n        \"DiskUsageMonitor\":prometheus.systemMetrics.DiskUsageMonitor,\n        \"NetworkUsageMonitor\":prometheus.systemMetrics.NetworkUsageMonitor\n    }\n    # base_directory = 'prometheus'\n    # base_module = 'prometheus'\n\n    # # Find all modules in the base directory\n    # modules = find_modules_in_directory(base_directory)\n    # metrics_classes = {}\n\n    # # Iterate over modules to find and filter classes\n    # for module_name, module_path in modules.items():\n    #     classes = find_classes_in_module(module_path)\n    #     filtered_classes = filter_metric_classes(classes, base_module)\n    #     metrics_classes.update(filtered_classes)\n\n    return metrics_classes\n</code></pre>"},{"location":"monitoring/#create_unified_metrics_class","title":"create_unified_metrics_class","text":"<p>Creates a unified metrics class based on the metrics enabled via environment variables.</p> <p>This function constructs a <code>UnifiedMetrics</code> class, which combines multiple metrics classes into a single interface for managing metrics. The metrics classes to be included are determined by the <code>ENABLED_METRICS</code> environment variable.</p> <p>Parameters:</p> Name Type Description Default <code>app</code> <code>FastAPI</code> <p>The FastAPI application instance. This is used to initialize each metric class.</p> required <p>Returns:</p> Type Description <code>Type[PrometheusMetricsDecorator]</code> <p>A subclass of <code>PrometheusMetricsDecorator</code> with the combined functionality of all enabled metrics classes.</p> Source code in <code>kal_utils/monitoring/prometheus/unifiedMetrics.py</code> <pre><code>def create_unified_metrics_class(app: FastAPI) -&gt; Type[PrometheusMetricsDecorator]:\n    \"\"\"\n    Creates a unified metrics class based on the metrics enabled via environment variables.\n\n    This function constructs a `UnifiedMetrics` class, which combines multiple metrics classes\n    into a single interface for managing metrics. The metrics classes to be included are determined\n    by the `ENABLED_METRICS` environment variable.\n\n    Args:\n        app (FastAPI): The FastAPI application instance. This is used to initialize each metric class.\n\n    Returns:\n        Type[PrometheusMetricsDecorator]: A subclass of `PrometheusMetricsDecorator` with the\n        combined functionality of all enabled metrics classes.\n    \"\"\"\n    metrics_classes = get_metrics_classes()\n    enabled_metrics = get_enabled_metrics()\n\n    class UnifiedMetrics(PrometheusMetricsDecorator):\n        \"\"\"\n        A unified metrics class that integrates multiple metrics classes into a single interface.\n\n        Attributes:\n            metrics_initialized (Set[PrometheusMetricsDecorator]): A set of initialized metrics instances\n            that are active for this application.\n        \"\"\"\n\n        def __init__(self, app: FastAPI):\n            \"\"\"\n            Initializes the UnifiedMetrics class.\n\n            This constructor sets up metrics by initializing the metrics classes that are enabled,\n            as determined by the environment variables.\n\n            Args:\n                app (FastAPI): The FastAPI application instance used to initialize each metric class.\n            \"\"\"\n            super().__init__(app)\n            self.metrics_initialized: Set[PrometheusMetricsDecorator] = set()\n            self.initialize_metrics(app, metrics_classes, enabled_metrics)\n\n        def initialize_metrics(self, app: FastAPI, metrics_classes: dict, enabled_metrics: Set[str]):\n            \"\"\"\n            Initializes metrics instances based on the enabled metrics classes.\n\n            This method checks the enabled metrics and creates instances of the corresponding\n            metrics classes. Each initialized metric instance is added to the `metrics_initialized`\n            set to ensure that each metric is only initialized once.\n\n            Args:\n                app (FastAPI): The FastAPI application instance used for initializing each metric class.\n                metrics_classes (dict): A dictionary mapping metric class names to their corresponding\n                metric classes.\n                enabled_metrics (Set[str]): A set of names for the metrics classes that are enabled\n                according to the environment variables.\n            \"\"\"\n            for metric_class_name in enabled_metrics:\n                metric_class = metrics_classes.get(metric_class_name)\n                if metric_class:\n                    metric_instance = metric_class(app)\n                    # Initialize metrics if not already done\n                    if metric_instance not in self.metrics_initialized:\n                        self.metrics_initialized.add(metric_instance)\n\n        def setup_metrics(self):\n            \"\"\"\n            Sets up metrics for all enabled metrics classes.\n\n            This method is currently a placeholder and does not perform any actions. It is intended\n            to be used for additional setup if needed in the future. The actual setup is performed\n            by individual metric classes during their initialization.\n            \"\"\"\n            pass\n\n        async def dispatch(self, request: Request, call_next):\n            # Define the path to exclude from metrics collection\n            excluded_paths = [\"/metrics\"]  # Add other paths to exclude as needed\n\n            if request.url.path in excluded_paths:\n                # Skip metrics collection for excluded paths\n                response = await call_next(request)\n                self.update_metrics(request, response)\n                return response\n\n            self.before_request(request)\n\n            response = await call_next(request)\n\n            self.after_request(request, response)\n\n            return response\n\n        def before_request(self, request: Request):\n            \"\"\"\n            Invokes the `before_request` method for all initialized metrics classes.\n\n            This method is called before processing each request. It allows each metrics instance\n            to perform any necessary actions or preparations before the request is handled.\n\n            Args:\n                request (Request): The incoming HTTP request object.\n            \"\"\"\n            for metric_instance in self.metrics_initialized:\n                metric_instance.before_request(request)\n\n        def after_request(self, request: Request, response: Any):\n            \"\"\"\n            Invokes the `after_request` method for all initialized metrics classes.\n\n            This method is called after processing each request. It allows each metrics instance\n            to perform any necessary actions or updates based on the request and response.\n\n            Args:\n                request (Request): The incoming HTTP request object.\n                response (Any): The HTTP response object.\n            \"\"\"\n            for metric_instance in self.metrics_initialized:\n                metric_instance.after_request(request, response)\n\n        def update_metrics(self, request: Request, response: Any):\n            \"\"\"\n            Invokes the `after_request` method for all initialized metrics classes.\n\n            This method is called after processing each request. It allows each metrics instance\n            to perform any necessary actions or updates based on the request and response.\n\n            Args:\n                request (Request): The incoming HTTP request object.\n                response (Any): The HTTP response object.\n            \"\"\"\n            for metric_instance in self.metrics_initialized:\n                metric_instance.update_metrics(request, response)\n\n    return UnifiedMetrics\n</code></pre>"},{"location":"monitoring/#authenticate","title":"authenticate","text":"Source code in <code>kal_utils/monitoring/utils/basic_authentication.py</code> <pre><code>def authenticate(credentials: HTTPBasicCredentials = Depends(security)):\n    # Retrieve credentials from environment variables\n    correct_username = os.getenv(\"BASIC_AUTH_USERNAME\", \"prometheus\")  # Default fallback value if not set\n    correct_password = os.getenv(\"BASIC_AUTH_PASSWORD\", \"prometheus\")  # Default fallback value if not set\n    if credentials.username != correct_username or credentials.password != correct_password:\n        raise HTTPException(\n            status_code=status.HTTP_401_UNAUTHORIZED,\n            detail=\"Invalid authentication credentials\",\n            headers={\"WWW-Authenticate\": \"Basic\"},\n        )\n</code></pre>"},{"location":"monitoring/#add_parent_directory_to_sys_path","title":"add_parent_directory_to_sys_path","text":"<p>Adds a directory <code>levels_up</code> levels above the current file to the sys.path.</p> <p>Parameters:</p> Name Type Description Default <code>levels_up</code> <code>int</code> <p>The number of directory levels to go up from the current file.              Defaults to 1.</p> <code>1</code> Source code in <code>kal_utils/monitoring/utils/relative_imports.py</code> <pre><code>def add_parent_directory_to_sys_path(levels_up: int = 1):\n    \"\"\"\n    Adds a directory `levels_up` levels above the current file to the sys.path.\n\n    Args:\n        levels_up (int): The number of directory levels to go up from the current file.\n                         Defaults to 1.\n    \"\"\"\n    current_file_directory = os.path.dirname(__file__)  # Directory of the current file\n    target_directory = os.path.abspath(os.path.join(current_file_directory, *[\"..\"] * levels_up))\n\n    if target_directory not in sys.path:\n        sys.path.insert(0, target_directory)\n</code></pre>"},{"location":"requests/","title":"requests module","text":""},{"location":"sorst/","title":"sorts module","text":""},{"location":"storage/","title":"Storage Module","text":"<p>This module provides an abstraction layer for working with different storage backends.</p>"},{"location":"storage/#classes","title":"Classes","text":""},{"location":"storage/#basestorage","title":"BaseStorage","text":"Source code in <code>kal_utils/storage/base_storage.py</code> <pre><code>class BaseStorage(ABC):\n    @abstractmethod\n    def create_bucket(self, bucket_name, location = \"\", storage_class = \"\"):\n        pass\n\n    @abstractmethod\n    def delete_bucket(self, bucket_name):\n        pass\n\n    @abstractmethod\n    def list_files(self, bucket_name, prefix=None):\n        pass\n\n    @abstractmethod\n    def get_file_metadata(self, bucket_name, file_path):\n        pass\n\n    @abstractmethod\n    def read_file(self, bucket_name: str, file_path: str) -&gt; str:\n        pass\n\n    @abstractmethod\n    def copy_file(self, bucket_name, source_file_path, destination_file_path):\n        pass\n\n    @abstractmethod\n    def rename_file(self, bucket_name, source_file_folder, source_file_name, new_file_name):\n        pass\n\n    @abstractmethod\n    def get_bucket_metadata(self, bucket_name):\n        pass\n\n    @abstractmethod\n    def set_bucket_permissions(self, bucket_name, entity, role):\n        pass\n\n    @abstractmethod\n    def set_file_permissions(self, bucket_name, file_path, entity, role):\n        pass\n\n    @abstractmethod\n    def upload_to_bucket(self, bucket_name, file_stream, destination_blob_name, content_type='application/octet-stream'):\n        pass\n\n    @abstractmethod\n    def upload_from_local(self, bucket_name: str, file_path: str, destination_blob_name: str,\n                          content_type='application/octet-stream'):\n        pass\n\n    @abstractmethod\n    def move_folder(self, bucket_name, source_folder, destination_folder):\n        pass\n\n    @abstractmethod\n    def move_file(self, bucket_name, source_file_path, destination_file_path):\n        pass\n\n    @abstractmethod\n    def delete_folder(self, bucket_name, folder_path):\n        pass\n\n    @abstractmethod\n    def delete_file(self, bucket_name, file_path):\n        pass\n\n    @abstractmethod\n    async def generate_signed_url(self, bucket_name, file_path, expiration_time_minutes=60):\n        pass\n\n    @abstractmethod\n    def list_buckets(self):\n        pass\n\n    @abstractmethod\n    def download_file(self, bucket_name, file_path, local_path=None):\n        pass\n</code></pre>"},{"location":"storage/#gcsstorage","title":"GCSStorage","text":"Source code in <code>kal_utils/storage/gcs_storage.py</code> <pre><code>class GCSStorage(BaseStorage):\n    def __init__(self, credentials_json=None):\n        if credentials_json:\n            if os.path.isfile(credentials_json):\n                logger.info(\"Using credentials from file path\")\n                with open(credentials_json, 'r') as f:\n                    service_account_info = json.load(f)\n            else:\n                try:\n                    logger.info(\"Trying to decode base64 credentials\")\n                    decoded_key = base64.b64decode(credentials_json).decode('utf-8')\n                    service_account_info = json.loads(decoded_key)\n                except (base64.binascii.Error, ValueError) as e:\n                    logger.error(\"Failed to decode base64 string, using it as JSON string\")\n                    service_account_info = json.loads(credentials_json)\n\n            credentials = service_account.Credentials.from_service_account_info(service_account_info)\n            self.storage_client = storage.Client(credentials=credentials)\n        else:\n            logger.info(\"credentials is None, trying to initialize storage without credentials\")\n            self.storage_client = storage.Client()\n\n    def create_bucket(self, bucket_name, location=\"me-west1\", storage_class=\"Standard\"):\n        try:\n            all_chars = string.ascii_letters + string.digits\n            new_name = bucket_name\n            while self.storage_client.lookup_bucket(new_name) is not None:\n                new_name += random.choice(all_chars)\n\n            bucket = self.storage_client.bucket(new_name)\n            bucket.location = location\n            bucket.storage_class = storage_class\n\n            bucket = self.storage_client.create_bucket(bucket)\n            logger.info(f'Bucket {new_name} created.')\n            return bucket\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to create bucket: {str(e)}\")\n            return None\n\n\n    def delete_bucket(self, bucket_name):\n        try:\n            bucket = self.storage_client.get_bucket(bucket_name)\n            bucket.delete()\n            logger.info(f'Bucket {bucket_name} deleted.')\n            return True\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to delete bucket: {str(e)}\")\n            return False\n\n    def list_files(self, bucket_name, prefix=None):\n        \"\"\"\n        Lists all files in a bucket or a specific folder in Google Cloud Storage.\n\n        Args:\n            bucket_name (str): The name of the bucket.\n            prefix (str, optional): The prefix (folder path) to list files from. Defaults to None.\n\n        Returns:\n            list: A list of file names in the specified bucket or folder.\n        \"\"\"\n        try:\n            bucket = self.storage_client.get_bucket(bucket_name)\n            # List files in the bucket or a specific folder\n            blobs = bucket.list_blobs(prefix=prefix)\n            file_names = [blob.name for blob in blobs]\n            return file_names\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to list files: {str(e)}\")\n            return []\n\n    def get_file_metadata(self, bucket_name, file_path):\n        \"\"\"\n        Retrieves metadata for a specific file in Google Cloud Storage.\n\n        Args:\n            bucket_name (str): The name of the bucket.\n            file_path (str): The full path to the file to retrieve metadata for.\n\n        Returns:\n            dict: A dictionary containing the file's metadata.\n        \"\"\"\n        try:\n            bucket = self.storage_client.get_bucket(bucket_name)\n            blob = bucket.get_blob(file_path)\n\n            if not blob:\n                logger.info(f'File {file_path} not found in bucket {bucket_name}.')\n                return {}\n\n            metadata = {\n                'name': blob.name,\n                'size': blob.size,\n                'content_type': blob.content_type,\n                'updated': blob.updated,\n                'generation': blob.generation,\n                'metageneration': blob.metageneration,\n                'md5_hash': blob.md5_hash,\n                'crc32c': blob.crc32c,\n                'etag': blob.etag,\n                'public_url': blob.public_url\n            }\n\n            return metadata\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to get file metadata: {str(e)}\")\n            return {}\n\n    def read_file(self, bucket_name: str, file_path: str) -&gt; str:\n        \"\"\"\n        Reads the content of a file from a Google Cloud Storage bucket.\n\n        Args:\n            bucket_name (str): The name of the bucket.\n            file_path (str): The path to the file within the bucket.\n\n        Returns:\n            str: The content of the file as a string.\n\n        Raises:\n            Exception: If there's an error reading the file.\n        \"\"\"\n        try:\n            bucket = self.storage_client.get_bucket(bucket_name)\n            blob = bucket.blob(file_path)\n            content = blob.download_as_text()\n            return content\n        except Exception as e:\n            logger.error(f\"Error reading file from GCS: {str(e)}\")\n            raise Exception(f\"Error reading file from GCS: {str(e)}\")\n\n    def copy_file(self, bucket_name, source_file_path, destination_file_path):\n        \"\"\"\n        Copies a file from one location to another within the same Google Cloud Storage bucket.\n\n        Args:\n            bucket_name (str): The name of the bucket.\n            source_file_path (str): The full path to the source file.\n            destination_file_path (str): The full path to the destination file.\n\n        Returns:\n            bool: True if the file was copied successfully, False otherwise.\n        \"\"\"\n        try:\n            bucket = self.storage_client.get_bucket(bucket_name)\n            source_blob = bucket.get_blob(source_file_path)\n\n            if not source_blob:\n                logger.info(f'Source file {source_file_path} not found in bucket {bucket_name}.')\n                return False\n\n            bucket.copy_blob(source_blob, bucket, destination_file_path)\n            logger.info(f'File {source_file_path} copied to {destination_file_path}.')\n            return True\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to copy file: {str(e)}\")\n            return False\n\n    def rename_file(self, bucket_name, source_file_folder, source_file_name, new_file_name):\n        \"\"\"\n        Renames a file in Google Cloud Storage by copying it to a new name and deleting the original.\n\n        Args:\n            bucket_name (str): The name of the bucket.\n            source_file_folder (str): The full path to the folder where the file is located.\n            source_file_name (str): The current file name.\n            new_file_name (str): The new file name.\n\n        Returns:\n            bool: True if the file was renamed successfully, False otherwise.\n        \"\"\"\n        try:\n            bucket = self.storage_client.get_bucket(bucket_name)\n\n            source_path = f\"{source_file_folder}/{source_file_name}\"\n            destination_path = f\"{source_file_folder}/{new_file_name}\"\n\n            source_blob = bucket.get_blob(source_path)\n            if not source_blob:\n                logger.error(f'Source file {source_path} not found in bucket {bucket_name}.')\n                return False\n\n            bucket.copy_blob(source_blob, bucket, destination_path)\n            logger.info(f'File {source_path} copied to {destination_path}.')\n\n            source_blob.delete()\n            logger.info(f'Source file {source_path} deleted.')\n\n            return True\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to rename file: {str(e)}\")\n            return False\n\n    def get_bucket_metadata(self, bucket_name):\n        \"\"\"\n        Retrieves metadata for a specific bucket in Google Cloud Storage.\n\n        Args:\n            bucket_name (str): The name of the bucket to retrieve metadata for.\n\n        Returns:\n            dict: A dictionary containing the bucket's metadata.\n        \"\"\"\n        try:\n            bucket = self.storage_client.get_bucket(bucket_name)\n\n            metadata = {\n                'id': bucket.id,\n                'name': bucket.name,\n                'location': bucket.location,\n                'storage_class': bucket.storage_class,\n                'created': bucket.time_created,\n                'updated': bucket.updated,\n                'default_event_based_hold': bucket.default_event_based_hold,\n                'retention_period': bucket.retention_period,\n                'labels': bucket.labels,\n                'versioning_enabled': bucket.versioning_enabled,\n                'cors': bucket.cors,\n                'lifecycle_rules': bucket.lifecycle_rules,\n                'logging': bucket.logging,\n                'encryption': bucket.encryption,\n                'owner': bucket.owner,\n                'acl': bucket.acl,\n                'default_acl': bucket.default_object_acl,\n            }\n\n            return metadata\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to get bucket metadata: {str(e)}\")\n            return {}\n\n    def set_bucket_permissions(self, bucket_name, entity, role):\n        \"\"\"\n        Sets permissions for a bucket in Google Cloud Storage.\n\n        Args:\n            bucket_name (str): The name of the bucket.\n            entity (str): The entity to set permissions for (e.g., 'user-email@example.com', 'group-group@example.com').\n            role (str): The role to assign to the entity (e.g., 'OWNER', 'READER', 'WRITER').\n\n        Returns:\n            bool: True if the permissions were set successfully, False otherwise.\n        \"\"\"\n        try:\n            bucket = self.storage_client.get_bucket(bucket_name)\n\n            # Get the bucket's ACL\n            acl = bucket.acl\n\n            # Clear existing ACLs for the entity\n            acl.revoke_entity(entity)\n\n            # Add the new permission\n            acl.entity_from_dict({'entity': entity, 'role': role})\n\n            # Save the changes to the ACL\n            acl.save()\n\n            logger.info(f'Permissions for entity {entity} set to {role} on bucket {bucket_name}.')\n            return True\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to set bucket permissions: {str(e)}\")\n            return False\n\n    def set_file_permissions(self, bucket_name, file_path, entity, role):\n        \"\"\"\n        Sets permissions for a specific file in Google Cloud Storage.\n\n        Args:\n            bucket_name (str): The name of the bucket.\n            file_path (str): The full path to the file within the bucket.\n            entity (str): The entity to set permissions for (e.g., 'user-email@example.com', 'group-group@example.com').\n            role (str): The role to assign to the entity (e.g., 'OWNER', 'READER', 'WRITER').\n\n        Returns:\n            bool: True if the permissions were set successfully, False otherwise.\n        \"\"\"\n        try:\n            bucket = self.storage_client.get_bucket(bucket_name)\n            blob = bucket.get_blob(file_path)\n\n            if not blob:\n                logger.error(f'File {file_path} not found in bucket {bucket_name}.')\n                return False\n\n            # Get the blob's ACL\n            acl = blob.acl\n\n            # Clear existing ACLs for the entity\n            acl.revoke_entity(entity)\n\n            # Add the new permission\n            acl.entity_from_dict({'entity': entity, 'role': role})\n\n            # Save the changes to the ACL\n            acl.save()\n\n            logger.info(f'Permissions set successfully on file {file_path} in bucket {bucket_name}.')\n            return True\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to set file permissions: {str(e)}\")\n            return False\n\n    def upload_to_bucket(self, bucket_name, file_stream, destination_blob_name,\n                         content_type='application/octet-stream'):\n        \"\"\"\n        Uploads a file to a bucket in Google Cloud Storage using chunked upload.\n\n        Args:\n            bucket_name (str): The name of the bucket.\n            file_stream (BytesIO): The byte stream of the file to upload.\n            destination_blob_name (str): The destination path and file name in the bucket.\n            content_type (str): The content type of the file (default: 'application/octet-stream').\n\n        Returns:\n            tuple: (bool, str) - (True if the file was uploaded successfully, False otherwise;\n                                  The public URL of the uploaded file if successful, None otherwise)\n        \"\"\"\n        try:\n            bucket = self.storage_client.get_bucket(bucket_name)\n            blob = bucket.blob(destination_blob_name)\n\n            chunk_size = 256 * 1024  # 256 KB chunks\n            file_stream.seek(0, 2)\n            file_size = file_stream.tell()\n            file_stream.seek(0)\n\n            with blob.open('wb') as f:\n                uploaded_bytes = 0\n                while True:\n                    chunk = file_stream.read(chunk_size)\n                    if not chunk:\n                        break\n                    f.write(chunk)\n                    uploaded_bytes += len(chunk)\n                    progress = (uploaded_bytes / file_size) * 100\n                    logger.info(f'Upload progress: {progress:.2f}%')\n\n            blob.content_type = content_type\n            blob.patch()\n\n            logger.info(f'File uploaded to {destination_blob_name} in bucket {bucket_name}.')\n            return True, blob.public_url\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to upload to bucket: {str(e)}\")\n            return False, None\n\n    def upload_from_local(self, bucket_name: str, file_path: str, destination_blob_name: str,\n                          content_type='application/octet-stream'):\n        \"\"\"Upload a file to the GCS bucket.\"\"\"\n        try:\n            # Get the bucket from GCS\n            bucket = self.storage_client.get_bucket(bucket_name)\n\n            # Create a blob object with the destination name\n            blob = bucket.blob(destination_blob_name)\n\n            # Upload the file from the local path\n            blob.upload_from_filename(file_path, content_type=content_type)\n\n            logger.info(f\"File {file_path} uploaded to {destination_blob_name} in bucket {bucket_name}.\")\n            return blob\n        except Exception as e:\n            logger.error(f\"Error while uploading to GCS: {str(e)}\", exc_info=True)\n            return None\n\n    def move_folder(self, bucket_name, source_folder, destination_folder):\n        \"\"\"\n        Moves all files from one folder to another within the same Google Cloud Storage bucket.\n\n        Args:\n            bucket_name (str): The name of the bucket.\n            source_folder (str): The path of the source folder.\n            destination_folder (str): The path of the destination folder.\n\n        Returns:\n            bool: True if the folder was moved successfully, False otherwise.\n        \"\"\"\n        try:\n            bucket = self.storage_client.get_bucket(bucket_name)\n\n            # List all blobs in the source folder\n            blobs = list(bucket.list_blobs(prefix=source_folder))\n\n            # Move each blob to the destination folder\n            for blob in blobs:\n                new_name = blob.name.replace(source_folder, destination_folder, 1)\n                new_blob = bucket.rename_blob(blob, new_name)\n                logger.info(f'Moved {blob.name} to {new_blob.name}')\n\n            logger.info(f'All files moved from {source_folder} to {destination_folder} in bucket {bucket_name}.')\n            return True\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to move folder: {str(e)}\")\n            return False\n\n    def move_file(self, bucket_name, source_file_path, destination_file_path):\n        \"\"\"\n        Moves a file from one location to another within the same Google Cloud Storage bucket.\n\n        Args:\n            bucket_name (str): The name of the bucket.\n            source_file_path (str): The full path to the source file.\n            destination_file_path (str): The full path to the destination file.\n\n        Returns:\n            tuple: (bool, str) - (True if the file was moved successfully, False otherwise;\n                                  The public URL of the moved file if successful, None otherwise)\n        \"\"\"\n        try:\n            bucket = self.storage_client.get_bucket(bucket_name)\n\n            # Get the blob (file) object for the source file\n            source_blob = bucket.get_blob(source_file_path)\n\n            if not source_blob:\n                logger.error(f'Source file {source_file_path} not found in bucket {bucket_name}.')\n                return False, None\n\n            # Rename (move) the blob\n            new_blob = bucket.rename_blob(source_blob, destination_file_path)\n            logger.info(f'File {source_file_path} moved to {destination_file_path}.')\n\n            return True, new_blob.public_url\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to move file: {str(e)}\")\n            return False, None\n\n    def delete_folder(self, bucket_name, folder_path):\n        \"\"\"\n        Deletes all files in a folder within a Google Cloud Storage bucket.\n\n        Args:\n            bucket_name (str): The name of the bucket.\n            folder_path (str): The path of the folder to delete.\n\n        Returns:\n            bool: True if the folder was deleted successfully, False otherwise.\n        \"\"\"\n        try:\n            bucket = self.storage_client.get_bucket(bucket_name)\n\n            # List all blobs in the folder\n            blobs = list(bucket.list_blobs(prefix=folder_path))\n\n            # Delete each blob in the folder\n            for blob in blobs:\n                blob.delete()\n                logger.info(f'File {blob.name} deleted.')\n\n            logger.info(f'All files in folder {folder_path} deleted from bucket {bucket_name}.')\n            return True\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to delete folder: {str(e)}\")\n            return False\n\n    def delete_file(self, bucket_name, file_path):\n        \"\"\"\n        Deletes a file in Google Cloud Storage.\n\n        Args:\n            bucket_name (str): The name of the bucket.\n            file_path (str): The full path to the file, including folder(s) and file name.\n\n        Returns:\n            bool: True if the file was deleted successfully, False otherwise.\n        \"\"\"\n        try:\n            bucket = self.storage_client.get_bucket(bucket_name)\n\n            # Get the blob (file) object\n            blob = bucket.blob(file_path)\n\n            # Check if the blob exists\n            if not blob.exists():\n                logger.warning(f'File {file_path} not found in bucket {bucket_name}.')\n                return False\n\n            # Delete the file\n            blob.delete()\n\n            logger.info(f'File {file_path} deleted from bucket {bucket_name}.')\n            return True\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to delete file: {str(e)}\")\n            return False\n\n    async def generate_signed_url(self, bucket_name, file_path, expiration_time_minutes=60):\n        \"\"\"\n        Generates a signed URL for a file in Google Cloud Storage.\n\n        Args:\n            bucket_name (str): The name of the bucket.\n            file_path (str): The full path to the file, including folder(s) and file name.\n            expiration_time_minutes (int): The time in minutes before the URL expires. Defaults to 60 minutes.\n\n        Returns:\n            str: The signed URL if generated successfully, None otherwise.\n        \"\"\"\n        try:\n            bucket = self.storage_client.get_bucket(bucket_name)\n\n            # Get the blob (file) object\n            blob = bucket.blob(file_path)\n\n            if not blob.exists():\n                logger.warning(f\"File {file_path} does not exist in bucket {bucket_name}\")\n                return None\n\n            # Generate a signed URL for the blob\n            url = blob.generate_signed_url(\n                version=\"v4\",\n                expiration=timedelta(minutes=expiration_time_minutes),\n                method=\"GET\"\n            )\n\n            return url\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to generate signed url: {str(e)}\")\n            return None\n\n    def list_buckets(self):\n        \"\"\"\n        Lists all buckets in the Google Cloud Storage project.\n\n        Returns:\n            list: A list of bucket names.\n        \"\"\"\n        try:\n            buckets = self.storage_client.list_buckets()\n\n            # Collect bucket names\n            bucket_names = [bucket.name for bucket in buckets]\n\n            return bucket_names\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to list buckets: {str(e)}\")\n            return []\n\n    def download_file(self, bucket_name, file_path, local_path=None):\n        \"\"\"\n        Downloads a file from a Google Cloud Storage bucket.\n\n        Args:\n            bucket_name (str): The name of the bucket.\n            file_path (str): The full path to the file within the bucket.\n            local_path (str, optional): The local path where the file should be saved.\n                If not provided, the file content will be returned as bytes.\n\n        Returns:\n            Union[bytes, str, None]: If local_path is not provided, returns the file content as bytes.\n                If local_path is provided, returns the path to the saved file.\n                If some error occurs during the download, returns None.\n        \"\"\"\n        try:\n            bucket = self.storage_client.get_bucket(bucket_name)\n            blob = bucket.blob(file_path)\n\n            if not blob.exists():\n                logger.error(f\"File {file_path} not found in bucket {bucket_name}\")\n                return None\n\n            if local_path:\n                blob.download_to_filename(local_path)\n                logger.info(f\"File {file_path} downloaded to {local_path}\")\n                return local_path\n            else:\n                content = blob.download_as_bytes()\n                logger.info(f\"File {file_path} downloaded as bytes\")\n                return content\n\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to download file: {str(e)}\")\n            return None\n</code></pre>"},{"location":"storage/#kal_utils.storage.gcs_storage.GCSStorage.copy_file","title":"<code>copy_file(self, bucket_name, source_file_path, destination_file_path)</code>","text":"<p>Copies a file from one location to another within the same Google Cloud Storage bucket.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The name of the bucket.</p> required <code>source_file_path</code> <code>str</code> <p>The full path to the source file.</p> required <code>destination_file_path</code> <code>str</code> <p>The full path to the destination file.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the file was copied successfully, False otherwise.</p> Source code in <code>kal_utils/storage/gcs_storage.py</code> <pre><code>def copy_file(self, bucket_name, source_file_path, destination_file_path):\n    \"\"\"\n    Copies a file from one location to another within the same Google Cloud Storage bucket.\n\n    Args:\n        bucket_name (str): The name of the bucket.\n        source_file_path (str): The full path to the source file.\n        destination_file_path (str): The full path to the destination file.\n\n    Returns:\n        bool: True if the file was copied successfully, False otherwise.\n    \"\"\"\n    try:\n        bucket = self.storage_client.get_bucket(bucket_name)\n        source_blob = bucket.get_blob(source_file_path)\n\n        if not source_blob:\n            logger.info(f'Source file {source_file_path} not found in bucket {bucket_name}.')\n            return False\n\n        bucket.copy_blob(source_blob, bucket, destination_file_path)\n        logger.info(f'File {source_file_path} copied to {destination_file_path}.')\n        return True\n    except Exception as e:\n        logger.error(f\"Error occurred while trying to copy file: {str(e)}\")\n        return False\n</code></pre>"},{"location":"storage/#kal_utils.storage.gcs_storage.GCSStorage.delete_file","title":"<code>delete_file(self, bucket_name, file_path)</code>","text":"<p>Deletes a file in Google Cloud Storage.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The name of the bucket.</p> required <code>file_path</code> <code>str</code> <p>The full path to the file, including folder(s) and file name.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the file was deleted successfully, False otherwise.</p> Source code in <code>kal_utils/storage/gcs_storage.py</code> <pre><code>def delete_file(self, bucket_name, file_path):\n    \"\"\"\n    Deletes a file in Google Cloud Storage.\n\n    Args:\n        bucket_name (str): The name of the bucket.\n        file_path (str): The full path to the file, including folder(s) and file name.\n\n    Returns:\n        bool: True if the file was deleted successfully, False otherwise.\n    \"\"\"\n    try:\n        bucket = self.storage_client.get_bucket(bucket_name)\n\n        # Get the blob (file) object\n        blob = bucket.blob(file_path)\n\n        # Check if the blob exists\n        if not blob.exists():\n            logger.warning(f'File {file_path} not found in bucket {bucket_name}.')\n            return False\n\n        # Delete the file\n        blob.delete()\n\n        logger.info(f'File {file_path} deleted from bucket {bucket_name}.')\n        return True\n    except Exception as e:\n        logger.error(f\"Error occurred while trying to delete file: {str(e)}\")\n        return False\n</code></pre>"},{"location":"storage/#kal_utils.storage.gcs_storage.GCSStorage.delete_folder","title":"<code>delete_folder(self, bucket_name, folder_path)</code>","text":"<p>Deletes all files in a folder within a Google Cloud Storage bucket.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The name of the bucket.</p> required <code>folder_path</code> <code>str</code> <p>The path of the folder to delete.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the folder was deleted successfully, False otherwise.</p> Source code in <code>kal_utils/storage/gcs_storage.py</code> <pre><code>def delete_folder(self, bucket_name, folder_path):\n    \"\"\"\n    Deletes all files in a folder within a Google Cloud Storage bucket.\n\n    Args:\n        bucket_name (str): The name of the bucket.\n        folder_path (str): The path of the folder to delete.\n\n    Returns:\n        bool: True if the folder was deleted successfully, False otherwise.\n    \"\"\"\n    try:\n        bucket = self.storage_client.get_bucket(bucket_name)\n\n        # List all blobs in the folder\n        blobs = list(bucket.list_blobs(prefix=folder_path))\n\n        # Delete each blob in the folder\n        for blob in blobs:\n            blob.delete()\n            logger.info(f'File {blob.name} deleted.')\n\n        logger.info(f'All files in folder {folder_path} deleted from bucket {bucket_name}.')\n        return True\n    except Exception as e:\n        logger.error(f\"Error occurred while trying to delete folder: {str(e)}\")\n        return False\n</code></pre>"},{"location":"storage/#kal_utils.storage.gcs_storage.GCSStorage.download_file","title":"<code>download_file(self, bucket_name, file_path, local_path=None)</code>","text":"<p>Downloads a file from a Google Cloud Storage bucket.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The name of the bucket.</p> required <code>file_path</code> <code>str</code> <p>The full path to the file within the bucket.</p> required <code>local_path</code> <code>str</code> <p>The local path where the file should be saved. If not provided, the file content will be returned as bytes.</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[bytes, str, None]</code> <p>If local_path is not provided, returns the file content as bytes.     If local_path is provided, returns the path to the saved file.     If some error occurs during the download, returns None.</p> Source code in <code>kal_utils/storage/gcs_storage.py</code> <pre><code>def download_file(self, bucket_name, file_path, local_path=None):\n    \"\"\"\n    Downloads a file from a Google Cloud Storage bucket.\n\n    Args:\n        bucket_name (str): The name of the bucket.\n        file_path (str): The full path to the file within the bucket.\n        local_path (str, optional): The local path where the file should be saved.\n            If not provided, the file content will be returned as bytes.\n\n    Returns:\n        Union[bytes, str, None]: If local_path is not provided, returns the file content as bytes.\n            If local_path is provided, returns the path to the saved file.\n            If some error occurs during the download, returns None.\n    \"\"\"\n    try:\n        bucket = self.storage_client.get_bucket(bucket_name)\n        blob = bucket.blob(file_path)\n\n        if not blob.exists():\n            logger.error(f\"File {file_path} not found in bucket {bucket_name}\")\n            return None\n\n        if local_path:\n            blob.download_to_filename(local_path)\n            logger.info(f\"File {file_path} downloaded to {local_path}\")\n            return local_path\n        else:\n            content = blob.download_as_bytes()\n            logger.info(f\"File {file_path} downloaded as bytes\")\n            return content\n\n    except Exception as e:\n        logger.error(f\"Error occurred while trying to download file: {str(e)}\")\n        return None\n</code></pre>"},{"location":"storage/#kal_utils.storage.gcs_storage.GCSStorage.generate_signed_url","title":"<code>generate_signed_url(self, bucket_name, file_path, expiration_time_minutes=60)</code>  <code>async</code>","text":"<p>Generates a signed URL for a file in Google Cloud Storage.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The name of the bucket.</p> required <code>file_path</code> <code>str</code> <p>The full path to the file, including folder(s) and file name.</p> required <code>expiration_time_minutes</code> <code>int</code> <p>The time in minutes before the URL expires. Defaults to 60 minutes.</p> <code>60</code> <p>Returns:</p> Type Description <code>str</code> <p>The signed URL if generated successfully, None otherwise.</p> Source code in <code>kal_utils/storage/gcs_storage.py</code> <pre><code>async def generate_signed_url(self, bucket_name, file_path, expiration_time_minutes=60):\n    \"\"\"\n    Generates a signed URL for a file in Google Cloud Storage.\n\n    Args:\n        bucket_name (str): The name of the bucket.\n        file_path (str): The full path to the file, including folder(s) and file name.\n        expiration_time_minutes (int): The time in minutes before the URL expires. Defaults to 60 minutes.\n\n    Returns:\n        str: The signed URL if generated successfully, None otherwise.\n    \"\"\"\n    try:\n        bucket = self.storage_client.get_bucket(bucket_name)\n\n        # Get the blob (file) object\n        blob = bucket.blob(file_path)\n\n        if not blob.exists():\n            logger.warning(f\"File {file_path} does not exist in bucket {bucket_name}\")\n            return None\n\n        # Generate a signed URL for the blob\n        url = blob.generate_signed_url(\n            version=\"v4\",\n            expiration=timedelta(minutes=expiration_time_minutes),\n            method=\"GET\"\n        )\n\n        return url\n    except Exception as e:\n        logger.error(f\"Error occurred while trying to generate signed url: {str(e)}\")\n        return None\n</code></pre>"},{"location":"storage/#kal_utils.storage.gcs_storage.GCSStorage.get_bucket_metadata","title":"<code>get_bucket_metadata(self, bucket_name)</code>","text":"<p>Retrieves metadata for a specific bucket in Google Cloud Storage.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The name of the bucket to retrieve metadata for.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing the bucket's metadata.</p> Source code in <code>kal_utils/storage/gcs_storage.py</code> <pre><code>def get_bucket_metadata(self, bucket_name):\n    \"\"\"\n    Retrieves metadata for a specific bucket in Google Cloud Storage.\n\n    Args:\n        bucket_name (str): The name of the bucket to retrieve metadata for.\n\n    Returns:\n        dict: A dictionary containing the bucket's metadata.\n    \"\"\"\n    try:\n        bucket = self.storage_client.get_bucket(bucket_name)\n\n        metadata = {\n            'id': bucket.id,\n            'name': bucket.name,\n            'location': bucket.location,\n            'storage_class': bucket.storage_class,\n            'created': bucket.time_created,\n            'updated': bucket.updated,\n            'default_event_based_hold': bucket.default_event_based_hold,\n            'retention_period': bucket.retention_period,\n            'labels': bucket.labels,\n            'versioning_enabled': bucket.versioning_enabled,\n            'cors': bucket.cors,\n            'lifecycle_rules': bucket.lifecycle_rules,\n            'logging': bucket.logging,\n            'encryption': bucket.encryption,\n            'owner': bucket.owner,\n            'acl': bucket.acl,\n            'default_acl': bucket.default_object_acl,\n        }\n\n        return metadata\n    except Exception as e:\n        logger.error(f\"Error occurred while trying to get bucket metadata: {str(e)}\")\n        return {}\n</code></pre>"},{"location":"storage/#kal_utils.storage.gcs_storage.GCSStorage.get_file_metadata","title":"<code>get_file_metadata(self, bucket_name, file_path)</code>","text":"<p>Retrieves metadata for a specific file in Google Cloud Storage.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The name of the bucket.</p> required <code>file_path</code> <code>str</code> <p>The full path to the file to retrieve metadata for.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing the file's metadata.</p> Source code in <code>kal_utils/storage/gcs_storage.py</code> <pre><code>def get_file_metadata(self, bucket_name, file_path):\n    \"\"\"\n    Retrieves metadata for a specific file in Google Cloud Storage.\n\n    Args:\n        bucket_name (str): The name of the bucket.\n        file_path (str): The full path to the file to retrieve metadata for.\n\n    Returns:\n        dict: A dictionary containing the file's metadata.\n    \"\"\"\n    try:\n        bucket = self.storage_client.get_bucket(bucket_name)\n        blob = bucket.get_blob(file_path)\n\n        if not blob:\n            logger.info(f'File {file_path} not found in bucket {bucket_name}.')\n            return {}\n\n        metadata = {\n            'name': blob.name,\n            'size': blob.size,\n            'content_type': blob.content_type,\n            'updated': blob.updated,\n            'generation': blob.generation,\n            'metageneration': blob.metageneration,\n            'md5_hash': blob.md5_hash,\n            'crc32c': blob.crc32c,\n            'etag': blob.etag,\n            'public_url': blob.public_url\n        }\n\n        return metadata\n    except Exception as e:\n        logger.error(f\"Error occurred while trying to get file metadata: {str(e)}\")\n        return {}\n</code></pre>"},{"location":"storage/#kal_utils.storage.gcs_storage.GCSStorage.list_buckets","title":"<code>list_buckets(self)</code>","text":"<p>Lists all buckets in the Google Cloud Storage project.</p> <p>Returns:</p> Type Description <code>list</code> <p>A list of bucket names.</p> Source code in <code>kal_utils/storage/gcs_storage.py</code> <pre><code>def list_buckets(self):\n    \"\"\"\n    Lists all buckets in the Google Cloud Storage project.\n\n    Returns:\n        list: A list of bucket names.\n    \"\"\"\n    try:\n        buckets = self.storage_client.list_buckets()\n\n        # Collect bucket names\n        bucket_names = [bucket.name for bucket in buckets]\n\n        return bucket_names\n    except Exception as e:\n        logger.error(f\"Error occurred while trying to list buckets: {str(e)}\")\n        return []\n</code></pre>"},{"location":"storage/#kal_utils.storage.gcs_storage.GCSStorage.list_files","title":"<code>list_files(self, bucket_name, prefix=None)</code>","text":"<p>Lists all files in a bucket or a specific folder in Google Cloud Storage.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The name of the bucket.</p> required <code>prefix</code> <code>str</code> <p>The prefix (folder path) to list files from. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>list</code> <p>A list of file names in the specified bucket or folder.</p> Source code in <code>kal_utils/storage/gcs_storage.py</code> <pre><code>def list_files(self, bucket_name, prefix=None):\n    \"\"\"\n    Lists all files in a bucket or a specific folder in Google Cloud Storage.\n\n    Args:\n        bucket_name (str): The name of the bucket.\n        prefix (str, optional): The prefix (folder path) to list files from. Defaults to None.\n\n    Returns:\n        list: A list of file names in the specified bucket or folder.\n    \"\"\"\n    try:\n        bucket = self.storage_client.get_bucket(bucket_name)\n        # List files in the bucket or a specific folder\n        blobs = bucket.list_blobs(prefix=prefix)\n        file_names = [blob.name for blob in blobs]\n        return file_names\n    except Exception as e:\n        logger.error(f\"Error occurred while trying to list files: {str(e)}\")\n        return []\n</code></pre>"},{"location":"storage/#kal_utils.storage.gcs_storage.GCSStorage.move_file","title":"<code>move_file(self, bucket_name, source_file_path, destination_file_path)</code>","text":"<p>Moves a file from one location to another within the same Google Cloud Storage bucket.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The name of the bucket.</p> required <code>source_file_path</code> <code>str</code> <p>The full path to the source file.</p> required <code>destination_file_path</code> <code>str</code> <p>The full path to the destination file.</p> required <p>Returns:</p> Type Description <code>tuple</code> <p>(bool, str) - (True if the file was moved successfully, False otherwise;                       The public URL of the moved file if successful, None otherwise)</p> Source code in <code>kal_utils/storage/gcs_storage.py</code> <pre><code>def move_file(self, bucket_name, source_file_path, destination_file_path):\n    \"\"\"\n    Moves a file from one location to another within the same Google Cloud Storage bucket.\n\n    Args:\n        bucket_name (str): The name of the bucket.\n        source_file_path (str): The full path to the source file.\n        destination_file_path (str): The full path to the destination file.\n\n    Returns:\n        tuple: (bool, str) - (True if the file was moved successfully, False otherwise;\n                              The public URL of the moved file if successful, None otherwise)\n    \"\"\"\n    try:\n        bucket = self.storage_client.get_bucket(bucket_name)\n\n        # Get the blob (file) object for the source file\n        source_blob = bucket.get_blob(source_file_path)\n\n        if not source_blob:\n            logger.error(f'Source file {source_file_path} not found in bucket {bucket_name}.')\n            return False, None\n\n        # Rename (move) the blob\n        new_blob = bucket.rename_blob(source_blob, destination_file_path)\n        logger.info(f'File {source_file_path} moved to {destination_file_path}.')\n\n        return True, new_blob.public_url\n    except Exception as e:\n        logger.error(f\"Error occurred while trying to move file: {str(e)}\")\n        return False, None\n</code></pre>"},{"location":"storage/#kal_utils.storage.gcs_storage.GCSStorage.move_folder","title":"<code>move_folder(self, bucket_name, source_folder, destination_folder)</code>","text":"<p>Moves all files from one folder to another within the same Google Cloud Storage bucket.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The name of the bucket.</p> required <code>source_folder</code> <code>str</code> <p>The path of the source folder.</p> required <code>destination_folder</code> <code>str</code> <p>The path of the destination folder.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the folder was moved successfully, False otherwise.</p> Source code in <code>kal_utils/storage/gcs_storage.py</code> <pre><code>def move_folder(self, bucket_name, source_folder, destination_folder):\n    \"\"\"\n    Moves all files from one folder to another within the same Google Cloud Storage bucket.\n\n    Args:\n        bucket_name (str): The name of the bucket.\n        source_folder (str): The path of the source folder.\n        destination_folder (str): The path of the destination folder.\n\n    Returns:\n        bool: True if the folder was moved successfully, False otherwise.\n    \"\"\"\n    try:\n        bucket = self.storage_client.get_bucket(bucket_name)\n\n        # List all blobs in the source folder\n        blobs = list(bucket.list_blobs(prefix=source_folder))\n\n        # Move each blob to the destination folder\n        for blob in blobs:\n            new_name = blob.name.replace(source_folder, destination_folder, 1)\n            new_blob = bucket.rename_blob(blob, new_name)\n            logger.info(f'Moved {blob.name} to {new_blob.name}')\n\n        logger.info(f'All files moved from {source_folder} to {destination_folder} in bucket {bucket_name}.')\n        return True\n    except Exception as e:\n        logger.error(f\"Error occurred while trying to move folder: {str(e)}\")\n        return False\n</code></pre>"},{"location":"storage/#kal_utils.storage.gcs_storage.GCSStorage.read_file","title":"<code>read_file(self, bucket_name, file_path)</code>","text":"<p>Reads the content of a file from a Google Cloud Storage bucket.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The name of the bucket.</p> required <code>file_path</code> <code>str</code> <p>The path to the file within the bucket.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The content of the file as a string.</p> <p>Exceptions:</p> Type Description <code>Exception</code> <p>If there's an error reading the file.</p> Source code in <code>kal_utils/storage/gcs_storage.py</code> <pre><code>def read_file(self, bucket_name: str, file_path: str) -&gt; str:\n    \"\"\"\n    Reads the content of a file from a Google Cloud Storage bucket.\n\n    Args:\n        bucket_name (str): The name of the bucket.\n        file_path (str): The path to the file within the bucket.\n\n    Returns:\n        str: The content of the file as a string.\n\n    Raises:\n        Exception: If there's an error reading the file.\n    \"\"\"\n    try:\n        bucket = self.storage_client.get_bucket(bucket_name)\n        blob = bucket.blob(file_path)\n        content = blob.download_as_text()\n        return content\n    except Exception as e:\n        logger.error(f\"Error reading file from GCS: {str(e)}\")\n        raise Exception(f\"Error reading file from GCS: {str(e)}\")\n</code></pre>"},{"location":"storage/#kal_utils.storage.gcs_storage.GCSStorage.rename_file","title":"<code>rename_file(self, bucket_name, source_file_folder, source_file_name, new_file_name)</code>","text":"<p>Renames a file in Google Cloud Storage by copying it to a new name and deleting the original.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The name of the bucket.</p> required <code>source_file_folder</code> <code>str</code> <p>The full path to the folder where the file is located.</p> required <code>source_file_name</code> <code>str</code> <p>The current file name.</p> required <code>new_file_name</code> <code>str</code> <p>The new file name.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the file was renamed successfully, False otherwise.</p> Source code in <code>kal_utils/storage/gcs_storage.py</code> <pre><code>def rename_file(self, bucket_name, source_file_folder, source_file_name, new_file_name):\n    \"\"\"\n    Renames a file in Google Cloud Storage by copying it to a new name and deleting the original.\n\n    Args:\n        bucket_name (str): The name of the bucket.\n        source_file_folder (str): The full path to the folder where the file is located.\n        source_file_name (str): The current file name.\n        new_file_name (str): The new file name.\n\n    Returns:\n        bool: True if the file was renamed successfully, False otherwise.\n    \"\"\"\n    try:\n        bucket = self.storage_client.get_bucket(bucket_name)\n\n        source_path = f\"{source_file_folder}/{source_file_name}\"\n        destination_path = f\"{source_file_folder}/{new_file_name}\"\n\n        source_blob = bucket.get_blob(source_path)\n        if not source_blob:\n            logger.error(f'Source file {source_path} not found in bucket {bucket_name}.')\n            return False\n\n        bucket.copy_blob(source_blob, bucket, destination_path)\n        logger.info(f'File {source_path} copied to {destination_path}.')\n\n        source_blob.delete()\n        logger.info(f'Source file {source_path} deleted.')\n\n        return True\n    except Exception as e:\n        logger.error(f\"Error occurred while trying to rename file: {str(e)}\")\n        return False\n</code></pre>"},{"location":"storage/#kal_utils.storage.gcs_storage.GCSStorage.set_bucket_permissions","title":"<code>set_bucket_permissions(self, bucket_name, entity, role)</code>","text":"<p>Sets permissions for a bucket in Google Cloud Storage.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The name of the bucket.</p> required <code>entity</code> <code>str</code> <p>The entity to set permissions for (e.g., 'user-email@example.com', 'group-group@example.com').</p> required <code>role</code> <code>str</code> <p>The role to assign to the entity (e.g., 'OWNER', 'READER', 'WRITER').</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the permissions were set successfully, False otherwise.</p> Source code in <code>kal_utils/storage/gcs_storage.py</code> <pre><code>def set_bucket_permissions(self, bucket_name, entity, role):\n    \"\"\"\n    Sets permissions for a bucket in Google Cloud Storage.\n\n    Args:\n        bucket_name (str): The name of the bucket.\n        entity (str): The entity to set permissions for (e.g., 'user-email@example.com', 'group-group@example.com').\n        role (str): The role to assign to the entity (e.g., 'OWNER', 'READER', 'WRITER').\n\n    Returns:\n        bool: True if the permissions were set successfully, False otherwise.\n    \"\"\"\n    try:\n        bucket = self.storage_client.get_bucket(bucket_name)\n\n        # Get the bucket's ACL\n        acl = bucket.acl\n\n        # Clear existing ACLs for the entity\n        acl.revoke_entity(entity)\n\n        # Add the new permission\n        acl.entity_from_dict({'entity': entity, 'role': role})\n\n        # Save the changes to the ACL\n        acl.save()\n\n        logger.info(f'Permissions for entity {entity} set to {role} on bucket {bucket_name}.')\n        return True\n    except Exception as e:\n        logger.error(f\"Error occurred while trying to set bucket permissions: {str(e)}\")\n        return False\n</code></pre>"},{"location":"storage/#kal_utils.storage.gcs_storage.GCSStorage.set_file_permissions","title":"<code>set_file_permissions(self, bucket_name, file_path, entity, role)</code>","text":"<p>Sets permissions for a specific file in Google Cloud Storage.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The name of the bucket.</p> required <code>file_path</code> <code>str</code> <p>The full path to the file within the bucket.</p> required <code>entity</code> <code>str</code> <p>The entity to set permissions for (e.g., 'user-email@example.com', 'group-group@example.com').</p> required <code>role</code> <code>str</code> <p>The role to assign to the entity (e.g., 'OWNER', 'READER', 'WRITER').</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the permissions were set successfully, False otherwise.</p> Source code in <code>kal_utils/storage/gcs_storage.py</code> <pre><code>def set_file_permissions(self, bucket_name, file_path, entity, role):\n    \"\"\"\n    Sets permissions for a specific file in Google Cloud Storage.\n\n    Args:\n        bucket_name (str): The name of the bucket.\n        file_path (str): The full path to the file within the bucket.\n        entity (str): The entity to set permissions for (e.g., 'user-email@example.com', 'group-group@example.com').\n        role (str): The role to assign to the entity (e.g., 'OWNER', 'READER', 'WRITER').\n\n    Returns:\n        bool: True if the permissions were set successfully, False otherwise.\n    \"\"\"\n    try:\n        bucket = self.storage_client.get_bucket(bucket_name)\n        blob = bucket.get_blob(file_path)\n\n        if not blob:\n            logger.error(f'File {file_path} not found in bucket {bucket_name}.')\n            return False\n\n        # Get the blob's ACL\n        acl = blob.acl\n\n        # Clear existing ACLs for the entity\n        acl.revoke_entity(entity)\n\n        # Add the new permission\n        acl.entity_from_dict({'entity': entity, 'role': role})\n\n        # Save the changes to the ACL\n        acl.save()\n\n        logger.info(f'Permissions set successfully on file {file_path} in bucket {bucket_name}.')\n        return True\n    except Exception as e:\n        logger.error(f\"Error occurred while trying to set file permissions: {str(e)}\")\n        return False\n</code></pre>"},{"location":"storage/#kal_utils.storage.gcs_storage.GCSStorage.upload_from_local","title":"<code>upload_from_local(self, bucket_name, file_path, destination_blob_name, content_type='application/octet-stream')</code>","text":"<p>Upload a file to the GCS bucket.</p> Source code in <code>kal_utils/storage/gcs_storage.py</code> <pre><code>def upload_from_local(self, bucket_name: str, file_path: str, destination_blob_name: str,\n                      content_type='application/octet-stream'):\n    \"\"\"Upload a file to the GCS bucket.\"\"\"\n    try:\n        # Get the bucket from GCS\n        bucket = self.storage_client.get_bucket(bucket_name)\n\n        # Create a blob object with the destination name\n        blob = bucket.blob(destination_blob_name)\n\n        # Upload the file from the local path\n        blob.upload_from_filename(file_path, content_type=content_type)\n\n        logger.info(f\"File {file_path} uploaded to {destination_blob_name} in bucket {bucket_name}.\")\n        return blob\n    except Exception as e:\n        logger.error(f\"Error while uploading to GCS: {str(e)}\", exc_info=True)\n        return None\n</code></pre>"},{"location":"storage/#kal_utils.storage.gcs_storage.GCSStorage.upload_to_bucket","title":"<code>upload_to_bucket(self, bucket_name, file_stream, destination_blob_name, content_type='application/octet-stream')</code>","text":"<p>Uploads a file to a bucket in Google Cloud Storage using chunked upload.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The name of the bucket.</p> required <code>file_stream</code> <code>BytesIO</code> <p>The byte stream of the file to upload.</p> required <code>destination_blob_name</code> <code>str</code> <p>The destination path and file name in the bucket.</p> required <code>content_type</code> <code>str</code> <p>The content type of the file (default: 'application/octet-stream').</p> <code>'application/octet-stream'</code> <p>Returns:</p> Type Description <code>tuple</code> <p>(bool, str) - (True if the file was uploaded successfully, False otherwise;                       The public URL of the uploaded file if successful, None otherwise)</p> Source code in <code>kal_utils/storage/gcs_storage.py</code> <pre><code>def upload_to_bucket(self, bucket_name, file_stream, destination_blob_name,\n                     content_type='application/octet-stream'):\n    \"\"\"\n    Uploads a file to a bucket in Google Cloud Storage using chunked upload.\n\n    Args:\n        bucket_name (str): The name of the bucket.\n        file_stream (BytesIO): The byte stream of the file to upload.\n        destination_blob_name (str): The destination path and file name in the bucket.\n        content_type (str): The content type of the file (default: 'application/octet-stream').\n\n    Returns:\n        tuple: (bool, str) - (True if the file was uploaded successfully, False otherwise;\n                              The public URL of the uploaded file if successful, None otherwise)\n    \"\"\"\n    try:\n        bucket = self.storage_client.get_bucket(bucket_name)\n        blob = bucket.blob(destination_blob_name)\n\n        chunk_size = 256 * 1024  # 256 KB chunks\n        file_stream.seek(0, 2)\n        file_size = file_stream.tell()\n        file_stream.seek(0)\n\n        with blob.open('wb') as f:\n            uploaded_bytes = 0\n            while True:\n                chunk = file_stream.read(chunk_size)\n                if not chunk:\n                    break\n                f.write(chunk)\n                uploaded_bytes += len(chunk)\n                progress = (uploaded_bytes / file_size) * 100\n                logger.info(f'Upload progress: {progress:.2f}%')\n\n        blob.content_type = content_type\n        blob.patch()\n\n        logger.info(f'File uploaded to {destination_blob_name} in bucket {bucket_name}.')\n        return True, blob.public_url\n    except Exception as e:\n        logger.error(f\"Error occurred while trying to upload to bucket: {str(e)}\")\n        return False, None\n</code></pre>"},{"location":"storage/#miniostorage","title":"MinIOStorage","text":"Source code in <code>kal_utils/storage/minio_storage.py</code> <pre><code>class MinIOStorage(BaseStorage):\n    def __init__(self, credentials_json=None):\n        if credentials_json:\n            if os.path.isfile(credentials_json):\n                logger.info(\"Using credentials from file path\")\n                with open(credentials_json, 'r') as f:\n                    minio_creds = json.load(f)\n            else:\n                try:\n                    logger.info(\"Trying to decode base64 credentials\")\n                    decoded_key = base64.b64decode(credentials_json).decode('utf-8')\n                    minio_creds = json.loads(decoded_key)\n                except (base64.binascii.Error, ValueError) as e:\n                    logger.error(\"Failed to decode base64 string, using it as JSON string\")\n                    minio_creds = json.loads(credentials_json)\n\n            self.client = Minio(\n                minio_creds['url'],\n                access_key=minio_creds['accessKey'],\n                secret_key=minio_creds['secretKey'],\n                secure=minio_creds.get('secure', False),\n                cert_check=False\n            )\n            self.url = f\"https://{minio_creds['url']}\" if minio_creds.get('secure', False) else f\"http://{minio_creds['url']}\"\n        else:\n            logger.info(\"credentials is None, trying to initialize storage with environment variables\")\n            if not (os.environ.get('MINIO_ENDPOINT') and os.environ.get('MINIO_ACCESS_KEY') and os.environ.get('MINIO_SECRET_KEY')):\n                logger.error(\"Missing required environment variables for MinIO\")\n            self.client = Minio(\n                os.environ.get('MINIO_ENDPOINT'),\n                access_key=os.environ.get('MINIO_ACCESS_KEY'),\n                secret_key=os.environ.get('MINIO_SECRET_KEY'),\n                secure=os.environ.get('MINIO_SECURE', \"false\") == \"true\",\n                cert_check=False\n            )\n            self.url = f\"https://{os.environ.get('MINIO_ENDPOINT')}\" if os.environ.get('MINIO_SECURE', \"false\") == \"true\" else f\"http://{os.environ.get('MINIO_ENDPOINT')}\"\n\n    def create_bucket(self, bucket_name, location=\"me-west1\", storage_class=\"Standard\"):\n        try:\n            all_chars = string.ascii_letters + string.digits\n            new_name = bucket_name\n            while self.client.bucket_exists(new_name):\n                new_name += random.choice(all_chars)\n\n            self.client.make_bucket(new_name)\n            logger.info(f'Bucket {new_name} created.')\n            return new_name\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to create bucket: {str(e)}\")\n            return None\n\n    def delete_bucket(self, bucket_name):\n        try:\n            self.client.remove_bucket(bucket_name)\n            logger.info(f'Bucket {bucket_name} deleted.')\n            return True\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to delete bucket: {str(e)}\")\n            return False\n\n    def list_files(self, bucket_name, prefix=None):\n        \"\"\"\n        Lists all files in a bucket or a specific folder in MinIO.\n\n        Args:\n            bucket_name (str): The name of the bucket.\n            prefix (str, optional): The prefix (folder path) to list files from. Defaults to None.\n\n        Returns:\n            list: A list of file names in the specified bucket or folder.\n        \"\"\"\n        try:\n            objects = self.client.list_objects(bucket_name, prefix=prefix, recursive=True)\n            file_names = [obj.object_name for obj in objects]\n            return file_names\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to list files: {str(e)}\")\n            return []\n\n    def get_file_metadata(self, bucket_name, file_path):\n        \"\"\"\n        Retrieves metadata for a specific file in MinIO.\n\n        Args:\n            bucket_name (str): The name of the bucket.\n            file_path (str): The full path to the file to retrieve metadata for.\n\n        Returns:\n            dict: A dictionary containing the file's metadata.\n        \"\"\"\n        try:\n            stat = self.client.stat_object(bucket_name, file_path)\n\n            if not stat:\n                logger.info(f'File {file_path} not found in bucket {bucket_name}.')\n                return {}\n\n            metadata = {\n                'name': file_path,\n                'size': stat.size,\n                'content_type': stat.content_type,\n                'updated': stat.last_modified,\n                'etag': stat.etag,\n                'version_id': stat.version_id,\n                'public_url': f\"{self.url}/{bucket_name}/{file_path}\"\n            }\n\n            return metadata\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to get file metadata: {str(e)}\")\n            return {}\n\n    def read_file(self, bucket_name: str, file_path: str) -&gt; str:\n        \"\"\"\n        Reads the content of a file from a MinIO bucket.\n\n        Args:\n            bucket_name (str): The name of the bucket.\n            file_path (str): The path to the file within the bucket.\n\n        Returns:\n            str: The content of the file as a string.\n\n        Raises:\n            Exception: If there's an error reading the file.\n        \"\"\"\n        try:\n            response = self.client.get_object(bucket_name, file_path)\n            content = response.read().decode('utf-8')\n            response.close()\n            response.release_conn()\n            return content\n        except Exception as e:\n            logger.error(f\"Error reading file from MinIO: {str(e)}\")\n            raise Exception(f\"Error reading file from MinIO: {str(e)}\")\n\n    def copy_file(self, bucket_name, source_file_path, destination_file_path):\n        \"\"\"\n        Copies a file from one location to another within the same MinIO bucket.\n\n        Args:\n            bucket_name (str): The name of the bucket.\n            source_file_path (str): The full path to the source file.\n            destination_file_path (str): The full path to the destination file.\n\n        Returns:\n            bool: True if the file was copied successfully, False otherwise.\n        \"\"\"\n        try:\n            source = CopySource(bucket_name, source_file_path)\n\n            result = self.client.copy_object(\n                bucket_name,\n                destination_file_path,\n                source\n            )\n\n            if result.object_name == destination_file_path:\n                logger.info(f'File {source_file_path} copied to {destination_file_path}.')\n                return True\n            else:\n                logger.info(f'Failed to copy file {source_file_path} to {destination_file_path}.')\n                return False\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to copy file: {str(e)}\")\n            return False\n\n    def rename_file(self, bucket_name, source_file_folder, source_file_name, new_file_name):\n        \"\"\"\n        Renames a file in MinIO by copying it to a new name and deleting the original.\n\n        Args:\n            bucket_name (str): The name of the bucket.\n            source_file_folder (str): The full path to the folder where the file is located.\n            source_file_name (str): The current file name.\n            new_file_name (str): The new file name.\n\n        Returns:\n            bool: True if the file was renamed successfully, False otherwise.\n        \"\"\"\n        try:\n            source_path = f\"{source_file_folder}/{source_file_name}\"\n            destination_path = f\"{source_file_folder}/{new_file_name}\"\n\n            # Create a CopySource object for the source file\n            source = CopySource(bucket_name, source_path)\n\n            # Copy the object\n            result = self.client.copy_object(bucket_name, destination_path, source)\n\n            if result.object_name == destination_path:\n                # If copy was successful, remove the original file\n                self.client.remove_object(bucket_name, source_path)\n                logger.info(f'File renamed from {source_path} to {destination_path}.')\n                return True\n            else:\n                logger.info(f'Failed to rename file from {source_path} to {destination_path}.')\n                return False\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to rename file: {str(e)}\")\n            return False\n\n    def get_bucket_metadata(self, bucket_name):\n        \"\"\"\n        Retrieves metadata for a specific bucket in MinIO.\n\n        Args:\n            bucket_name (str): The name of the bucket to retrieve metadata for.\n\n        Returns:\n            dict: A dictionary containing the bucket's metadata.\n        \"\"\"\n        try:\n            # Check if the bucket exists\n            if not self.client.bucket_exists(bucket_name):\n                logger.error(f\"Bucket {bucket_name} does not exist.\")\n                return {}\n\n            # Get bucket policy\n            policy = self.client.get_bucket_policy(bucket_name)\n\n            # Get bucket versioning\n            versioning = self.client.get_bucket_versioning(bucket_name)\n\n            # Get bucket tags\n            tags = self.client.get_bucket_tags(bucket_name)\n\n            metadata = {\n                'name': bucket_name,\n                'policy': policy,\n                'versioning': versioning,\n                'tags': tags,\n            }\n\n            return metadata\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to get bucket metadata: {str(e)}\")\n            return {}\n\n    def set_bucket_permissions(self, bucket_name, entity, role):\n        \"\"\"\n        Sets permissions for a bucket in MinIO.\n\n        Args:\n            bucket_name (str): The name of the bucket.\n            entity (str): The entity to set permissions for (e.g., 'user-email@example.com', 'group-group@example.com').\n            role (str): The role to assign to the entity (e.g., 'OWNER', 'READER', 'WRITER').\n\n        Returns:\n            bool: True if the permissions were set successfully, False otherwise.\n        \"\"\"\n        try:\n            # Map GCS roles to MinIO policy actions\n            role_to_actions = {\n                'READER': ['s3:GetBucketLocation', 's3:ListBucket', 's3:GetObject'],\n                'WRITER': ['s3:GetBucketLocation', 's3:ListBucket', 's3:GetObject', 's3:PutObject', 's3:DeleteObject'],\n                'OWNER': ['s3:*'],\n            }\n\n            if role not in role_to_actions:\n                raise ValueError(f\"Unsupported role: {role}\")\n\n            actions = role_to_actions[role]\n\n            # Create a policy document\n            policy = {\n                \"Version\": \"2012-10-17\",\n                \"Statement\": [\n                    {\n                        \"Effect\": \"Allow\",\n                        \"Principal\": {\"AWS\": [entity]},\n                        \"Action\": actions,\n                        \"Resource\": [f\"arn:aws:s3:::{bucket_name}\", f\"arn:aws:s3:::{bucket_name}/*\"]\n                    }\n                ]\n            }\n\n            # Convert the policy to JSON string\n            policy_str = json.dumps(policy)\n\n            # Set the bucket policy\n            self.client.set_bucket_policy(bucket_name, policy_str)\n\n            logger.info(f'Permissions for entity {entity} set to {role} on bucket {bucket_name}.')\n            return True\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to set bucket permissions: {str(e)}\")\n            return False\n\n    def set_file_permissions(self, bucket_name, file_path, entity, role):\n        \"\"\"\n        Sets permissions for a specific file in MinIO.\n        Note: MinIO doesn't support object-level ACLs directly. This method sets a bucket policy\n        that affects the specified object.\n\n        Args:\n            bucket_name (str): The name of the bucket.\n            file_path (str): The full path to the file within the bucket.\n            entity (str): The entity to set permissions for (e.g., 'user-email@example.com', 'group-group@example.com').\n            role (str): The role to assign to the entity (e.g., 'OWNER', 'READER', 'WRITER').\n\n        Returns:\n            bool: True if the permissions were set successfully, False otherwise.\n        \"\"\"\n        try:\n            # Map GCS roles to MinIO policy actions\n            role_to_actions = {\n                'READER': ['s3:GetObject'],\n                'WRITER': ['s3:GetObject', 's3:PutObject', 's3:DeleteObject'],\n                'OWNER': ['s3:*'],\n            }\n\n            if role not in role_to_actions:\n                raise ValueError(f\"Unsupported role: {role}\")\n\n            actions = role_to_actions[role]\n\n            # Create a policy document\n            policy = {\n                \"Version\": \"2012-10-17\",\n                \"Statement\": [\n                    {\n                        \"Effect\": \"Allow\",\n                        \"Principal\": {\"AWS\": [entity]},\n                        \"Action\": actions,\n                        \"Resource\": [f\"arn:aws:s3:::{bucket_name}/{file_path}\"]\n                    }\n                ]\n            }\n\n            # Convert the policy to JSON string\n            policy_str = json.dumps(policy)\n\n            # Get the current bucket policy\n            current_policy = self.client.get_bucket_policy(bucket_name)\n\n            # Merge the new policy with the existing one\n            # This is a simplistic approach and might need to be more sophisticated\n            # depending on your exact requirements\n            if current_policy:\n                current_policy_json = json.loads(current_policy)\n                current_policy_json['Statement'].append(policy['Statement'][0])\n                policy_str = json.dumps(current_policy_json)\n\n            # Set the updated bucket policy\n            self.client.set_bucket_policy(bucket_name, policy_str)\n\n            logger.info(f'Permissions set successfully on file {file_path} in bucket {bucket_name}.')\n            return True\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to set file permissions: {str(e)}\")\n            return False\n\n    def upload_to_bucket(self, bucket_name, file_stream, destination_blob_name, content_type='application/octet-stream'):\n        \"\"\"\n        Uploads a file to a bucket in MinIO.\n\n        Args:\n            bucket_name (str): The name of the bucket.\n            file_stream (BytesIO): The byte stream of the file to upload.\n            destination_blob_name (str): The destination path and file name in the bucket.\n\n        Returns:\n            tuple: (bool, str) - (True if the file was uploaded successfully, False otherwise;\n                                  The public URL of the uploaded file if successful, None otherwise)\n        \"\"\"\n        try:\n            # Get the length of the file stream\n            file_stream.seek(0, 2)  # Go to the end of the stream\n            file_size = file_stream.tell()  # Get the position (size)\n            file_stream.seek(0)  # Go back to the beginning of the stream\n\n            # Upload the file to MinIO\n            self.client.put_object(\n                bucket_name,\n                destination_blob_name,\n                file_stream,\n                file_size,\n                content_type=content_type\n            )\n\n            logger.info(f'File uploaded to {destination_blob_name} in bucket {bucket_name}.')\n\n            # Generate a presigned URL for the uploaded object\n            # Note: This URL will expire after the specified time\n            url = f\"{self.url}/{bucket_name}/{destination_blob_name}\"\n\n            return True, url\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to upload to bucket: {str(e)}\")\n            return False, None\n\n    def upload_from_local(self, bucket_name: str, file_path: str, destination_blob_name: str,\n                          content_type='application/octet-stream'):\n        \"\"\"Upload a file to the MinIO bucket.\"\"\"\n        try:\n            # Get the size of the file to upload\n            file_size = os.stat(file_path).st_size\n\n            # Open the file and upload it using MinIO's `put_object`\n            with open(file_path, 'rb') as file_data:\n                self.client.put_object(\n                    bucket_name=bucket_name,\n                    object_name=destination_blob_name,\n                    data=file_data,\n                    length=file_size,\n                    content_type=content_type\n                )\n\n            logger.info(f\"File {file_path} uploaded to {destination_blob_name} in bucket {bucket_name}.\")\n            return True\n        except Exception as e:\n            logger.error(f\"Error while uploading to MinIO: {str(e)}\", exc_info=True)\n            return False\n\n    def move_folder(self, bucket_name, source_folder, destination_folder):\n        \"\"\"\n        Moves all files from one folder to another within the same MinIO bucket.\n\n        Args:\n            bucket_name (str): The name of the bucket.\n            source_folder (str): The path of the source folder.\n            destination_folder (str): The path of the destination folder.\n\n        Returns:\n            bool: True if the folder was moved successfully, False otherwise.\n        \"\"\"\n        try:\n            # List all objects in the source folder\n            objects = self.client.list_objects(bucket_name, prefix=source_folder, recursive=True)\n\n            for obj in objects:\n                # Construct the new object name\n                new_name = obj.object_name.replace(source_folder, destination_folder, 1)\n\n                # Copy the object to the new location\n                result = self.client.copy_object(\n                    bucket_name,\n                    new_name,\n                    CopySource(bucket_name, obj.object_name)\n                )\n\n                # If copy was successful, remove the original object\n                if result:\n                    self.client.remove_object(bucket_name, obj.object_name)\n                    logger.info(f'Moved {obj.object_name} to {new_name}')\n                else:\n                    logger.warning(f'Failed to move {obj.object_name}')\n\n            logger.info(f'All files moved from {source_folder} to {destination_folder} in bucket {bucket_name}.')\n            return True\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to move folder: {str(e)}\")\n            return False\n\n    def move_file(self, bucket_name, source_file_path, destination_file_path):\n        \"\"\"\n        Moves a file from one location to another within the same MinIO bucket.\n\n        Args:\n            bucket_name (str): The name of the bucket.\n            source_file_path (str): The full path to the source file.\n            destination_file_path (str): The full path to the destination file.\n\n        Returns:\n            tuple: (bool, str) - (True if the file was moved successfully, False otherwise;\n                                  The URL of the moved file if successful, None otherwise)\n        \"\"\"\n        try:\n            # Copy the object to the new location\n            result = self.client.copy_object(\n                bucket_name,\n                destination_file_path,\n                CopySource(bucket_name, source_file_path)\n            )\n\n            if result:\n                # If copy was successful, remove the original object\n                self.client.remove_object(bucket_name, source_file_path)\n                logger.info(f'File {source_file_path} moved to {destination_file_path}.')\n\n                # Generate a URL for the moved file\n                # Note: This generates a pre-signed URL that will expire\n                url = f\"{self.url}/{bucket_name}/{destination_file_path}\"\n\n                return True, url\n            else:\n                logger.error(f'Failed to move file {source_file_path}.')\n                return False, None\n\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to move file: {str(e)}\")\n            return False, None\n\n    def delete_folder(self, bucket_name, folder_path):\n        \"\"\"\n        Deletes all files in a folder within a MinIO bucket.\n\n        Args:\n            bucket_name (str): The name of the bucket.\n            folder_path (str): The path of the folder to delete.\n\n        Returns:\n            bool: True if the folder was deleted successfully, False otherwise.\n        \"\"\"\n        try:\n            # List all objects in the folder\n            objects = self.client.list_objects(bucket_name, prefix=folder_path, recursive=True)\n\n            # Delete each object in the folder\n            for obj in objects:\n                self.client.remove_object(bucket_name, obj.object_name)\n                logger.info(f'File {obj.object_name} deleted.')\n\n            logger.info(f'All files in folder {folder_path} deleted from bucket {bucket_name}.')\n            return True\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to delete folder: {str(e)}\")\n            return False\n\n    def delete_file(self, bucket_name, file_path):\n        \"\"\"\n        Deletes a file in MinIO.\n\n        Args:\n            bucket_name (str): The name of the bucket.\n            file_path (str): The full path to the file, including folder(s) and file name.\n\n        Returns:\n            bool: True if the file was deleted successfully, False otherwise.\n        \"\"\"\n        try:\n            # Check if the object exists\n            try:\n                self.client.stat_object(bucket_name, file_path)\n            except Exception:\n                logger.warning(f'File {file_path} not found in bucket {bucket_name}.')\n                return False\n\n            # Delete the file\n            self.client.remove_object(bucket_name, file_path)\n\n            logger.info(f'File {file_path} deleted from bucket {bucket_name}.')\n            return True\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to delete file: {str(e)}\")\n            return False\n\n    async def generate_signed_url(self, bucket_name, file_path, expiration_time_minutes=60):\n        \"\"\"\n        Generates a presigned URL for a file in MinIO.\n\n        Args:\n            bucket_name (str): The name of the bucket.\n            file_path (str): The full path to the file, including folder(s) and file name.\n            expiration_time_minutes (int): The time in minutes before the URL expires. Defaults to 60 minutes.\n\n        Returns:\n            str: The presigned URL if generated successfully, None otherwise.\n        \"\"\"\n        try:\n            # Check if the object exists\n            try:\n                self.client.stat_object(bucket_name, file_path)\n            except Exception:\n                logger.warning(f\"File {file_path} does not exist in bucket {bucket_name}\")\n                return None\n\n            # Generate a presigned URL for the object\n            url = self.client.presigned_get_object(\n                bucket_name,\n                file_path,\n                expires=timedelta(minutes=expiration_time_minutes)\n            )\n\n            return url\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to generate signed url: {str(e)}\")\n            return None\n\n    def list_buckets(self):\n        \"\"\"\n        Lists all buckets in the MinIO instance.\n\n        Returns:\n            list: A list of bucket names.\n        \"\"\"\n        try:\n            buckets = self.client.list_buckets()\n\n            # Collect bucket names\n            bucket_names = [bucket.name for bucket in buckets]\n\n            return bucket_names\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to list buckets: {str(e)}\")\n            return []\n\n\n    def download_file(self, bucket_name, file_path, local_path=None):\n        \"\"\"\n        Downloads a file from a MinIO bucket.\n\n        Args:\n            bucket_name (str): The name of the bucket.\n            file_path (str): The full path to the file within the bucket.\n            local_path (str, optional): The local path where the file should be saved.\n                If not provided, the file content will be returned as bytes.\n\n        Returns:\n            Union[bytes, str, None]: If local_path is not provided, returns the file content as bytes.\n                If local_path is provided, returns the path to the saved file.\n                If some error occurs during the download, returns None.\n        \"\"\"\n        try:\n            # Check if the object exists\n            try:\n                self.client.stat_object(bucket_name, file_path)\n            except Exception:\n                logger.error(f\"File {file_path} not found in bucket {bucket_name}\")\n                return None\n\n            if local_path:\n                self.client.fget_object(bucket_name, file_path, local_path)\n                logger.info(f\"File {file_path} downloaded to {local_path}\")\n                return local_path\n            else:\n                response = self.client.get_object(bucket_name, file_path)\n                content = response.read()\n                response.close()\n                response.release_conn()\n                logger.info(f\"File {file_path} downloaded as bytes\")\n                return content\n\n        except Exception as e:\n            logger.error(f\"Error occurred while trying to download file: {str(e)}\")\n            return None\n</code></pre>"},{"location":"storage/#kal_utils.storage.minio_storage.MinIOStorage.copy_file","title":"<code>copy_file(self, bucket_name, source_file_path, destination_file_path)</code>","text":"<p>Copies a file from one location to another within the same MinIO bucket.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The name of the bucket.</p> required <code>source_file_path</code> <code>str</code> <p>The full path to the source file.</p> required <code>destination_file_path</code> <code>str</code> <p>The full path to the destination file.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the file was copied successfully, False otherwise.</p> Source code in <code>kal_utils/storage/minio_storage.py</code> <pre><code>def copy_file(self, bucket_name, source_file_path, destination_file_path):\n    \"\"\"\n    Copies a file from one location to another within the same MinIO bucket.\n\n    Args:\n        bucket_name (str): The name of the bucket.\n        source_file_path (str): The full path to the source file.\n        destination_file_path (str): The full path to the destination file.\n\n    Returns:\n        bool: True if the file was copied successfully, False otherwise.\n    \"\"\"\n    try:\n        source = CopySource(bucket_name, source_file_path)\n\n        result = self.client.copy_object(\n            bucket_name,\n            destination_file_path,\n            source\n        )\n\n        if result.object_name == destination_file_path:\n            logger.info(f'File {source_file_path} copied to {destination_file_path}.')\n            return True\n        else:\n            logger.info(f'Failed to copy file {source_file_path} to {destination_file_path}.')\n            return False\n    except Exception as e:\n        logger.error(f\"Error occurred while trying to copy file: {str(e)}\")\n        return False\n</code></pre>"},{"location":"storage/#kal_utils.storage.minio_storage.MinIOStorage.delete_file","title":"<code>delete_file(self, bucket_name, file_path)</code>","text":"<p>Deletes a file in MinIO.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The name of the bucket.</p> required <code>file_path</code> <code>str</code> <p>The full path to the file, including folder(s) and file name.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the file was deleted successfully, False otherwise.</p> Source code in <code>kal_utils/storage/minio_storage.py</code> <pre><code>def delete_file(self, bucket_name, file_path):\n    \"\"\"\n    Deletes a file in MinIO.\n\n    Args:\n        bucket_name (str): The name of the bucket.\n        file_path (str): The full path to the file, including folder(s) and file name.\n\n    Returns:\n        bool: True if the file was deleted successfully, False otherwise.\n    \"\"\"\n    try:\n        # Check if the object exists\n        try:\n            self.client.stat_object(bucket_name, file_path)\n        except Exception:\n            logger.warning(f'File {file_path} not found in bucket {bucket_name}.')\n            return False\n\n        # Delete the file\n        self.client.remove_object(bucket_name, file_path)\n\n        logger.info(f'File {file_path} deleted from bucket {bucket_name}.')\n        return True\n    except Exception as e:\n        logger.error(f\"Error occurred while trying to delete file: {str(e)}\")\n        return False\n</code></pre>"},{"location":"storage/#kal_utils.storage.minio_storage.MinIOStorage.delete_folder","title":"<code>delete_folder(self, bucket_name, folder_path)</code>","text":"<p>Deletes all files in a folder within a MinIO bucket.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The name of the bucket.</p> required <code>folder_path</code> <code>str</code> <p>The path of the folder to delete.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the folder was deleted successfully, False otherwise.</p> Source code in <code>kal_utils/storage/minio_storage.py</code> <pre><code>def delete_folder(self, bucket_name, folder_path):\n    \"\"\"\n    Deletes all files in a folder within a MinIO bucket.\n\n    Args:\n        bucket_name (str): The name of the bucket.\n        folder_path (str): The path of the folder to delete.\n\n    Returns:\n        bool: True if the folder was deleted successfully, False otherwise.\n    \"\"\"\n    try:\n        # List all objects in the folder\n        objects = self.client.list_objects(bucket_name, prefix=folder_path, recursive=True)\n\n        # Delete each object in the folder\n        for obj in objects:\n            self.client.remove_object(bucket_name, obj.object_name)\n            logger.info(f'File {obj.object_name} deleted.')\n\n        logger.info(f'All files in folder {folder_path} deleted from bucket {bucket_name}.')\n        return True\n    except Exception as e:\n        logger.error(f\"Error occurred while trying to delete folder: {str(e)}\")\n        return False\n</code></pre>"},{"location":"storage/#kal_utils.storage.minio_storage.MinIOStorage.download_file","title":"<code>download_file(self, bucket_name, file_path, local_path=None)</code>","text":"<p>Downloads a file from a MinIO bucket.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The name of the bucket.</p> required <code>file_path</code> <code>str</code> <p>The full path to the file within the bucket.</p> required <code>local_path</code> <code>str</code> <p>The local path where the file should be saved. If not provided, the file content will be returned as bytes.</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[bytes, str, None]</code> <p>If local_path is not provided, returns the file content as bytes.     If local_path is provided, returns the path to the saved file.     If some error occurs during the download, returns None.</p> Source code in <code>kal_utils/storage/minio_storage.py</code> <pre><code>def download_file(self, bucket_name, file_path, local_path=None):\n    \"\"\"\n    Downloads a file from a MinIO bucket.\n\n    Args:\n        bucket_name (str): The name of the bucket.\n        file_path (str): The full path to the file within the bucket.\n        local_path (str, optional): The local path where the file should be saved.\n            If not provided, the file content will be returned as bytes.\n\n    Returns:\n        Union[bytes, str, None]: If local_path is not provided, returns the file content as bytes.\n            If local_path is provided, returns the path to the saved file.\n            If some error occurs during the download, returns None.\n    \"\"\"\n    try:\n        # Check if the object exists\n        try:\n            self.client.stat_object(bucket_name, file_path)\n        except Exception:\n            logger.error(f\"File {file_path} not found in bucket {bucket_name}\")\n            return None\n\n        if local_path:\n            self.client.fget_object(bucket_name, file_path, local_path)\n            logger.info(f\"File {file_path} downloaded to {local_path}\")\n            return local_path\n        else:\n            response = self.client.get_object(bucket_name, file_path)\n            content = response.read()\n            response.close()\n            response.release_conn()\n            logger.info(f\"File {file_path} downloaded as bytes\")\n            return content\n\n    except Exception as e:\n        logger.error(f\"Error occurred while trying to download file: {str(e)}\")\n        return None\n</code></pre>"},{"location":"storage/#kal_utils.storage.minio_storage.MinIOStorage.generate_signed_url","title":"<code>generate_signed_url(self, bucket_name, file_path, expiration_time_minutes=60)</code>  <code>async</code>","text":"<p>Generates a presigned URL for a file in MinIO.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The name of the bucket.</p> required <code>file_path</code> <code>str</code> <p>The full path to the file, including folder(s) and file name.</p> required <code>expiration_time_minutes</code> <code>int</code> <p>The time in minutes before the URL expires. Defaults to 60 minutes.</p> <code>60</code> <p>Returns:</p> Type Description <code>str</code> <p>The presigned URL if generated successfully, None otherwise.</p> Source code in <code>kal_utils/storage/minio_storage.py</code> <pre><code>async def generate_signed_url(self, bucket_name, file_path, expiration_time_minutes=60):\n    \"\"\"\n    Generates a presigned URL for a file in MinIO.\n\n    Args:\n        bucket_name (str): The name of the bucket.\n        file_path (str): The full path to the file, including folder(s) and file name.\n        expiration_time_minutes (int): The time in minutes before the URL expires. Defaults to 60 minutes.\n\n    Returns:\n        str: The presigned URL if generated successfully, None otherwise.\n    \"\"\"\n    try:\n        # Check if the object exists\n        try:\n            self.client.stat_object(bucket_name, file_path)\n        except Exception:\n            logger.warning(f\"File {file_path} does not exist in bucket {bucket_name}\")\n            return None\n\n        # Generate a presigned URL for the object\n        url = self.client.presigned_get_object(\n            bucket_name,\n            file_path,\n            expires=timedelta(minutes=expiration_time_minutes)\n        )\n\n        return url\n    except Exception as e:\n        logger.error(f\"Error occurred while trying to generate signed url: {str(e)}\")\n        return None\n</code></pre>"},{"location":"storage/#kal_utils.storage.minio_storage.MinIOStorage.get_bucket_metadata","title":"<code>get_bucket_metadata(self, bucket_name)</code>","text":"<p>Retrieves metadata for a specific bucket in MinIO.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The name of the bucket to retrieve metadata for.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing the bucket's metadata.</p> Source code in <code>kal_utils/storage/minio_storage.py</code> <pre><code>def get_bucket_metadata(self, bucket_name):\n    \"\"\"\n    Retrieves metadata for a specific bucket in MinIO.\n\n    Args:\n        bucket_name (str): The name of the bucket to retrieve metadata for.\n\n    Returns:\n        dict: A dictionary containing the bucket's metadata.\n    \"\"\"\n    try:\n        # Check if the bucket exists\n        if not self.client.bucket_exists(bucket_name):\n            logger.error(f\"Bucket {bucket_name} does not exist.\")\n            return {}\n\n        # Get bucket policy\n        policy = self.client.get_bucket_policy(bucket_name)\n\n        # Get bucket versioning\n        versioning = self.client.get_bucket_versioning(bucket_name)\n\n        # Get bucket tags\n        tags = self.client.get_bucket_tags(bucket_name)\n\n        metadata = {\n            'name': bucket_name,\n            'policy': policy,\n            'versioning': versioning,\n            'tags': tags,\n        }\n\n        return metadata\n    except Exception as e:\n        logger.error(f\"Error occurred while trying to get bucket metadata: {str(e)}\")\n        return {}\n</code></pre>"},{"location":"storage/#kal_utils.storage.minio_storage.MinIOStorage.get_file_metadata","title":"<code>get_file_metadata(self, bucket_name, file_path)</code>","text":"<p>Retrieves metadata for a specific file in MinIO.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The name of the bucket.</p> required <code>file_path</code> <code>str</code> <p>The full path to the file to retrieve metadata for.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing the file's metadata.</p> Source code in <code>kal_utils/storage/minio_storage.py</code> <pre><code>def get_file_metadata(self, bucket_name, file_path):\n    \"\"\"\n    Retrieves metadata for a specific file in MinIO.\n\n    Args:\n        bucket_name (str): The name of the bucket.\n        file_path (str): The full path to the file to retrieve metadata for.\n\n    Returns:\n        dict: A dictionary containing the file's metadata.\n    \"\"\"\n    try:\n        stat = self.client.stat_object(bucket_name, file_path)\n\n        if not stat:\n            logger.info(f'File {file_path} not found in bucket {bucket_name}.')\n            return {}\n\n        metadata = {\n            'name': file_path,\n            'size': stat.size,\n            'content_type': stat.content_type,\n            'updated': stat.last_modified,\n            'etag': stat.etag,\n            'version_id': stat.version_id,\n            'public_url': f\"{self.url}/{bucket_name}/{file_path}\"\n        }\n\n        return metadata\n    except Exception as e:\n        logger.error(f\"Error occurred while trying to get file metadata: {str(e)}\")\n        return {}\n</code></pre>"},{"location":"storage/#kal_utils.storage.minio_storage.MinIOStorage.list_buckets","title":"<code>list_buckets(self)</code>","text":"<p>Lists all buckets in the MinIO instance.</p> <p>Returns:</p> Type Description <code>list</code> <p>A list of bucket names.</p> Source code in <code>kal_utils/storage/minio_storage.py</code> <pre><code>def list_buckets(self):\n    \"\"\"\n    Lists all buckets in the MinIO instance.\n\n    Returns:\n        list: A list of bucket names.\n    \"\"\"\n    try:\n        buckets = self.client.list_buckets()\n\n        # Collect bucket names\n        bucket_names = [bucket.name for bucket in buckets]\n\n        return bucket_names\n    except Exception as e:\n        logger.error(f\"Error occurred while trying to list buckets: {str(e)}\")\n        return []\n</code></pre>"},{"location":"storage/#kal_utils.storage.minio_storage.MinIOStorage.list_files","title":"<code>list_files(self, bucket_name, prefix=None)</code>","text":"<p>Lists all files in a bucket or a specific folder in MinIO.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The name of the bucket.</p> required <code>prefix</code> <code>str</code> <p>The prefix (folder path) to list files from. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>list</code> <p>A list of file names in the specified bucket or folder.</p> Source code in <code>kal_utils/storage/minio_storage.py</code> <pre><code>def list_files(self, bucket_name, prefix=None):\n    \"\"\"\n    Lists all files in a bucket or a specific folder in MinIO.\n\n    Args:\n        bucket_name (str): The name of the bucket.\n        prefix (str, optional): The prefix (folder path) to list files from. Defaults to None.\n\n    Returns:\n        list: A list of file names in the specified bucket or folder.\n    \"\"\"\n    try:\n        objects = self.client.list_objects(bucket_name, prefix=prefix, recursive=True)\n        file_names = [obj.object_name for obj in objects]\n        return file_names\n    except Exception as e:\n        logger.error(f\"Error occurred while trying to list files: {str(e)}\")\n        return []\n</code></pre>"},{"location":"storage/#kal_utils.storage.minio_storage.MinIOStorage.move_file","title":"<code>move_file(self, bucket_name, source_file_path, destination_file_path)</code>","text":"<p>Moves a file from one location to another within the same MinIO bucket.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The name of the bucket.</p> required <code>source_file_path</code> <code>str</code> <p>The full path to the source file.</p> required <code>destination_file_path</code> <code>str</code> <p>The full path to the destination file.</p> required <p>Returns:</p> Type Description <code>tuple</code> <p>(bool, str) - (True if the file was moved successfully, False otherwise;                       The URL of the moved file if successful, None otherwise)</p> Source code in <code>kal_utils/storage/minio_storage.py</code> <pre><code>def move_file(self, bucket_name, source_file_path, destination_file_path):\n    \"\"\"\n    Moves a file from one location to another within the same MinIO bucket.\n\n    Args:\n        bucket_name (str): The name of the bucket.\n        source_file_path (str): The full path to the source file.\n        destination_file_path (str): The full path to the destination file.\n\n    Returns:\n        tuple: (bool, str) - (True if the file was moved successfully, False otherwise;\n                              The URL of the moved file if successful, None otherwise)\n    \"\"\"\n    try:\n        # Copy the object to the new location\n        result = self.client.copy_object(\n            bucket_name,\n            destination_file_path,\n            CopySource(bucket_name, source_file_path)\n        )\n\n        if result:\n            # If copy was successful, remove the original object\n            self.client.remove_object(bucket_name, source_file_path)\n            logger.info(f'File {source_file_path} moved to {destination_file_path}.')\n\n            # Generate a URL for the moved file\n            # Note: This generates a pre-signed URL that will expire\n            url = f\"{self.url}/{bucket_name}/{destination_file_path}\"\n\n            return True, url\n        else:\n            logger.error(f'Failed to move file {source_file_path}.')\n            return False, None\n\n    except Exception as e:\n        logger.error(f\"Error occurred while trying to move file: {str(e)}\")\n        return False, None\n</code></pre>"},{"location":"storage/#kal_utils.storage.minio_storage.MinIOStorage.move_folder","title":"<code>move_folder(self, bucket_name, source_folder, destination_folder)</code>","text":"<p>Moves all files from one folder to another within the same MinIO bucket.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The name of the bucket.</p> required <code>source_folder</code> <code>str</code> <p>The path of the source folder.</p> required <code>destination_folder</code> <code>str</code> <p>The path of the destination folder.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the folder was moved successfully, False otherwise.</p> Source code in <code>kal_utils/storage/minio_storage.py</code> <pre><code>def move_folder(self, bucket_name, source_folder, destination_folder):\n    \"\"\"\n    Moves all files from one folder to another within the same MinIO bucket.\n\n    Args:\n        bucket_name (str): The name of the bucket.\n        source_folder (str): The path of the source folder.\n        destination_folder (str): The path of the destination folder.\n\n    Returns:\n        bool: True if the folder was moved successfully, False otherwise.\n    \"\"\"\n    try:\n        # List all objects in the source folder\n        objects = self.client.list_objects(bucket_name, prefix=source_folder, recursive=True)\n\n        for obj in objects:\n            # Construct the new object name\n            new_name = obj.object_name.replace(source_folder, destination_folder, 1)\n\n            # Copy the object to the new location\n            result = self.client.copy_object(\n                bucket_name,\n                new_name,\n                CopySource(bucket_name, obj.object_name)\n            )\n\n            # If copy was successful, remove the original object\n            if result:\n                self.client.remove_object(bucket_name, obj.object_name)\n                logger.info(f'Moved {obj.object_name} to {new_name}')\n            else:\n                logger.warning(f'Failed to move {obj.object_name}')\n\n        logger.info(f'All files moved from {source_folder} to {destination_folder} in bucket {bucket_name}.')\n        return True\n    except Exception as e:\n        logger.error(f\"Error occurred while trying to move folder: {str(e)}\")\n        return False\n</code></pre>"},{"location":"storage/#kal_utils.storage.minio_storage.MinIOStorage.read_file","title":"<code>read_file(self, bucket_name, file_path)</code>","text":"<p>Reads the content of a file from a MinIO bucket.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The name of the bucket.</p> required <code>file_path</code> <code>str</code> <p>The path to the file within the bucket.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The content of the file as a string.</p> <p>Exceptions:</p> Type Description <code>Exception</code> <p>If there's an error reading the file.</p> Source code in <code>kal_utils/storage/minio_storage.py</code> <pre><code>def read_file(self, bucket_name: str, file_path: str) -&gt; str:\n    \"\"\"\n    Reads the content of a file from a MinIO bucket.\n\n    Args:\n        bucket_name (str): The name of the bucket.\n        file_path (str): The path to the file within the bucket.\n\n    Returns:\n        str: The content of the file as a string.\n\n    Raises:\n        Exception: If there's an error reading the file.\n    \"\"\"\n    try:\n        response = self.client.get_object(bucket_name, file_path)\n        content = response.read().decode('utf-8')\n        response.close()\n        response.release_conn()\n        return content\n    except Exception as e:\n        logger.error(f\"Error reading file from MinIO: {str(e)}\")\n        raise Exception(f\"Error reading file from MinIO: {str(e)}\")\n</code></pre>"},{"location":"storage/#kal_utils.storage.minio_storage.MinIOStorage.rename_file","title":"<code>rename_file(self, bucket_name, source_file_folder, source_file_name, new_file_name)</code>","text":"<p>Renames a file in MinIO by copying it to a new name and deleting the original.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The name of the bucket.</p> required <code>source_file_folder</code> <code>str</code> <p>The full path to the folder where the file is located.</p> required <code>source_file_name</code> <code>str</code> <p>The current file name.</p> required <code>new_file_name</code> <code>str</code> <p>The new file name.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the file was renamed successfully, False otherwise.</p> Source code in <code>kal_utils/storage/minio_storage.py</code> <pre><code>def rename_file(self, bucket_name, source_file_folder, source_file_name, new_file_name):\n    \"\"\"\n    Renames a file in MinIO by copying it to a new name and deleting the original.\n\n    Args:\n        bucket_name (str): The name of the bucket.\n        source_file_folder (str): The full path to the folder where the file is located.\n        source_file_name (str): The current file name.\n        new_file_name (str): The new file name.\n\n    Returns:\n        bool: True if the file was renamed successfully, False otherwise.\n    \"\"\"\n    try:\n        source_path = f\"{source_file_folder}/{source_file_name}\"\n        destination_path = f\"{source_file_folder}/{new_file_name}\"\n\n        # Create a CopySource object for the source file\n        source = CopySource(bucket_name, source_path)\n\n        # Copy the object\n        result = self.client.copy_object(bucket_name, destination_path, source)\n\n        if result.object_name == destination_path:\n            # If copy was successful, remove the original file\n            self.client.remove_object(bucket_name, source_path)\n            logger.info(f'File renamed from {source_path} to {destination_path}.')\n            return True\n        else:\n            logger.info(f'Failed to rename file from {source_path} to {destination_path}.')\n            return False\n    except Exception as e:\n        logger.error(f\"Error occurred while trying to rename file: {str(e)}\")\n        return False\n</code></pre>"},{"location":"storage/#kal_utils.storage.minio_storage.MinIOStorage.set_bucket_permissions","title":"<code>set_bucket_permissions(self, bucket_name, entity, role)</code>","text":"<p>Sets permissions for a bucket in MinIO.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The name of the bucket.</p> required <code>entity</code> <code>str</code> <p>The entity to set permissions for (e.g., 'user-email@example.com', 'group-group@example.com').</p> required <code>role</code> <code>str</code> <p>The role to assign to the entity (e.g., 'OWNER', 'READER', 'WRITER').</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the permissions were set successfully, False otherwise.</p> Source code in <code>kal_utils/storage/minio_storage.py</code> <pre><code>def set_bucket_permissions(self, bucket_name, entity, role):\n    \"\"\"\n    Sets permissions for a bucket in MinIO.\n\n    Args:\n        bucket_name (str): The name of the bucket.\n        entity (str): The entity to set permissions for (e.g., 'user-email@example.com', 'group-group@example.com').\n        role (str): The role to assign to the entity (e.g., 'OWNER', 'READER', 'WRITER').\n\n    Returns:\n        bool: True if the permissions were set successfully, False otherwise.\n    \"\"\"\n    try:\n        # Map GCS roles to MinIO policy actions\n        role_to_actions = {\n            'READER': ['s3:GetBucketLocation', 's3:ListBucket', 's3:GetObject'],\n            'WRITER': ['s3:GetBucketLocation', 's3:ListBucket', 's3:GetObject', 's3:PutObject', 's3:DeleteObject'],\n            'OWNER': ['s3:*'],\n        }\n\n        if role not in role_to_actions:\n            raise ValueError(f\"Unsupported role: {role}\")\n\n        actions = role_to_actions[role]\n\n        # Create a policy document\n        policy = {\n            \"Version\": \"2012-10-17\",\n            \"Statement\": [\n                {\n                    \"Effect\": \"Allow\",\n                    \"Principal\": {\"AWS\": [entity]},\n                    \"Action\": actions,\n                    \"Resource\": [f\"arn:aws:s3:::{bucket_name}\", f\"arn:aws:s3:::{bucket_name}/*\"]\n                }\n            ]\n        }\n\n        # Convert the policy to JSON string\n        policy_str = json.dumps(policy)\n\n        # Set the bucket policy\n        self.client.set_bucket_policy(bucket_name, policy_str)\n\n        logger.info(f'Permissions for entity {entity} set to {role} on bucket {bucket_name}.')\n        return True\n    except Exception as e:\n        logger.error(f\"Error occurred while trying to set bucket permissions: {str(e)}\")\n        return False\n</code></pre>"},{"location":"storage/#kal_utils.storage.minio_storage.MinIOStorage.set_file_permissions","title":"<code>set_file_permissions(self, bucket_name, file_path, entity, role)</code>","text":"<p>Sets permissions for a specific file in MinIO. Note: MinIO doesn't support object-level ACLs directly. This method sets a bucket policy that affects the specified object.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The name of the bucket.</p> required <code>file_path</code> <code>str</code> <p>The full path to the file within the bucket.</p> required <code>entity</code> <code>str</code> <p>The entity to set permissions for (e.g., 'user-email@example.com', 'group-group@example.com').</p> required <code>role</code> <code>str</code> <p>The role to assign to the entity (e.g., 'OWNER', 'READER', 'WRITER').</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the permissions were set successfully, False otherwise.</p> Source code in <code>kal_utils/storage/minio_storage.py</code> <pre><code>def set_file_permissions(self, bucket_name, file_path, entity, role):\n    \"\"\"\n    Sets permissions for a specific file in MinIO.\n    Note: MinIO doesn't support object-level ACLs directly. This method sets a bucket policy\n    that affects the specified object.\n\n    Args:\n        bucket_name (str): The name of the bucket.\n        file_path (str): The full path to the file within the bucket.\n        entity (str): The entity to set permissions for (e.g., 'user-email@example.com', 'group-group@example.com').\n        role (str): The role to assign to the entity (e.g., 'OWNER', 'READER', 'WRITER').\n\n    Returns:\n        bool: True if the permissions were set successfully, False otherwise.\n    \"\"\"\n    try:\n        # Map GCS roles to MinIO policy actions\n        role_to_actions = {\n            'READER': ['s3:GetObject'],\n            'WRITER': ['s3:GetObject', 's3:PutObject', 's3:DeleteObject'],\n            'OWNER': ['s3:*'],\n        }\n\n        if role not in role_to_actions:\n            raise ValueError(f\"Unsupported role: {role}\")\n\n        actions = role_to_actions[role]\n\n        # Create a policy document\n        policy = {\n            \"Version\": \"2012-10-17\",\n            \"Statement\": [\n                {\n                    \"Effect\": \"Allow\",\n                    \"Principal\": {\"AWS\": [entity]},\n                    \"Action\": actions,\n                    \"Resource\": [f\"arn:aws:s3:::{bucket_name}/{file_path}\"]\n                }\n            ]\n        }\n\n        # Convert the policy to JSON string\n        policy_str = json.dumps(policy)\n\n        # Get the current bucket policy\n        current_policy = self.client.get_bucket_policy(bucket_name)\n\n        # Merge the new policy with the existing one\n        # This is a simplistic approach and might need to be more sophisticated\n        # depending on your exact requirements\n        if current_policy:\n            current_policy_json = json.loads(current_policy)\n            current_policy_json['Statement'].append(policy['Statement'][0])\n            policy_str = json.dumps(current_policy_json)\n\n        # Set the updated bucket policy\n        self.client.set_bucket_policy(bucket_name, policy_str)\n\n        logger.info(f'Permissions set successfully on file {file_path} in bucket {bucket_name}.')\n        return True\n    except Exception as e:\n        logger.error(f\"Error occurred while trying to set file permissions: {str(e)}\")\n        return False\n</code></pre>"},{"location":"storage/#kal_utils.storage.minio_storage.MinIOStorage.upload_from_local","title":"<code>upload_from_local(self, bucket_name, file_path, destination_blob_name, content_type='application/octet-stream')</code>","text":"<p>Upload a file to the MinIO bucket.</p> Source code in <code>kal_utils/storage/minio_storage.py</code> <pre><code>def upload_from_local(self, bucket_name: str, file_path: str, destination_blob_name: str,\n                      content_type='application/octet-stream'):\n    \"\"\"Upload a file to the MinIO bucket.\"\"\"\n    try:\n        # Get the size of the file to upload\n        file_size = os.stat(file_path).st_size\n\n        # Open the file and upload it using MinIO's `put_object`\n        with open(file_path, 'rb') as file_data:\n            self.client.put_object(\n                bucket_name=bucket_name,\n                object_name=destination_blob_name,\n                data=file_data,\n                length=file_size,\n                content_type=content_type\n            )\n\n        logger.info(f\"File {file_path} uploaded to {destination_blob_name} in bucket {bucket_name}.\")\n        return True\n    except Exception as e:\n        logger.error(f\"Error while uploading to MinIO: {str(e)}\", exc_info=True)\n        return False\n</code></pre>"},{"location":"storage/#kal_utils.storage.minio_storage.MinIOStorage.upload_to_bucket","title":"<code>upload_to_bucket(self, bucket_name, file_stream, destination_blob_name, content_type='application/octet-stream')</code>","text":"<p>Uploads a file to a bucket in MinIO.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The name of the bucket.</p> required <code>file_stream</code> <code>BytesIO</code> <p>The byte stream of the file to upload.</p> required <code>destination_blob_name</code> <code>str</code> <p>The destination path and file name in the bucket.</p> required <p>Returns:</p> Type Description <code>tuple</code> <p>(bool, str) - (True if the file was uploaded successfully, False otherwise;                       The public URL of the uploaded file if successful, None otherwise)</p> Source code in <code>kal_utils/storage/minio_storage.py</code> <pre><code>def upload_to_bucket(self, bucket_name, file_stream, destination_blob_name, content_type='application/octet-stream'):\n    \"\"\"\n    Uploads a file to a bucket in MinIO.\n\n    Args:\n        bucket_name (str): The name of the bucket.\n        file_stream (BytesIO): The byte stream of the file to upload.\n        destination_blob_name (str): The destination path and file name in the bucket.\n\n    Returns:\n        tuple: (bool, str) - (True if the file was uploaded successfully, False otherwise;\n                              The public URL of the uploaded file if successful, None otherwise)\n    \"\"\"\n    try:\n        # Get the length of the file stream\n        file_stream.seek(0, 2)  # Go to the end of the stream\n        file_size = file_stream.tell()  # Get the position (size)\n        file_stream.seek(0)  # Go back to the beginning of the stream\n\n        # Upload the file to MinIO\n        self.client.put_object(\n            bucket_name,\n            destination_blob_name,\n            file_stream,\n            file_size,\n            content_type=content_type\n        )\n\n        logger.info(f'File uploaded to {destination_blob_name} in bucket {bucket_name}.')\n\n        # Generate a presigned URL for the uploaded object\n        # Note: This URL will expire after the specified time\n        url = f\"{self.url}/{bucket_name}/{destination_blob_name}\"\n\n        return True, url\n    except Exception as e:\n        logger.error(f\"Error occurred while trying to upload to bucket: {str(e)}\")\n        return False, None\n</code></pre>"},{"location":"storage/#functions","title":"Functions","text":""},{"location":"storage/#get_storage_client","title":"get_storage_client","text":"Source code in <code>kal_utils/storage/__init__.py</code> <pre><code>def get_storage_client(credentials_json = None, storage_type = None) -&gt; BaseStorage:\n    if storage_type is None or storage_type.upper() not in ['MINIO', 'GCS']:\n        storage_type = os.environ.get('STORAGE_TYPE', 'GCS').upper()\n    else:\n        storage_type = storage_type.upper()\n    if storage_type == 'GCS':\n        return GCSStorage(credentials_json)\n    elif storage_type == 'MINIO':\n        return MinIOStorage(credentials_json)\n    else:\n        raise ValueError(f\"Unsupported storage type: {storage_type}\")\n</code></pre>"},{"location":"time_zone/","title":"time_zone module","text":""},{"location":"usage/","title":"Usage","text":"<p>To use kal-utils in a project:</p> <pre><code>import kal_utils\n</code></pre>"},{"location":"examples/intro/","title":"Intro","text":"In\u00a0[1]: Copied! <pre>print('Hello World!')\n</pre> print('Hello World!') <pre>Hello World!\n</pre>"}]}